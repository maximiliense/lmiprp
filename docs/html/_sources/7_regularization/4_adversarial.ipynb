{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worse-failing",
   "metadata": {},
   "source": [
    "# Les attaques adversaires ☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-cleveland",
   "metadata": {},
   "source": [
    "## I. Introduction, qu'est-ce qu'une attaque adversaire ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-nickname",
   "metadata": {},
   "source": [
    "Reprenons le problème introduit précédemment. Soit $\\mathcal{X}\\subseteq\\mathbb{R}^d$ notre espace d'entrée et $\\mathcal{Y}=\\{0, 1\\}^C$ notre espace de sortie où $C\\in\\mathbb{N}$ est le nombre de classes de notre problème de classification. Considérons une famille paramétrique de fonctions :\n",
    "\n",
    "$$\\mathcal{H}=\\{h_\\theta:\\ \\theta\\in\\mathbb{R}^p\\},$$\n",
    "\n",
    "où $p\\in\\mathbb{N}$ est le nombre de paramètres. Notons $S_n$ notre jeu de données d'apprentissage composé de $n$ exemples, $T_m$ notre jeu de test et $\\ell$ la <em>loss</em> pour une unique prédiction. Notons aussi $\\text{Acc}(h_\\theta, S)$ le pourcentage de bonnes prédictions (i.e. <em>accuracy</em>) faites par $h_\\theta$ sur l'ensemble de données $S$. Notre objectif est de trouver la paramétrisation qui nous permet de minimiser notre <em>loss</em> sur le jeu de données :\n",
    "\n",
    "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\ell(h_\\theta(x_i), y_i)=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\mathcal{L}(h_\\theta, S_n).$$\n",
    "\n",
    "Cette minimisation n'est cependant pas un critère ultime et on souhaite que la fonction ainsi obtenue se comporte bien sur de nouvelles données jamais observées. Une manière d'estimer ces performances consiste à tester notre fonction sur un jeu de test : \n",
    "\n",
    "$$\\text{Acc}(h_{\\theta^\\star}, T_m).$$ \n",
    "\n",
    "Et malheureusement, la paramétrisation qui minimise notre <em>loss</em> n'est pas toujours performante sur de nouvelles données, comme nous avons pu le voir. Pour cela, diverses techniques allant de la réduction du nombre de paramètres aux techniques de régularitation $\\ell_1$ ou $\\ell_2$ en passant par le <em>dropout</em>, etc. sont possibles.\n",
    "\n",
    "Cependant, imaginons que notre jeu de test $T_m$ au lieu d'être un tirage aléatoire représentatif de la distribution de nos données soit choisi par un adversaire dont l'objectif est de mettre en échec notre modèle d'une manière telle qu'un être humain n'y verrait aucune différence. Est-il possible de faire croire à un modèle que la photo d'un STOP est en réalité une limitation de vitesse à 130km/h sans qu'un être humain ne voit la différence. C'est là l'objectif des attaques adversaires.\n",
    "\n",
    "<img SRC=\"https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemons_result.jpeg\" style='width:700px' align=\"center\" >\n",
    "\n",
    "Nous commencerons l'étude de ces questions en utilisant un modèle de l'état de l'art déjà pré-entraîné sur la base de données ImagetNet. L'objectif sera dans un premier temps de construire ces attaques adversaires puis, dans un second temps, de construire une procédure d'apprentissage robuste aux attaques adversaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-shuttle",
   "metadata": {},
   "source": [
    "## II. Imports et construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms, datasets\n",
    "from torch.nn.functional import softmax\n",
    "from torch.nn import CrossEntropyLoss, Linear, BatchNorm1d, ReLU, Sequential, Module\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch import optim, zeros_like, LongTensor\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import ast, json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-identity",
   "metadata": {},
   "source": [
    "Le modèle utilisé est $\\texttt{resnet50}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "\n",
    "# https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "preprocessing_no_normalize = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-australian",
   "metadata": {},
   "source": [
    "Notre réseau de neurones fait ses prédictions au travers d'un vecteur de dimension 1000 où chaque dimension est la probabilité (ou un score) associée à la classe de même indice. Afin de pouvoir associer un nom à chacune de ces classes, nous construisons le dictionnaire ci-dessous $\\texttt{classes}\\_\\texttt{to}\\_\\texttt{labels}$.\n",
    "\n",
    "Le fichier est téléchargeable à l'adresse suivante : \n",
    "[imagenet.json](https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/imagenet.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet.json', 'r') as f:\n",
    "    classes_to_labels = {int(k):v for k, v in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-headquarters",
   "metadata": {},
   "source": [
    "## III. La donnée à attaquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('lemon.jpeg')\n",
    "tensor = preprocessing_no_normalize(image)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(tensor.numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-helen",
   "metadata": {},
   "source": [
    "$\\texttt{Pytorch}$ prend en entrée des données dont la première dimension représente celle du batch. S'il n'y a qu'une donnée alors cette première dimension doit toujours exister et vaut $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = normalize(tensor)[None, :, :, :] # we create a batch\n",
    "\n",
    "print('[batch size, channels, width, height]:', batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-edgar",
   "metadata": {},
   "source": [
    "L'image est téléchargeable à l'adresse suivante : \n",
    "[lemon.jpeg](https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemon.jpeg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('lemon.jpeg')\n",
    "prediction = resnet(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim=1 indique qu'on prédit image par image \n",
    "# rappelez-vous que dim=0 correspond à la dimension du batch\n",
    "true_index = prediction.max(dim=1)[1].item()\n",
    "probability = softmax(prediction, dim=1).max(dim=1)[0][0].item()\n",
    "true_label = classes_to_labels[true_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_label, ':', probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-auditor",
   "metadata": {},
   "source": [
    "On observe que notre modèle prédit le bon label avec une très bonne probabilité !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-sugar",
   "metadata": {},
   "source": [
    "## IV. Une première attaque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-mississippi",
   "metadata": {},
   "source": [
    "### Quelques rappels d'optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-casino",
   "metadata": {},
   "source": [
    "Revenons à l'apprentissage de notre réseau de neurones. Notre objectif est de trouver une solution à la minimisation suivante : \n",
    "\n",
    "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\ell(h_\\theta(x_i), y_i)=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\mathcal{L}(h_\\theta, S_n).$$\n",
    "\n",
    "Pour cela, nous exploitons le fait que $\\mathcal{L}(h_\\theta, S_n)$ est différentiable presque partout en tant que fonction de $\\theta$ et cela afin d'utiliser l'algorithme de descente de gradient. Ce dernier réalise des pas successifs afin de se rapprocher toujours plus du minimum de notre fonction (ou du moins d'une valeur qui minimise). Chacun des pas se construit de la manière suivante :\n",
    "\n",
    "$$\\theta^{(t+1)}=\\theta^{(t)}-\\eta \\nabla_\\theta\\mathcal{L}(h_{\\theta^{(t)}}, S_n)$$\n",
    "\n",
    "La valeur du gradient $\\nabla_\\theta\\mathcal{L}(h_{\\theta^{(t)}}, S_n)$ est elle obtenue au travers de l'algorithme de <em>backpropagration</em>. Le paramètre $\\eta>0$ est ce qu'on appelle le pas d'apprentissage ou <em>learning rate</em> et permet de controler la stabilité de l'optimisation mais a aussi un effet de régularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-atmosphere",
   "metadata": {},
   "source": [
    "### Construction d'une attaque adversaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-missile",
   "metadata": {},
   "source": [
    "L'idée d'une attaque adversaire est de s'appuyer sur le même raisonnement mais dans l'espace des données $\\mathbb{R}^d$. Soit une donnée et son label $(x, y)$. Notre objectif est ainsi de trouver une perturbation $\\delta\\in\\mathbb{R}^d$ telle que la nouvelle donnée $x+\\delta$ ne soit plus associée au label $y$. Rappelons que notre loss $\\ell$ est une mesure des performances de notre réseau de neurones pour la donnée $(x, y)$. Ainsi, $\\ell(h_\\theta(x), y)$ est d'autant plus faible que notre modèle est bon et d'autant plus forte que notre modèle est mauvais. Nous allons omettre l'indice $\\theta$ de notre modèle puisqu'on le considère maintenant comme une constante.\n",
    "\n",
    "L'objectif d'une attaque adversaire est donc de trouver un bruit $\\delta\\in\\mathbb{R}^d$ de telle manière à ce que $\\ell(h_\\theta(x+\\delta), y)$ ait la plus grande valeur possible. Ainsi, on peut reformuler l'attaque adversaire via le problème de minimisation suivant :\n",
    "\n",
    "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathbb{R}^d}-\\ell(h_{\\theta}(x+\\delta), y).$$\n",
    "\n",
    "Observez qu'on minimise bien l'opposé de notre <em>loss</em> puisqu'on est en réalité intéressé par une maximisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-flight",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> Complétez l'algorithme suivant permettant de construire notre attaque adversaire.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we initialize delta with 0\n",
    "delta = zeros_like(tensor, requires_grad=True)\n",
    "\n",
    "# we construct our optimizer and loss\n",
    "optimizer = optim.SGD([delta], lr=2e-1)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# we construct the target\n",
    "target = LongTensor([true_index])\n",
    "\n",
    "for iteration in range(60):\n",
    "    ############### COMPLETE HERE ###############\n",
    "    # we construct the batch\n",
    "    batch = normalize(tensor + delta)[None, :, :, :]\n",
    "    pred = resnet(batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss = -criterion(pred, target)\n",
    "\n",
    "    if iteration % 5 == 0:\n",
    "        print('\\r[%d] loss: %.3f' % (iteration, loss.item()), end=\"\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "logit = resnet(batch)\n",
    "\n",
    "print('\\rTrue class probability:', softmax(logit, dim=1)[0, true_index].item())\n",
    "\n",
    "new_index = logit.max(dim=1)[1].item()\n",
    "new_label = classes_to_labels[new_index]\n",
    "\n",
    "print('New class:', new_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-marker",
   "metadata": {},
   "source": [
    "Excellent, nous avons réussi à transformer notre image $x$ via un bruit $\\delta$ de manière à piéger notre modèle ! On observe de plus que la probabilité de la bonne classe est maintenant ridiculement faible et se retrouve très probablement parmi les classes les moins probables. Observons le résultat de notre attaque adversaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(131)\n",
    "plt.title('Notre image transformée $x+\\delta$')\n",
    "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.title('Le bruit $\\delta$')\n",
    "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.title('Le bruit $\\delta$ amplifié')\n",
    "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-portal",
   "metadata": {},
   "source": [
    "Oups ! Notre image ne ressemble plus à rien. Le bruit ajouté est clairement visible. On pourrait même, si nous ne savions pas qu'il s'agit de citrons, douter et penser qu'il s'agit réellement d'oranges..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-special",
   "metadata": {},
   "source": [
    "## V. Un deuxième essai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-pastor",
   "metadata": {},
   "source": [
    "La stratégie va être de contraindre les déformations à rester à l'intérieur d'une boule dont nous pourrons contrôler le rayon et le fixer à de petites valeurs :\n",
    "\n",
    "$$\\mathcal{B}_\\epsilon=\\{x\\in\\mathbb{R}^d:\\ \\lVert x\\rVert\\leq \\epsilon\\}$$\n",
    "\n",
    "Considérons le cas simple de la norme $\\ell_\\infty$ :\n",
    "\n",
    "$$\\lVert x\\rVert_\\infty=\\text{max}_i|x_i|.$$\n",
    "\n",
    "Contraindre un vecteur à rester au sein d'une boule de rayon $\\epsilon$ revient pour la norme $\\ell_\\infty$ à tronquer chaque coordonnée de manière à ce que sa valeur absolue ne dépasse pas $\\epsilon$.\n",
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> Complétez l'algorithme suivant permettant de construire notre attaque adversaire en contraignant le vecteur $\\delta$ à rester dans une boule de rayon $\\epsilon$. Utilisez la méthode $\\texttt{delta.data.clamp}\\_\\texttt{(min, max)}$ qui permet de tronquer la valeur.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 2./255\n",
    "\n",
    "# we initialize delta with 0\n",
    "delta = zeros_like(tensor, requires_grad=True)\n",
    "\n",
    "# we construct our optimizer and loss\n",
    "optimizer = optim.SGD([delta], lr=2e-1)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# we construct the target\n",
    "target = LongTensor([true_index])\n",
    "\n",
    "for iteration in range(60):\n",
    "    ############### COMPLETE HERE ###############\n",
    "    # we construct the batch\n",
    "    batch = normalize(tensor + delta)[None, :, :, :]\n",
    "    pred = resnet(batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss = -criterion(pred, target)\n",
    "\n",
    "    if iteration % 5 == 0:\n",
    "        print('\\r[%d] loss: %.3f' % (iteration, loss.item()), end=\"\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    delta.data.clamp_(-epsilon, epsilon)\n",
    "    #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "logit = resnet(batch)\n",
    "\n",
    "print('\\rTrue class probability:', softmax(logit, dim=1)[0, true_index].item())\n",
    "\n",
    "new_index = logit.max(dim=1)[1].item()\n",
    "new_label = classes_to_labels[new_index]\n",
    "\n",
    "print('New class:', new_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-circumstances",
   "metadata": {},
   "source": [
    "Affichons maintenant l'image ainsi obtenue et le bruit qui lui est associé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(131)\n",
    "plt.title('Notre image transformée $x+\\delta$')\n",
    "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.title('Le bruit $\\delta$')\n",
    "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.title('Le bruit $\\delta$ amplifié')\n",
    "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-leeds",
   "metadata": {},
   "source": [
    "C'est beaucoup mieux ! Cependant, ce n'est pas en transformant des citrons en oranges que nous arriverons à prendre le contrôle de l'univers ! Ce que nous souhaiterions, c'est tromper le réseau de neurones avec une classe qui n'a RIEN À VOIR !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-tennis",
   "metadata": {},
   "source": [
    "Avant d'aller plus loin, il convient de comprendre un peu mieux pourquoi le réseau de neurones a choisi la classe orange à la place de citron. En minimisant l'opposé de l'entropie croisée afin de trouver notre bruit $\\delta$ nous avons en réalité principalement réduit l'amplitude des logits (i.e. le vecteur de score associé à chaque classe) pour la classe citron... Celle-ci en perdant de l'importance a laissé la place à la deuxième classe la plus probable pour cette image : les oranges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-international",
   "metadata": {},
   "source": [
    "## VI. Une attaque un petit peu plus ciblée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-server",
   "metadata": {},
   "source": [
    "Ce que nous voulons ici, c'est minimiser l'importance d'une classe $A$ tout en augmentant l'importance d'une classe $B$. Le problème qui nous intéresse est donc :\n",
    "\n",
    "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y)+\\ell(h_{\\theta}(x+\\delta), y_{\\text{target}}),$$\n",
    "\n",
    "où $y_{\\text{target}}$ est la classe que nous aimerions voir prédite. Choisissons maintenant la classe que nous visons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = 589\n",
    "print('Selected target:', classes_to_labels[target_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-dealing",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> Complétez l'algorithme suivant permettant de construire notre attaque adversaire en contraignant le vecteur $\\delta$ à rester dans une boule de rayon $\\epsilon$ et en ciblant une classe objectif.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 2./255\n",
    "\n",
    "# we initialize delta with 0\n",
    "delta = zeros_like(tensor, requires_grad=True)\n",
    "\n",
    "# we construct our optimizer and loss\n",
    "optimizer = optim.SGD([delta], lr=5e-3)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# we construct the targets\n",
    "true_target = LongTensor([true_index])\n",
    "target_target = LongTensor([target_index])\n",
    "\n",
    "for iteration in range(100):\n",
    "    ############### COMPLETE HERE ###############\n",
    "    # we construct the batch\n",
    "    batch = normalize(tensor + delta)[None, :, :, :]\n",
    "    pred = resnet(batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss = -criterion(pred, true_target) + criterion(pred, target_target)\n",
    "\n",
    "    if iteration % 5 == 0:\n",
    "        print('\\r[%d] loss: %.3f' % (iteration, loss.item()), end=\"\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    delta.data.clamp_(-epsilon, epsilon)\n",
    "    #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "logit = resnet(batch)\n",
    "\n",
    "print('\\rTrue class probability:', softmax(logit, dim=1)[0, true_index].item())\n",
    "\n",
    "new_index = logit.max(dim=1)[1].item()\n",
    "new_label = classes_to_labels[new_index]\n",
    "\n",
    "print('New class:', new_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-gasoline",
   "metadata": {},
   "source": [
    "Victoire ! Observons maintenant l'image bruitée ainsi que le bruit associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(131)\n",
    "plt.title('Notre image transformée $x+\\delta$')\n",
    "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.title('Le bruit $\\delta$')\n",
    "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.title('Le bruit $\\delta$ amplifié')\n",
    "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-gothic",
   "metadata": {},
   "source": [
    "Nous avons ainsi réussi à choisir notre classe objectif et à perturber notre réseau de neurones avec un bruit invisible à l'oeil nu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-george",
   "metadata": {},
   "source": [
    "## VII. La méthode \"fast-sign\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-tracker",
   "metadata": {},
   "source": [
    "Nous avons pu constater dans l'exemple précédent que la construction d'un exemple adversaire demandait de minimiser une fonction de coût (i.e. l'opposé de ce qu'on souhaiterait minimiser en temps normal). Cette minimisation prend un certain temps pour une unique image.\n",
    "\n",
    "Il existe une méthode alternative, moins performante en terme d'attaque mais plus efficaces computationnellement. Il s'agit de la méthode \"fast-sign\". Rappelons que l'objectif d'une attaque adversaire est de construire le bruit suivant : \n",
    "\n",
    "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y).$$\n",
    "\n",
    "L'intuition derrière la méthode \"fast-sign\" est de supposer que la direction du gradient au cours de la minimisation ne changera pas très significativement. Ainsi, au lieu de réaliser plusieurs petits pas successifs, nous pouvons réaliser un grand pas dans la direction du gradient au point de départ. Notons que nous souhaitons que notre vecteur de bruit reste dans une boule en norme infini $\\ell_\\infty$. Cela revient à dire que pour chaque coordonnée positive de notre gradient nous voulons que $\\delta_j=-\\epsilon$ et pour chaque coordonnée négative, nous voulons $\\delta_j=\\epsilon$ (nous voulons aller le plus loin possible). Notre bruit devient donc :\n",
    "\n",
    "$$\\hat{\\delta}=-\\epsilon\\cdot\\text{sign}(\\nabla_\\delta\\ell(h_{\\theta}(x+\\delta), y)).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-durham",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> À vous d'implémenter la méthode *fast-sign* dans le cas d'une attaque non ciblée.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 2./255\n",
    "\n",
    "# we initialize delta with 0\n",
    "delta = zeros_like(tensor, requires_grad=True)\n",
    "\n",
    "# we construct our loss\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# we construct the target\n",
    "target = LongTensor([true_index])\n",
    "\n",
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "\n",
    "pred = resnet(batch)\n",
    "\n",
    "############### COMPLETE HERE ###############\n",
    "loss = -criterion(pred, target)\n",
    "loss.backward()\n",
    "\n",
    "delta = -(delta.grad>0).float()*epsilon\n",
    "#############################################\n",
    "\n",
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "pred = resnet(batch)\n",
    "\n",
    "print('\\rTrue class probability:', softmax(pred, dim=1)[0, true_index].item())\n",
    "\n",
    "new_index = pred.max(dim=1)[1].item()\n",
    "new_label = classes_to_labels[new_index]\n",
    "\n",
    "print('New class:', new_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-disease",
   "metadata": {},
   "source": [
    "La performance de l'attaque est grandement réduite, mais fonctionne ! Visualisons le résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(131)\n",
    "plt.title('Notre image transformée $x+\\delta$')\n",
    "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.title('Le bruit $\\delta$')\n",
    "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.title('Le bruit $\\delta$ amplifié')\n",
    "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-midwest",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> À vous d'implémenter la méthode *fast-sign* dans le cas d'une attaque ciblée.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 50./255\n",
    "\n",
    "target_index = 589\n",
    "print('Selected target:', classes_to_labels[target_index])\n",
    "\n",
    "# we initialize delta with 0\n",
    "delta = zeros_like(tensor, requires_grad=True)\n",
    "\n",
    "# we construct our loss\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# we construct the target\n",
    "true_target = LongTensor([true_index])\n",
    "target_target = LongTensor([target_index])\n",
    "\n",
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "\n",
    "pred = resnet(batch)\n",
    "\n",
    "############### COMPLETE HERE ###############\n",
    "loss = -criterion(pred, true_target) + criterion(pred, target_target)\n",
    "loss.backward()\n",
    "#############################################\n",
    "\n",
    "delta = -(delta.grad>0).float()*epsilon\n",
    "\n",
    "batch = normalize(tensor + delta)[None, :, :, :]\n",
    "pred = resnet(batch)\n",
    "\n",
    "print('\\rTrue class probability:', softmax(pred, dim=1)[0, true_index].item())\n",
    "\n",
    "new_index = pred.max(dim=1)[1].item()\n",
    "new_label = classes_to_labels[new_index]\n",
    "\n",
    "print('New class:', new_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-difficulty",
   "metadata": {},
   "source": [
    "Il est probable que cette attaque ait échoué. En effet, nous avons déjà pu observer que dans le cas non ciblé, notre attaque avait eu beaucoup moins d'effet. L'effet sur les logits de la bonne classe est encore plus réduit lorsque l'attaque devient ciblée. Pour que l'attaque fonctionne, nous devons considérer un déplacement plus significatif qui risque d'être visible à l'écran...\n",
    "\n",
    "Testez plusieurs valeurs de $\\epsilon$ et observez le résultat à la fois en termes de prédiction que visuellement avec le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(131)\n",
    "plt.title('Notre image transformée $x+\\delta$')\n",
    "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.title('Le bruit $\\delta$')\n",
    "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.title('Le bruit $\\delta$ amplifié')\n",
    "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-participant",
   "metadata": {},
   "source": [
    "## VIII. Devenir robuste aux attaques adversaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-chorus",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "Comme indiqué plus haut, l'objectif de notre apprentissage est de trouver la solution :\n",
    "\n",
    "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\ell(h_\\theta(x_i), y_i)=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\mathcal{L}(h_\\theta, S_n).$$\n",
    "\n",
    "C'est la paramétrisation qui fait le moins d'erreur (au sens de la loss $\\ell$) sur notre jeu de données d'apprentissage. Si le choix de notre classe de fonctions et de nos hyperparamètres est bon, alors cette même paramétrisation fonctionnera également sur des données que nous n'avons pas encore vu. Cependant, cette dernière peut être très sensible aux attaques adversaires comme nous avons pu le voir ci-dessus. Une solution consiste à ne pas minimiser notre loss sur le jeu d'apprentissage, mais notre loss dans le pire des cas :\n",
    "\n",
    "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(h_\\theta(x_i+\\delta), y_i).$$\n",
    "\n",
    "Rappelons nous que l'algorithme de descente de gradient a besoin de ce dernier. Il nous faut donc calculer le gradient du maximum. Il se trouve que la solution est assez simple et revient à calculer le gradient au point $\\delta^\\star$, solution du maximum :\n",
    "\n",
    "$$\\nabla_\\theta \\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(h_\\theta(x_i+\\delta), y_i)=\\nabla_\\theta \\ell(h_\\theta(x_i+\\delta^\\star), y_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-watch",
   "metadata": {},
   "source": [
    "#### Construction du jeu de données\n",
    "Nous utiliserons ici le jeu de données MNIST restreint aux chiffres 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = mnist_train.targets <= 1\n",
    "mnist_train.data = mnist_train.data[train_idx]\n",
    "mnist_train.targets = mnist_train.targets[train_idx]\n",
    "\n",
    "test_idx = mnist_test.targets <= 1\n",
    "mnist_test.data = mnist_test.data[test_idx]\n",
    "mnist_test.targets = mnist_test.targets[test_idx]\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size = 512, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = 512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-emerald",
   "metadata": {},
   "source": [
    "Visualisons la tête de ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_loader)\n",
    "images, labels = next(iterator)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for j in range(16):\n",
    "    plt.subplot(4, 4, j+1)\n",
    "    plt.title(str(labels[j].numpy()))\n",
    "    plt.imshow(torch.squeeze(images[j].detach()).numpy())\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-reward",
   "metadata": {},
   "source": [
    "#### Un cas simple : le modèle linéaire (Rappels)\n",
    "\n",
    "La méthode \"fast-sign\" permet d'obtenir efficacement un adversaire mais le résultat n'est qu'approximatif. Le cas du modèle linéaire est intéressant car il est possible de trouver analytiquement les solutions de la maximisation (l'adversaire). Comme nous l'avons vu, un modèle linéaire cherche à séparer les classes par un ou plusieurs (multi-classes) hyperplans. Supposons que nous soyons dans $\\mathbb{R}^d$, un hyper-plan est décrit par un vecteur $\\omega\\in\\mathbb{R}^d$ et un scalaire $b\\in\\mathbb{R}$. Le vecteur $\\omega$ donne l'orientation de l'hyperplan et $b$ sa \"distance\" à \"l'origine\". Ainsi, un hyperplan est représenté par l'ensemble des points suivants :\n",
    "\n",
    "$$\\{x\\in\\mathbb{R}^d:\\ \\langle \\omega, x\\rangle+b=0\\}.$$\n",
    "\n",
    "Au-delà des points de l'hyperplan, la quantité $\\langle \\omega, x,\\rangle+b$ est positive si on est d'un côté de l'hyperplan et négative de l'autre. Considérons le cas binaire et notons nos classes $\\mathcal{Y}=\\{-1,+1\\}$. On souhaiterait que le côté négatif de l'hyperplan soit associé aux données dont le label est -1 et de la même manière que le côté positif soit associé aux données dont le label est +1.\n",
    "\n",
    "Soit la fonction $\\text{sign}(z)$ qui retourne $+1$ si $z>0$ et $-1$ si $z\\leq 0$. Le classifieur associé à notre hyperplan se construit donc de la manière suivante : \n",
    "\n",
    "$$h_\\theta(x)=\\text{sign}(\\langle \\omega, x\\rangle + b),\\ \\theta=\\{\\omega\\in\\mathbb{R}^d,b\\in\\mathbb{R}\\}.$$\n",
    "\n",
    "Par simplicité de notation nous ommettrons à partir de maintenant le biais $b$. Notons $g(x)=\\langle \\omega, x\\rangle$. Il s'agit d'une fonction qui donne le score de classification. On remarque que la fonction $g$ prédit le bon label si $g(x)$ a le même signe que $y$. Dit autrement, nos prédictions sont correctes si $g(x)y>0$.\n",
    "\n",
    "Intuitivement, nous aimerions minimiser la loss 0/1 :\n",
    "$$\\ell_{0/1}(z)=1\\{z\\leq 0\\}.$$\n",
    "Cette loss retourne $1$ si $z$ est négatif et $0$ sinon. Appliqué à notre modèle, cela donnée $\\ell(g(x)y)$ qui vaut $1$ si $g(x)$ n'a pas le même signe que $y$. C'est exactement ce qu'on veut. Cependant, cette loss n'est pas différentiable en $0$ et son gradient vaut $0$ partout ailleurs. Cela nous complique la tâche lorsqu'on cherche à optimiser notre modèle. Utilisons donc une loss possédant de meilleures propriétés mathématiques ainsi que certaines garanties pour la classification. Il s'agit de la fonction de perte logistique :\n",
    "\n",
    "$$\\ell(z)=\\text{log}(1+e^{-z}).$$\n",
    "\n",
    "On remarque que si $z$ est très grand ($g$ et $y$ sont de même signe et le score prédit est grand) alors la fonction est très proche de $0$. Si $z$ est très petit ($g$ et $y$ sont de signe différent et le score prédit est grand) alors la fonction diverge vers $+\\infty$. Il s'agit en réalité exactement de l'entropie croisée composée avec la sigmoid que nous avons déjà vu !\n",
    "\n",
    "Finalement, le problème à résoudre dans le cadre d'un classifieur linéaire est le suivant :\n",
    "\n",
    "$$\\theta^\\star=\\text{argmin}_{\\theta=\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i \\ell(y\\langle \\omega, x\\rangle).$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-ottawa",
   "metadata": {},
   "source": [
    "#### Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(Module):\n",
    "    def __init__(self, dim_input=784):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.weights = Linear(dim_input, 1)\n",
    "        self.dim_input = dim_input\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # we flatten the image into a vector\n",
    "        x = x.view(x.size()[0], self.dim_input)\n",
    "        # we apply our linear model\n",
    "        return self.weights(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-hazard",
   "metadata": {},
   "source": [
    "#### Construction de la loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-level",
   "metadata": {},
   "source": [
    "La logistic loss n'est rien d'autre que la sigmoid composée avec l'entropie croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticLoss(Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, y_hat, y):\n",
    "        # we flatten the image into a vector\n",
    "        y_hat = torch.squeeze(y_hat)\n",
    "        batch_size = y_hat.size()[0]\n",
    "        y = 2*y-1  # on met les labels entre -1 (anciennement 0) et 1\n",
    "        z = y*y_hat\n",
    "        return torch.sum(torch.log(1+torch.exp(-z))) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-battlefield",
   "metadata": {},
   "source": [
    "#### Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-hampshire",
   "metadata": {},
   "source": [
    "Notez qu'il s'agit encore et toujours ici de l'entraînement classique où nous ne tenons pas compte des attaques adversaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_plot(lr=0.005, epochs=50, logs=10, criterion=LogisticLoss()):\n",
    "    model = LinearClassifier()\n",
    "    # model.cuda()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n",
    "    \n",
    "    loss_history = []\n",
    "    running_loss = 0.0\n",
    "    for e in range(epochs):\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            # labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            if idx % logs == logs - 1:  # print every 2000 mini-batches\n",
    "                print('\\r[%d, %5d] loss: %.3f' % (e + 1, idx + 1, running_loss / logs), end=\"\")\n",
    "                loss_history.append(running_loss / logs)\n",
    "                running_loss = 0.0\n",
    "\n",
    "            loss.backward() # on calcule le gradient\n",
    "            optimizer.step() # on fait un pas d'optimisation\n",
    "    print('\\r************* Training done! *************')\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(loss_history)\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_and_plot(lr=0.001, epochs=60, logs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-depth",
   "metadata": {},
   "source": [
    "#### Test des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()  # on passe le modele en mode evaluation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            #images = images.cuda()\n",
    "            #labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            predicted = torch.squeeze((outputs > 0).float())\n",
    "        \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    model.train()  # on remet le modele en mode apprentissage\n",
    "    print('Accuracy du modele sur le jeu de test: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-express",
   "metadata": {},
   "source": [
    "#### Construction d'une attaque adversaire dans le cas du modèle linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-candidate",
   "metadata": {},
   "source": [
    "\n",
    "En reprenant le problème de l'apprentissage robuste aux attaques adversaires tel que défini ci-dessus, notre loss n'est plus directement $\\ell$. En effet, comme indiqué, nous devons non pas évaluer $\\ell$ en $x$ mais dans un voisinage de $x$ tel que le score de notre modèle y est le plus mauvais possible. La *loss* dans le pire des cas est décrite par l'équation suivante :\n",
    "\n",
    "$$\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(y\\langle\\omega, x+\\delta\\rangle)=\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\text{log}(1+e^{-y\\langle\\omega, x+\\delta\\rangle}).$$\n",
    "\n",
    "Avant d'aller plus loin, observons notre fonction de perte logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.linspace(-5, 5, 101)\n",
    "y=np.log(1+np.exp(-z))\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.plot(z, y)\n",
    "plt.title('La fonction de perte logistique')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-permit",
   "metadata": {},
   "source": [
    "Celle-ci semble monotone et décroissante (et convexe). Pour nous en convaincre, calculons la dérivée :\n",
    "\n",
    "$$\\ell^\\prime(z)=-\\frac{1}{e^z+1}<0,$$\n",
    "\n",
    "qui est bien toujours négative confirmant à la fois la monotonie et la décroissance. Pour le fun, constatons que notre fonction est bien également convexe :\n",
    "\n",
    "$$\\ell^{\\prime\\prime}(z)=\\frac{e^z}{(e^z+1)^2}>0.$$\n",
    "\n",
    "La fonction de perte logistique est donc même strictement convexe.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-mozambique",
   "metadata": {},
   "source": [
    "En constatant ainsi que la fonction de perte logistique est monotone ET décroissante et en exploitant la linéarité du produit scalaire, on obtient donc :\n",
    "\n",
    "$$\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(y\\langle\\omega, x+\\delta\\rangle)=\\ell(\\text{min}y\\langle\\omega, x+\\delta\\rangle)=\\ell(y\\langle\\omega, x\\rangle+\\text{min}y\\langle \\omega, \\delta\\rangle).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-batman",
   "metadata": {},
   "source": [
    "Il nous reste donc à chercher la solution du problème de minimisation $\\text{min}_{\\delta\\in\\mathcal{B}_\\epsilon}y\\langle \\omega, \\delta\\rangle$\n",
    "qui, heureusement pour nous, est convexe avec un domaine de définition compact. Il y a donc un minimum local qui est le minimum global. La norme $\\ell_\\infty$ nous permet de considérer chaque dimension séparément (le problème est séparable). Nous voulons donc calculer :\n",
    "\n",
    "$$\\text{min}_{|\\delta_j|\\leq \\epsilon}y\\langle \\omega_j, \\delta_j\\rangle.$$\n",
    "\n",
    "Si $\\omega_j=0$, toutes les solutions se valent. Si $\\omega_j\\neq 0$ et $y=-1$, alors le minimum est atteint lorsque $\\delta_j=\\epsilon\\cdot\\text{sign}(\\omega_j)$. Enfin, si $y=1$, alors le minimum est atteint lorsque $\\delta_j=-\\epsilon\\cdot\\text{sign}(\\omega_j)$. De manière générale, nous avons :\n",
    "\n",
    "$$\\delta^\\star=-y \\epsilon\\cdot\\text{sign}(\\omega)$$\n",
    "\n",
    "Nous avons ainsi : \n",
    "\n",
    "$$\\text{min}_{\\delta\\in\\mathcal{B}_\\epsilon}y\\langle \\omega, \\delta\\rangle=y\\langle\\omega, -y \\epsilon\\cdot\\text{sign}(\\omega)\\rangle=-y^2\\epsilon\\langle \\omega, \\text{sign}(\\omega)\\rangle=-\\epsilon\\lVert\\omega\\rVert_1.$$\n",
    "\n",
    "Un apprentissage robuste aux attaques adversaires minimise donc la loss :\n",
    "\n",
    "$$\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\text{log}(1+e^{-y\\langle\\omega, x\\rangle+\\epsilon\\lVert\\omega\\rVert_1})=\\ell(y\\langle\\omega, x\\rangle-\\epsilon\\lVert\\omega\\rVert_1)$$\n",
    "\n",
    "On retombe quasiment sur un problème d'optimisation avec une pénalité $\\ell_1$. On cherche le vecteur $\\omega$ qui maximise les bonnes prédictions mais qui en même temps possède une norme $\\ell_1$ faible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-conspiracy",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> En vous appuyant sur les \"résultats théoriques\" précédent, proposez un code permettant de générer un bruit adversaire.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_noise(image_and_label, model, epsilon=0.5):\n",
    "    imagesize = (1, 28, 28)\n",
    "    image, label = image_and_label\n",
    "    label = -1 if label==0 else label\n",
    "    ############### COMPLETE HERE ###############\n",
    "    noise = -(torch.reshape(model.weights.weight, imagesize)>0).float() * epsilon * label\n",
    "    #############################################\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_noise(image, noise):\n",
    "    plt.figure(figsize=(18,18))\n",
    "    plt.subplot(131)\n",
    "    plt.title('Notre image $x$')\n",
    "    plt.imshow(torch.squeeze(image.detach()).numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(132)\n",
    "    plt.title('Notre image transformée $x + \\delta^\\star$')\n",
    "    plt.imshow(torch.squeeze((image+noise).detach()).numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(133)\n",
    "    plt.title('Notre bruit $\\delta^\\star$')\n",
    "    plt.imshow(torch.squeeze(noise.detach()))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iterator)\n",
    "noise = generate_adversarial_noise((images[0], labels[0]), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_noise(images[0], noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = 0 if model(images[0])[0, 0] < 0 else 1\n",
    "print('Prédiction:', prediction)\n",
    "prediction = 0 if model(images[0]+noise)[0, 0] < 0 else 1\n",
    "print('Prédiction avec du bruit:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-sound",
   "metadata": {},
   "source": [
    "#### Apprentissage robuste aux attaques adversaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-classification",
   "metadata": {},
   "source": [
    "Un apprentissage robuste aux exemples adversaires cherche tout simplement à minimiser le pire des scénarios :\n",
    "\n",
    "$$\\omega^\\star=\\text{argmin}_{\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(y_i\\langle\\omega, x_i +\\delta\\rangle)=\\text{argmin}_{\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i\\ell(y_i\\langle\\omega, x_i\\rangle-\\epsilon\\lVert\\omega\\rVert_1).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-meeting",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> En vous appuyant sur les \"résultats théoriques\" précédent, proposez un code permettant de construire une loss robuste aux attaques adversaires.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustLogisticLoss(Module):\n",
    "    def __init__(self, weights, epsilon=0.5):\n",
    "        super(RobustLogisticLoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.weights = weights\n",
    "        \n",
    "    def forward(self, y_hat, y):\n",
    "        # we flatten the image into a vector\n",
    "        y_hat = torch.squeeze(y_hat)\n",
    "        batch_size = y_hat.size()[0]\n",
    "        y[y == 0] = -1\n",
    "        ############### COMPLETE HERE ###############\n",
    "        z = y*y_hat - torch.sum(torch.abs(self.weights)) * self.epsilon\n",
    "        #############################################\n",
    "        \n",
    "        return torch.sum(torch.log(1+torch.exp(-z))) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_and_plot(lr=0.001, epochs=60, logs=1, criterion=RobustLogisticLoss(model.weights.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iterator)\n",
    "noise = generate_adversarial_noise((images[0], labels[0]), model)\n",
    "\n",
    "plot_images_and_noise(images[0], noise)\n",
    "\n",
    "prediction = 0 if model(images[0])[0, 0] < 0 else 1\n",
    "\n",
    "print('Prédiction:', prediction)\n",
    "prediction = 0 if model(images[0]+noise)[0, 0] < 0 else 1\n",
    "print('Prédiction avec du bruit:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-scale",
   "metadata": {},
   "source": [
    "Il se trouve que les modèles linéaires sont déjà beaucoup plus robustes aux attaques adversaires que les réseaux de neurones. Malheureusement, les choses sont plus compliquées pour ces dernières puisque il n'y a déjà pas de solution analytique..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-divide",
   "metadata": {},
   "source": [
    "## En résumé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-ideal",
   "metadata": {},
   "source": [
    "*  Nous avons vu comment formaliser la notion d'attaque adversaire via un problème d'optimisation sous contrainte :\n",
    "\n",
    "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y),$$\n",
    "\n",
    "*  Nous avons vu une manière de cibler l'attaque afin de \"forcer\" notre modèle à prédire une classe particulière :\n",
    "\n",
    "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y)+\\ell(h_{\\theta}(x+\\delta), y_{\\text{target}}),$$\n",
    "\n",
    "*  Nous avons contourné le processus d'optimisation via une heuristique, la méthode *fast-sign* :\n",
    "\n",
    "$$\\hat{\\delta}=-\\epsilon\\cdot\\text{sign}(\\nabla_\\delta\\ell(h_{\\theta}(x+\\delta), y)),$$\n",
    "\n",
    "*  Nous avons également formalisé le problème d'apprentissage robuste aux attaques : \n",
    "\n",
    "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(h_\\theta(x_i+\\delta), y_i),$$\n",
    "\n",
    "*  Et avons résolu la maximisation dans le cadre d'un classifieur linéaire :\n",
    "\n",
    "$$\\omega^\\star=\\text{argmin}_{\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i\\ell(y_i\\langle\\omega, x_i\\rangle-\\epsilon\\lVert\\omega\\rVert_1).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-means",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
