{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rental-eligibility",
   "metadata": {},
   "source": [
    "# L'apprentissage multi-tâches ☕️☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-supplier",
   "metadata": {},
   "source": [
    "## I. Introduction\n",
    "\n",
    "Il est important de séparer un problème de *machine learning* pour lequel nous aurions plusieurs variables à prédir de l'apprentissage \"multi-tâches\". Ce dernier prédit certes plusieurs variables, mais ces dernières ne doivent leur présence que pour des raisons de régularisation (ou au moins pour ces raisons).\n",
    "\n",
    "Soit $\\mathcal{X}$ nos données d'entrée et $\\mathcal{Y}$ nos données de sortir. Notre objectif est de trouver une application de $\\mathcal{X}$ dans $\\mathcal{Y}$ qui fait peu d'erreur. Considérons à titre illustratif le cas de la classification binaire. Nous avons ici l'erreur $0/1$ définie de la manière suivante :\n",
    "\n",
    "$$R(h)=\\mathbb{E}\\big[\\textbf{1}\\{h(X)\\neq Y\\}\\big]=\\mathbb{P}\\big(h(X)\\neq Y\\big).$$\n",
    "\n",
    "Il s'agit bien sûr comme toujours de la probabilité que notre modèle se trompe. Bien sûr, ne connaissant pas la loi de nos variables aléatoires $X$ et $Y$, nous ne pouvons pas calculer ce risque. Pour cela, nous collectons un jeu de données :\n",
    "$$S_n=\\{(X_i, Y_i)\\}_{i\\leq n}\\sim \\mathbb{P}^n.$$\n",
    "Nous pouvons définir à partir de ce jeu de données un estimateur du risque précédent. On appelle ce dernier le risque empirique :\n",
    "\n",
    "$$Re(h)=\\frac{1}{n}\\sum_i \\textbf{1}\\{h(X_i)\\neq Y_i\\}.$$\n",
    "\n",
    "Soit $\\mathcal{H}$ une classe de fonction et notons $h_n$ son minimiseur (i.e. le minimiseur du risque empirique) :\n",
    "$$h_n=\\text{argmin}_{h\\in\\mathcal{H}}Re(h).$$\n",
    "Le principe de convergence uniforme nous dit que si notre risque empirique est un bon estimateur du risque de toutes les fonctions de $\\mathcal{H}$, alors le minimiseur du risque empirique est un bon choix. Plus formellement, comme vous l'avez peut-être lu dans la séquence traitant de la théorie de Vapnik et Chervonenkis, nous avons l'inégalité suivante : \n",
    "\n",
    "$$Re(h_n)-\\inf_{h\\in\\mathcal{H}}R(h)\\leq 2\\sup_{h\\in\\mathcal{H}}|Re(h)-R(h)|.$$\n",
    "\n",
    "Il est important de visualiser au moins intuitivement ce que la partie de droite implique. Notre estimateur empirique du risque est un mauvais estimateur si en moyenne sur $S_n$ les performances de $h$ sont très loin de ses performances en espérance. Cela devient bien sûr de plus en plus improbable lorsque la taille du jeu de données augmente. Mais cela devient de plus en plus probable lorsque la taille de $\\mathcal{H}$ (dont nous avons discuté dans la séquence traitant de la théorie VC) augmente.\n",
    "\n",
    "L'apprentissage multi-tâches n'a de sens que si certaines hypothèses sont vérifiées par $\\mathcal{H}$. Considérons le cas suivant. Notre tâche se décompose en deux étapes. Dans la première, on cherche à trouver une bonne représentation intermédiaire de notre données via une application $\\phi$ et dans la seconde, nous utilisons cette représentation afin de réaliser notre classification via une fonction $\\psi$. Nous avons donc :\n",
    "\n",
    "$$h:\\mathcal{X}\\overset{\\phi}{\\rightarrow}\\mathcal{Z}\\overset{\\psi}{\\rightarrow}\\mathcal{Y}.$$\n",
    "\n",
    "De plus imaginons plusieurs tâches $\\mathcal{Y}_1,\\ldots,\\mathcal{Y}_K$. Notre objectif est donc de trouver $K$ applications allant de $\\mathcal{X}$ vers chacune des cibles. Supposons que ces tâches partagent des *features* discriminantes (sur des images on pourrait imaginer que les *features* visuels sont importants pour plusieurs tâches). Nous avons donc $\\mathcal{Y}=\\mathcal{Y}_1\\times\\ldots\\times\\mathcal{Y}_k$, un espace de représentation $\\mathcal{Z}$, un espace de données $\\mathcal{X}$, une classe d'application d'apprentissage de *features* $\\mathcal{H}_f=\\{f:\\mathcal{X}\\rightarrow\\mathcal{Z}\\}$ et des classes de classifieurs $\\mathcal{H}_i=\\{g_i:\\mathcal{Z}\\rightarrow\\mathcal{Y}_i\\}$. Notre classe de fonctions complète est donc :\n",
    "\n",
    "$$\\mathcal{H}=\\{h=(g_1, \\ldots, g_K)\\circ f: f\\in\\mathcal{H}_f, g_i\\in\\mathcal{H}_i\\}.$$\n",
    "\n",
    "Une situation de surapprentissage peut se produire pour deux raisons : un mauvais choix de classifieurs $g_i$ et un mauvais choix de features via $f$. Pour ce qui est du classifieur $g_i$ c'est la situation classique. Cependant, pour le choix de $f$, un mauvais choix implique que malgré tout la totalité de nos $K$ tâches arrivent à minimiser le risque empirique via ces mauvais features qui en espérance ne le permettent pas. On se rend assez vite compte qu'en fonction de l'indépendance de ces tâches, cela devient de plus en plus improbables.\n",
    "\n",
    "En résumé, rajouter des tâches est une manière \"virtuelle\" d'augmenter la taille de notre jeu de données pour ce qui est de l'apprentissage de *features*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-apple",
   "metadata": {},
   "source": [
    "## II. En pratique avec des réseaux de neurones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-garlic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
