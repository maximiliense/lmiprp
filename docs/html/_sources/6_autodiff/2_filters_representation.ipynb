{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liked-monaco",
   "metadata": {},
   "source": [
    "# Filtres et espace de représentation des réseaux de neurones ☕️☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-section",
   "metadata": {},
   "source": [
    "Les exercices de cette session seront réalisés deux fois. Une fois sur le jeu de données CIFAR10 et une fois sur un jeu de données représentant les personnages des Simpsons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-longer",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "recreational-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour Google Colaboratory\n",
    "# Décommenter la ligne suivante\n",
    "# !pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competent-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-bubble",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Each itereates over the dataloader define with batch size will get a batch of batch size samples\n",
    "# After the iterator has gone through every data sample (one epoch), then we shuffle the order and we go again.\n",
    "batch_size = 128\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-afternoon",
   "metadata": {},
   "source": [
    "## I. Construction du jeu de données CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-season",
   "metadata": {},
   "source": [
    "Le $\\texttt{dataset}$ est une sorte de tableau qui contient les éléments de notre jeu de données. Le $\\texttt{dataloader}$ est l'objet qui nous permettra d'accéder à nos données via des batchs aléatoires. Rappelons que le calcul du gradient se fait sur les données. Cependant avec des fonctions aussi complexes qu'un réseau de neurones et avec des jeu de données aussi gros, il devient nécessaire de n'estimer le gradient que sur une partie de ces données.\n",
    "\n",
    "L'objet $\\texttt{transform}$ permettra de normaliser les données qui seront données à notre modèle. En $\\texttt{pytorch}$, les données sont gérées par un *data loader*. En effet, on ne traite que très rarement tout le jeu de données d'un coup. On estime plutôt le gradient via un *batch* de données. De meilleurs résultats sont généralement observés lorsque le jeu de données est mélangé entre chaque itération d'optimisation. \n",
    "\n",
    "Les parties qui commencent par un **[•] Méthode de....** sont celles qu'il faudra réutiliser plus tard (plusieurs fois)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-spouse",
   "metadata": {},
   "source": [
    "### [•] Méthode de split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, valid_size = 0.0, random_state=42):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(valid_size * dataset_size))\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    return dataset, copy.deepcopy(dataset), train_sampler, valid_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-relationship",
   "metadata": {},
   "source": [
    "### Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    # label names\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "      [\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    #root_directory where images are.\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    trainset, validset, train_sampler, valid_sampler = split_dataset(trainset, valid_size = 0.2, random_state=None)\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "      trainset, batch_size=batch_size, sampler=train_sampler,\n",
    "      num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    validloader = DataLoader(\n",
    "      validset, batch_size=batch_size, sampler=valid_sampler,\n",
    "      num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    print(len(trainloader), len(validloader))\n",
    "\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = DataLoader(\n",
    "      testset, batch_size=batch_size, shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    print('Nb test batchs:', len(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-pointer",
   "metadata": {},
   "source": [
    "### Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-motion",
   "metadata": {},
   "source": [
    "####  [•] Méthode de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visualisation d'images du jeu de données\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(images, labels, predicted=None):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for idx in range(8):\n",
    "        plt.subplot(2, 4, idx+1)\n",
    "        plt.axis('off')\n",
    "        img = (images[idx] * 0.224 + 0.456)#/ 2 + 0.5  # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        title = str(classes[labels[idx]]) + \\\n",
    "        ('' if predicted is None else ' - ' + str(classes[predicted[idx]]))\n",
    "        plt.title(title)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-president",
   "metadata": {},
   "source": [
    "#### Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    # get some random training images\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # show images\n",
    "    imshow(images[:8], labels[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-pierce",
   "metadata": {},
   "source": [
    "## II. Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-regression",
   "metadata": {},
   "source": [
    "## III. Visualisation des filtres/paramètres du modèle à l'initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-pacific",
   "metadata": {},
   "source": [
    "### [•] Méthode de visualisation des filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = torchvision.utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-support",
   "metadata": {},
   "source": [
    "### Visualisation des filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    filters = model.conv1.weight.data.clone().cpu()\n",
    "    visualize_filters(filters, ch=0, allkernels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-alert",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Que pouvez-vous dire de ces filtres ?**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-barcelona",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Réponse :**</span> Comme attendu, les filtres semblent aléatoires !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-sharp",
   "metadata": {},
   "source": [
    "## IV. L'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-matrix",
   "metadata": {},
   "source": [
    "### Fonction objectif, scheduler et optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    #Choose the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[25, 50], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-wings",
   "metadata": {},
   "source": [
    "### [•] Méthodes d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Let us code a generic prediction function\n",
    "def predict(model, loader, criterion=nn.CrossEntropyLoss(), feature_extract=False, max_size=0, resize=128):\n",
    "    with torch.no_grad():\n",
    "        if not feature_extract:\n",
    "            model.eval()\n",
    "\n",
    "        y_preds = []\n",
    "        y_labels = []\n",
    "        inputs_ = []\n",
    "\n",
    "        running_loss = 0.0\n",
    "        size = 0.0\n",
    "        for idx, data in enumerate(loader):\n",
    "            inputs, labels = data\n",
    "            # inputs = inputs.cuda()\n",
    "            # labels = labels.cuda()\n",
    "\n",
    "            # wrap them in Variable\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            y_preds.extend(outputs.data.tolist())\n",
    "            y_labels.extend(labels.data.tolist())\n",
    "            if size <= max_size and feature_extract:\n",
    "                images = [\n",
    "                    cv2.resize(\n",
    "                        (\n",
    "                            (i*0.224+0.456)*255).astype('uint8').transpose((1, 2, 0)), dsize=(resize, resize)\n",
    "                    ) for i in inputs.data.cpu().numpy()\n",
    "                ]\n",
    "                inputs_.extend(images)\n",
    "                size = len(inputs_)\n",
    "\n",
    "        predictions, labels, inputs = np.asarray(y_preds), np.asarray(y_labels), np.asarray(inputs_)\n",
    "\n",
    "    if not feature_extract:\n",
    "        return predictions, labels, running_loss/len(loader)\n",
    "\n",
    "    return predictions, labels, inputs\n",
    "\n",
    "\n",
    "def accuracy_topk(predictions, labels, top_k=1):\n",
    "        res = 0\n",
    "        for i, pred in enumerate(predictions):\n",
    "            answer = np.argsort(-pred)[0:top_k]\n",
    "            if labels[i] in answer:\n",
    "                res += 1\n",
    "        acc = float(res) / float(labels.shape[0])\n",
    "        return acc\n",
    "\n",
    "    \n",
    "def evaluate(loader, model, top_k = 1, criterion = nn.CrossEntropyLoss()):\n",
    "    predictions, labels, loss = predict(model, loader, criterion)\n",
    "    return accuracy_topk(predictions, labels, top_k = top_k), loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-moore",
   "metadata": {},
   "source": [
    "### [•] Méthode d'apprentissage (i.e. d'optimisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-likelihood",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Proposez le code en utilisant une fonction (pour pouvoir réutiliser le code plus tard) permettant d'optimiser votre réseau pendant deux *epochs*.**\n",
    "\n",
    "**Attention, votre code doit renvoyer 4 tableaux : l'historique de la loss de train, l'historique la loss de validation, l'historique de l'accuracy de train et de l'accuracy de test.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_frequency=5\n",
    "####### Complete this part ######## or die ####################\n",
    "def train(model, criterion, optimizer, scheduler, n_epoch=2):\n",
    "    loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "        print(\"[EPOCH %d, LR: %s]\"%(epoch + 1, str(scheduler.get_last_lr())))\n",
    "\n",
    "        #iterate over the training batches until all all samples have been considered\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            print('\\r[Batch id: %d/%d]' % (i+1, len(trainloader)), end='')\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Convert to cuda is device is gpu\n",
    "            # inputs = inputs.cuda()\n",
    "            # labels = labels.cuda()\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward : compute outputs for all layers \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Backward: Compute gradient wrt parameters of all layers\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize = update model parameters = Apply one step of SGD\n",
    "            # for all paramters (one step move in the parameters space)\n",
    "            optimizer.step()\n",
    "\n",
    "        print(' train loss: %.3f' % (running_loss/len(trainloader)), end='')\n",
    "\n",
    "        #Apply learning update according to the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % eval_frequency == 0:\n",
    "            #Compute training statistics\n",
    "            accuracy, _ = evaluate(trainloader, model, criterion = criterion)\n",
    "            print(', train accuracy: %.3f,' % (accuracy), end='')\n",
    "            loss_history.append(running_loss/len(trainloader))\n",
    "            acc_history.append(accuracy)\n",
    "\n",
    "            #Compute validation statistics\n",
    "            accuracy, running_loss = evaluate(validloader, model, criterion = criterion)\n",
    "            print(' validation loss: %.3f, validation accuracy: %.3f' % (running_loss, accuracy), end='\\n')\n",
    "            valid_loss_history.append(running_loss)\n",
    "            val_acc_history.append(accuracy)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print('**** Finished Training ****')\n",
    "    return loss_history, valid_loss_history, acc_history, val_acc_history\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-ensemble",
   "metadata": {},
   "source": [
    "### L'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    eval_frequency=1\n",
    "\n",
    "    loss_history, \\\n",
    "    valid_loss_history, \\\n",
    "    acc_history, \\\n",
    "    val_acc_history = train(model, criterion, optimizer, scheduler, n_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-territory",
   "metadata": {},
   "source": [
    "### Affichage des courbes de loss et de précision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-precipitation",
   "metadata": {},
   "source": [
    "#### [•] Méthode d'affichage des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_history, valid_loss_history, acc_history, val_acc_history):\n",
    "    plt.figure()\n",
    "    plt.plot([i*eval_frequency for i in range(1, len(loss_history)+1)], loss_history, \n",
    "             label='Train loss')\n",
    "    plt.plot([i*eval_frequency for i in range(1, len(loss_history)+1)], valid_loss_history, \n",
    "             label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([i*eval_frequency for i in range(1, len(acc_history)+1)], acc_history, \n",
    "             label='Train Accuracy')\n",
    "    plt.plot([i*eval_frequency for i in range(1, len(acc_history)+1)], val_acc_history, \n",
    "             label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-science",
   "metadata": {},
   "source": [
    "#### Affichage des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    plot_loss(loss_history, valid_loss_history, acc_history, val_acc_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-functionality",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Que pouvez-vous conclure en regardant la loss et l'accuracy ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-theme",
   "metadata": {},
   "source": [
    "### Sauvegarde et chargement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-unknown",
   "metadata": {},
   "source": [
    "En *deep learning* l'apprentissage d'un modèle peut prendre énormément de temps. Pensez à toujours sauvegarder votre modèle régulièrement afin de ne pas le perdre. (Attention, il faut parfois aussi sauvegarder les variables liées à l'optimiseur lui-même...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-taxation",
   "metadata": {},
   "source": [
    "#### Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    torch.save(model.state_dict(), 'my_model.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-youth",
   "metadata": {},
   "source": [
    "#### Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load('my_model.torch'))\n",
    "    # model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-identification",
   "metadata": {},
   "source": [
    "## V. Visualisation des filtres/paramètres appris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    filters = model.conv1.weight.data.clone().cpu()\n",
    "    visualize_filters(filters, ch=0, allkernels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-prison",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Que conclure en regardant ces filtres relativement aux filtres avant l'entraînement du modèle ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-cheat",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:green\">**Réponse :**</span> On peut remarquer que nos filtres contiennent des informations beaucoup plus précises !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-machine",
   "metadata": {},
   "source": [
    "## VI. Évaluasion du modèle sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    accuracy, _ = evaluate(testloader, model)\n",
    "    print('Test accuracy: %.3f' % (accuracy), end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-region",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Que dire de l'accuracy ? Quel est le score attendu d'un modèle aléatoire ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-cigarette",
   "metadata": {},
   "source": [
    "## VII. Test des prédictions sur quelques images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    #Test prediction on some images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = model(images[:8])#  .to(device))  # we use the loaded model\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    imshow(images[:8], labels[:8], predicted[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-berlin",
   "metadata": {},
   "source": [
    "Tester son modèle sur quelques images peut être intéressant lorsqu'il s'agit de comprendre le type d'erreurs qui sont faites. Ça ne peut JAMAIS être un argument suffisant pour dire que le modèle \"marche\" !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-romantic",
   "metadata": {},
   "source": [
    "## VIII. Extraction des features et Dataviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-chambers",
   "metadata": {},
   "source": [
    "Rappelons nous qu'une réseau de neurones est la composition d'une première fonction $\\phi:\\mathbb{R}^p\\mapsto\\mathbb{R}^f$ qui apprend un *feature space* et d'un classifieur linéaire $\\psi:\\mathbb{R}^f\\mapsto\\mathbb{R}^C$ qui retourne un score pour chacune des classes de notre problèmes à $C$ classes. Il est intéressant d'étudier la manière dont la fonction $\\phi$ a déformé l'espace d'entrée en regroupant certaines images entre elles, etc. Notons que la fonction $\\phi$ est elle-même une composition et qu'il est possible d'étudier les sorties des différentes couches.\n",
    "\n",
    "Visualiser la sortie de la fonction $\\phi$ n'est pas directement possible puisqe l'espace possède $f$ dimensions et que $f$ est généralement très loin devant $2$ et $3$. Il convient donc d'utiliser un algorithme de réduction de dimension. Ces algorithmes fonctionnent très bien sur la sortie de la fonction $\\phi$ car la \"dimension effective\" de nos données s'y retrouvent très réduites : les images similaires se retrouvent très proches les une des autres et très différentes des autres images, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-reception",
   "metadata": {},
   "source": [
    "Dans un modèle $\\texttt{Pytorch}$, la coutume est d'appeler $\\texttt{fc}$ la fonction $\\psi$. Si nous souhaitons récupérer la sortie de la fonction $\\phi$ il suffit de remplacer $\\texttt{fc}$ par la fonction identité. C'est ce que nous faisons maintenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the classification lyaer by an identify function forward the feature space to the end\n",
    "# We now may forward and get the features as output of the model\n",
    "model.fc = nn.Identity()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-karma",
   "metadata": {},
   "source": [
    "### Reduction de dimensionalité: PCA, t-SNE, UMAP, etc ....\n",
    "L'idée est ici d'apprendre à partir de l'espace de caractéristique (i.e. de représentation) du modèle, un projecteur qui va faire passer d'un espace de dimension $f$ à un espace de dimension $2$ qu'on va pouvoir visualiser sur un graphe. Vous connaissez déjà un certains nombre d'algorithmes de ce type (PCA, t-SNE, etc.). Nous utiliserons ici UMAP qui on pour objectif d'apprendre une fonction $map : x \\rightarrow map(x) :  \\mathbb{R}^k \\rightarrow \\mathbb{R}^2$ de sorte à ce que les vecteurs voisins au sens d'une norme (e.g. distance euclidienne $L_2$) soient voisin au sens de la norme euclidienne dans l'espace de basse dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    #Extract feature vectors:\n",
    "    features, labels, images = predict(\n",
    "        model, \n",
    "        trainloader, \n",
    "        feature_extract=True, \n",
    "        max_size=len(trainset)\n",
    "    )\n",
    "\n",
    "    print(features.shape, labels.shape, images.shape)\n",
    "\n",
    "    labels = [classes[labels[j]] for j in range(labels.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    umap_2d = umap.umap_.UMAP(n_components=2, random_state=0)\n",
    "    umap_2d.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    projections_umap = umap_2d.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-there",
   "metadata": {},
   "source": [
    "###  Visualisation avec plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    fig = px.scatter(\n",
    "        projections_umap, x=0, y=1,\n",
    "        color=labels\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-badge",
   "metadata": {},
   "source": [
    "N'hésitez pas à déselectionner en cliquant sur le label associé ou à ne sélectionner qu'une seule catégorie en double cliquant !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-costs",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Que dire de ce feature space. Permet-il d'expliquer les performances de votre modèle ? Pourquoi ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-uruguay",
   "metadata": {},
   "source": [
    "### Visualisation interactive avec Bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-three",
   "metadata": {},
   "source": [
    "En réalité, chaque point de notre feature space est l'image d'un $x\\in\\mathbb{R}^d$ par la fonction $\\phi$. Il est particulièrement intéressant d'essayer de visualiser les $x$ qui ont permis de produire chacun des points. Cela nous permettra de constater les proximités et/ou différences entre les points en fonction de leur proximité/distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-acoustic",
   "metadata": {},
   "source": [
    "#### [•] Méthode de visualisation du feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10, Viridis256, Category20, Turbo256, mpl\n",
    "import itertools\n",
    "\n",
    "def plot_feature_space_with_images(classes, images, labels):\n",
    "    output_notebook()\n",
    "    colors = itertools.cycle(Category20[20])    \n",
    "    pal = [color for m, color in zip(range(len(classes)), colors)]\n",
    "    np.random.shuffle(pal)\n",
    "\n",
    "    def embeddable_image(data):\n",
    "        image = Image.fromarray(data, mode='RGB')\n",
    "        buffer = BytesIO()\n",
    "        image.save(buffer, format='jpeg')\n",
    "        for_encoding = buffer.getvalue()\n",
    "        return 'data:image/jpeg;base64,' + base64.b64encode(for_encoding).decode()\n",
    "    max_size = 2000\n",
    "    data_df = pd.DataFrame(projections_umap[:max_size], columns=('x', 'y'))\n",
    "    data_df['class'] = [x for x in labels][:max_size]\n",
    "    data_df['image'] = list(map(embeddable_image, images[:max_size]))\n",
    "\n",
    "    datasource = ColumnDataSource(data_df)\n",
    "    color_mapping = CategoricalColorMapper(factors=classes,\n",
    "                                           palette=pal)\n",
    "    plot_figure = figure(\n",
    "        title='UMAP projection of the dataset',\n",
    "        plot_width=900,\n",
    "        plot_height=600,\n",
    "        tools=('pan, wheel_zoom, reset')\n",
    "    )\n",
    "    plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style='font-size: 16px; color: #224499'>Classe:</span>\n",
    "            <span style='font-size: 18px'>@class</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "    plot_figure.circle(\n",
    "        'x',\n",
    "        'y',\n",
    "        source=datasource,\n",
    "        color=dict(field='class', transform=color_mapping),\n",
    "        line_alpha=0.6,\n",
    "        fill_alpha=0.6,\n",
    "        size=10,\n",
    "        legend_field=\"class\",\n",
    "    )\n",
    "    plot_figure.legend.location = \"top_left\"\n",
    "    #plot_figure.legend.click_policy=\"mute\"\n",
    "    plot_figure.legend.label_text_font_size = \"8px\"\n",
    "    show(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-harbor",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    plot_feature_space_with_images(classes, images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-permission",
   "metadata": {},
   "source": [
    "## IX. On recommence avec les Simpsons !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-indication",
   "metadata": {},
   "source": [
    "Attention, afin de ne pas tout recoder, pensez à exécuter les cellules des sections dont le titre est au format **[•] Méthode de ...** qui contiennent du code réutilisable !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-framework",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Répondez à toutes les questions précédentes dans le cadre de ce nouveau jeu de données et de ce nouveau modèle !**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-paint",
   "metadata": {},
   "source": [
    "### A. Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour Google Colaboratory\n",
    "# Décommenter les lignes suivantes\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# dataset_path = '/content/drive/MyDrive/DeepTP/archive/simpsons_dataset'\n",
    "# dataset_path_test = '/content/drive/MyDrive/DeepTP/archive/kaggle_simpson_testset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    # Chemin local vers le dataset\n",
    "    dataset_path = './data/Simpsons/simpsons_dataset'\n",
    "    dataset_path_test ='./data/Simpsons/kaggle_simpson_testset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        #  RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    dataset_train = datasets.ImageFolder(root=dataset_path, transform=data_transform)\n",
    "\n",
    "    trainset, validset, train_sampler, valid_sampler = split_dataset(\n",
    "        dataset_train, valid_size = 0.2, random_state=None\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "      trainset, batch_size=batch_size, sampler=train_sampler,\n",
    "      num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    validloader = DataLoader(\n",
    "      validset, batch_size=batch_size, sampler=valid_sampler,\n",
    "      num_workers=num_workers,\n",
    "    )\n",
    "    print('Number of batches in train/val:', len(trainloader), len(validloader))\n",
    "\n",
    "    #  Get the test data from the test directory\n",
    "    dataset_test = datasets.ImageFolder(root=dataset_path_test,\n",
    "                                        transform=data_transform)\n",
    "\n",
    "    # We don't need to split train val, all test data are in one folder\n",
    "    testloader = DataLoader(\n",
    "      dataset_test, batch_size=batch_size, shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "    )\n",
    "    print('Number of batches in test:', len(testloader))\n",
    "\n",
    "    # We list all the directories in alphabetical order to have the label classes.\n",
    "    classes = [c for c in sorted(os.listdir(dataset_path))]\n",
    "    print('Classes :\\n\\t- ' + '\\n\\t- '.join(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-franchise",
   "metadata": {},
   "source": [
    "### B. Visualisation de quelques images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    imshow(images[:8], labels[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-panama",
   "metadata": {},
   "source": [
    "### C. Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    print(\"Loading existing architecture and init parameters of model pretrained on ImageNet...\")\n",
    "    model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-subscription",
   "metadata": {},
   "source": [
    "Dans certains cas, nous ne voulons apprendre que le classifieur final en espérant que l'espace de représentation appris nous permettra de résoudre notre tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    finetuning = True\n",
    "    if finetuning:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "    # model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-canvas",
   "metadata": {},
   "source": [
    "### D. Visualisation des filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    filters = model.conv1.weight.data.clone().cpu()\n",
    "    visualize_filters(filters, ch=0, allkernels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-giving",
   "metadata": {},
   "source": [
    "### E. L'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-privacy",
   "metadata": {},
   "source": [
    "#### Fonction objectif, scheduler et optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    #Choose the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[25, 50], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-march",
   "metadata": {},
   "source": [
    "#### L'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    eval_frequency=1\n",
    "\n",
    "    loss_history, \\\n",
    "    valid_loss_history, \\\n",
    "    acc_history, \\\n",
    "    val_acc_history = train(model, criterion, optimizer, scheduler, n_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-attention",
   "metadata": {},
   "source": [
    "#### Visualisation des courbes de loss et de précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    plot_loss(\n",
    "        loss_history, valid_loss_history, acc_history, val_acc_history\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-pillow",
   "metadata": {},
   "source": [
    "#### Sauvegarde et chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    torch.save(model.state_dict(), 'my_model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load('my_model.torch'))\n",
    "    # model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-deployment",
   "metadata": {},
   "source": [
    "### F. Visualisation des filtres/paramètres appris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-glance",
   "metadata": {},
   "source": [
    "Attention, si le modèle a été finetuné, les filtres n'ont pas été modifiés et sont donc les mêmes qu'au départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    filters = model.conv1.weight.data.clone().cpu()\n",
    "    visualize_filters(filters, ch=0, allkernels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-burning",
   "metadata": {},
   "source": [
    "### G. Évaluation du modèle et test de quelques prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    accuracy, _ = evaluate(testloader, model)\n",
    "\n",
    "    print('Test accuracy: %.3f' % (accuracy), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    #Test prediction on some images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = model(images[:8])#  .to(device))  # we use the loaded model\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    imshow(images[:8], labels[:8], predicted[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-chain",
   "metadata": {},
   "source": [
    "### H. Extraction de features et Dataviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    #Extract feature vectors:\n",
    "    features, labels, images = predict(\n",
    "        model, \n",
    "        trainloader, \n",
    "        feature_extract=True, \n",
    "        max_size=len(trainset)\n",
    "    )\n",
    "\n",
    "    print(features.shape, labels.shape, images.shape)\n",
    "\n",
    "    labels = [classes[labels[j]] for j in range(labels.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    umap_2d = umap.umap_.UMAP(n_components=2, random_state=0)\n",
    "    umap_2d.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    projections_umap = umap_2d.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-rendering",
   "metadata": {},
   "source": [
    "####  Visualisation avec plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    fig = px.scatter(#_3d(\n",
    "        projections_umap, x=0, y=1, # z=2,\n",
    "        color=labels\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-victory",
   "metadata": {},
   "source": [
    "#### Visualisation interactive avec Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not book:\n",
    "    plot_feature_space_with_images(classes, images, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
