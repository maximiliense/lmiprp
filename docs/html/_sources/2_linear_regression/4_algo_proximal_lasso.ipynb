{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "urban-envelope",
   "metadata": {},
   "source": [
    "# Sous-différentiel et le cas du Lasso ☕️☕️☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-robinson",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-truck",
   "metadata": {},
   "source": [
    "Soit $X\\in\\mathbb{R}^{n\\times d}$ et $\\boldsymbol{y}=\\mathbb{R}^n$. De manière assez directe, le problème des moindres carrés se formule de la manière suivante :\n",
    "\n",
    "$$\\beta^\\star=\\text{argmin}_{\\beta\\in\\mathbb{R}^d}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2^2.$$\n",
    "\n",
    "Supposons que $X^TX$ soit inversible. Alors, en annulant le gradient, on obtient :\n",
    "\n",
    "$$\\beta^\\star=(X^TX)^{-1}X^T\\boldsymbol{y}.$$\n",
    "\n",
    "Si nous avions souhaité minimiser notre fonction objectif via une descente de gradient (par exemple dans le cas où $X^TX$ n'est pas inversible ou si le coût de son inversion est trop important), alors le gradient à utiliser est :\n",
    "\n",
    "$$\\nabla (\\lVert X\\beta-\\boldsymbol{y}\\rVert_2)=2X^TX-2X^t\\boldsymbol{y}.$$\n",
    "\n",
    "Cependant, comme nous l'avons vu dans une séquence précédente, il est parfois préférable de \"régulariser\" ce problème d'optimisation de manière à obtenir un vecteur $\\beta^\\star$ généralisant mieux à de nouveaux exemples d'apprentissage en machine learning ou offrant plus de stabilité. Le cas de la régularisation $\\lVert\\cdot\\rVert_1$ dit $\\ell_1$, qu'on appelle Lasso, est intéressant car il permet de faire de la sélection de variables. En effet, le vecteur $\\beta^\\star$ obtenu après minimisation est sparse.\n",
    "\n",
    "Rappelons que la norme $\\ell_1$ se définie de la manière suivante :\n",
    "\n",
    "$$\\lVert x \\rVert_1=\\sum_i |x_i|.$$\n",
    "\n",
    "Le problème régularisé peut donc se reformuler de la manière suivante :\n",
    "\n",
    "$$\\beta^\\star=\\text{argmin}_{\\beta\\in\\mathbb{R}^d}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2^2+\\lambda \\lVert \\beta\\rVert_1,$$\n",
    "\n",
    "où $\\lambda\\geq0$ contrôle la quantité de régularisation.\n",
    "\n",
    "Le problème ici est que $\\lVert \\beta\\rVert_1$ n'est pas différentiable partout - la valeur absolu n'est pas dérivable en $0$. On aurait pu se dire que ce n'est pas un problème et que notre descente de gradient aurait à coup sûr \"sauté\" les points non-différentiables, mais ces derniers s'avèrent justement être solution de notre problème : c'est le côté sparse. Nous allons, dans cette séquence introduire quelques éléments permettant d'aborder ce problème : le sous-différentiel.\n",
    "\n",
    "\n",
    "À la fin de cette séquence, nous dériverons un algorithme permettant d'obtenir la solution du problème d'optimisation Lasso !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-baptist",
   "metadata": {},
   "source": [
    "## I. Quelques bases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-mainland",
   "metadata": {},
   "source": [
    "Nous allons ici introduire quelques éléments mathématiques permettant de dériver les algorithmes d'optimisation voulus. Tout d'abord, soit $f:\\mathbb{R}\\mapsto\\mathbb{R}$ une fonction dérivable, alors sa tangente en $a$ a pour équation :\n",
    "\n",
    "$$t(x)=f(a)+f^\\prime(a)(x-a).$$\n",
    "\n",
    "Si $f$ est convexe, alors $f(y)\\geq t(x),\\ \\forall x, y\\in\\mathbb{R}$. Rappelons que la convexité d'une fonction $f$ nous indique que $\\forall x,y\\in\\mathbb{R},\\ \\lambda\\in [0, 1]$, on a :\n",
    "\n",
    "$$f(\\lambda x+(1-\\lambda)y)\\leq \\lambda f(x)+(1-\\lambda)f(y).$$\n",
    "\n",
    "### La sous-dérivée\n",
    "L'idée de la sous-dérivée est de pouvoir généraliser l'idée que la dérivée contrôle la tangente dans le cas d'une fonction convexe. Soit $f$ une fonction convexe, $s$ est une sous dérivée de $f$ en $a$ si :\n",
    "\n",
    "$$f(x) \\geq f(a)+s(x-a),\\ \\forall x\\in\\mathbb{R}.$$\n",
    "\n",
    "La sous-dérivée n'est pas forcément unique en un point $a$ et on appelle sous-différentiel l'ensemble des sous-dérivés qu'on note $\\partial f(a)$. Cependant, si $f$ est différentiable en $a$, alors $\\partial f(a)=\\{f^\\prime(a)\\}$. On observe assez rapidement que si $f$ est concave au voisinage de $a$, alors elle n'admet pas de sous-dérivée : $\\partial f(x)=\\emptyset$.\n",
    "\n",
    "La figure suivante illustre quelques sous-dérivées pour les fonctions $f(x)=|x|$ et $g(x)=x^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-2, 2, 101)\n",
    "\n",
    "\n",
    "y = np.abs(x)\n",
    "sub_gradient = np.stack([0.9*x, 0.3*x, -0.3*x, -0.7*x])\n",
    "\n",
    "x = np.tile(x, (4, 1))\n",
    "\n",
    "plt.figure(figsize=(16.0, 8.0))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x[0], y, label='$f(x)=|x|$')\n",
    "lines = plt.plot(x.T, sub_gradient.T, \n",
    "                 label=r'$t_s(x)=\\langle s, x\\rangle$, $s$ sous-dérivée', color='gray', alpha=0.5)\n",
    "plt.setp(lines[1:], label=\"_\")\n",
    "\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "plt.gca().spines['left'].set_position('center')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['bottom'].set_position('center')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().xaxis.set_ticks_position('bottom')\n",
    "plt.gca().yaxis.set_ticks_position('left')\n",
    "\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.plot(x[0], x[0]**2, label='$g(x)=x^2$')\n",
    "y = 0.5**2 + 2*0.5*(x[0]-0.5)\n",
    "plt.plot(x[0], y, color='gray', alpha=0.5, label='Tangente')\n",
    "plt.gca().spines['left'].set_position('center')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['bottom'].set_position('center')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().xaxis.set_ticks_position('bottom')\n",
    "plt.gca().yaxis.set_ticks_position('left')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-scanning",
   "metadata": {},
   "source": [
    "On observe bien l'infinité des sous-dérivées de la valeur absolue en $0$ et l'unicité en tout point pour la fonction $x^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-bumper",
   "metadata": {},
   "source": [
    "Un certain nombre de règles de calcul usuelles se généralisent assez bien à ce nouveau concept. Soit $f, g$ deux fonctions et un scalaire $\\alpha$, nous avons:\n",
    "\n",
    "$$\\partial (\\alpha(f+g))=\\alpha\\partial f+\\alpha \\partial g.$$\n",
    "\n",
    "Soit $f$ une fonction dérivable et soit le problème d'optimisation suivant :\n",
    "\n",
    "$$x^\\star=\\text{argmin}_{x\\in\\mathbb{R}}f(x).$$\n",
    "\n",
    "La condition d'optimalité du premier ordre, dit de Fermat, nous donne l'équivalence suivante :\n",
    "\n",
    "$$x^\\star\\text{ est un minimum local}\\Leftrightarrow f^\\prime(x^\\star)=0.$$\n",
    "\n",
    "Si $f$ est convexe, alors $x^\\star$ est un minimum global. Qu'en est-il dans le cas où $f$ n'est pas dérivable en $x^\\star$ mais sous-différentiable ? Supposons $f$ convexe. On a :\n",
    "\n",
    "$$x^\\star\\text{ est un minimum global}\\Leftrightarrow 0\\in\\partial f(x^\\star).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-windsor",
   "metadata": {},
   "source": [
    "Lorsqu'on considère des fonctions de $\\mathbb{R}^n$ dans $\\mathbb{R}$, alors les principes précédents se généralisent. On parle alors de sous-gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-search",
   "metadata": {},
   "source": [
    "## II. L'algorithme d'optimisation proximal et son application au Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-germany",
   "metadata": {},
   "source": [
    "Reprenons le problème d'optimisation régularisé suivant :\n",
    "\n",
    "$$\\beta^\\star=\\text{argmin}_{\\beta\\in\\mathbb{R}^d}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2+\\lambda \\lVert \\beta\\rVert_1 = f(\\beta)+g(\\beta),$$\n",
    "\n",
    "où $f$ et $g$ sont des fonctions convexes, $f$ une fonction différentiable.\n",
    "\n",
    "Une stratégie d'optimisation de ce problème est ce qu'on appelle l'algorithme *proximal*. Ce dernier découpe chaque pas d'optimisation en deux étapes. La première consiste à optimiser $f$ en suivant son gradient (comme dans la descente de gradient). La seconde étape consiste à \"optimiser $g$ dans le voisinage du point précédemment obtenu\" :\n",
    "\n",
    "$$\\text{pas d'optimisation : }\\begin{cases}u^{(t+1)}&=\\beta^{(t)}-\\gamma\\nabla f(\\beta^{(t)})\\\\\n",
    "\\beta^{(t+1)}&=\\textbf{prox}_{\\gamma g}(u^{(t+1)})\\end{cases}$$\n",
    "\n",
    "Cette algorithme s'appuie sur un opérateur qu'on appelle \"l'opérateur proximal\" :\n",
    "\n",
    "$$\\textbf{prox}_{\\gamma g}(u)=\\text{argmin}_y\\big\\{g(y)+\\frac{1}{2\\gamma}\\lVert y-u\\rVert_2^2\\big\\}.$$\n",
    "\n",
    "On cherche à minimiser $g$ depuis un point $u$ en gardant la distance $\\ell_2$ au carré faible.\n",
    "\n",
    "**La pénalité $\\ell_1$ du Lasso et l'opérateur proximal :** Soit $g(x)=\\lambda \\lVert x\\rVert_1$. On cherche donc à trouver un point d'annulation de la sous-différentielle de la fonction objectif de notre opérateur proximal. On a donc :\n",
    "\n",
    "$$\\textbf{prox}_{\\gamma g}(u)=\\textbf{prox}_{\\gamma \\lambda \\lVert \\cdot\\rVert_1}(u),$$\n",
    "\n",
    "et en calculant la différentielle, nous obtenons :\n",
    "\n",
    "$$\\partial(\\lVert y\\rVert_1+\\frac{1}{2\\lambda\\gamma}\\lVert y-u\\rVert_2^2)=\\partial \\lVert y\\rVert_1+\\frac{1}{2\\lambda\\gamma}\\partial \\lVert y-u \\rVert_2^2=\\partial \\lVert y\\rVert_1+\\Big\\{\\frac{y-u}{\\lambda\\gamma}\\Big\\}.$$\n",
    "\n",
    "Le problème est séparable et peut être considéré coordonnée par coordonnée :\n",
    "\n",
    "$$(\\partial \\lVert y\\rVert_1)_i=\\begin{cases}1&\\text{ si }y_i>0\\\\ [-1, 1]&\\text{ si }y_i=0\\\\ -1&\\text{ sinon.}\\end{cases}$$\n",
    "\n",
    "En combinant les deux sous-différentielles, et en traitant les deux problèmes coordonnée par coordonnée, nous obtenons :\n",
    "\n",
    "$$\\partial(\\lVert y\\rVert_1+\\frac{1}{2\\lambda\\gamma}\\lVert y-u\\rVert_2^2)=\\begin{cases}1+\\frac{y_i-u_i}{\\lambda\\gamma}&\\text{ si }y_i>0\\\\ \\Big[-1+\\frac{y_i-u_i}{\\lambda\\gamma}, 1+\\frac{y_i-u_i}{\\lambda\\gamma}\\Big]&\\text{ si }y_i=0\\\\ -1+\\frac{y_i-u_i}{\\lambda\\gamma}&\\text{ si }y<0.\\end{cases}$$\n",
    "\n",
    "Notre objectif est de trouver $y_i$ tel que $0\\in\\partial(\\lVert y\\rVert_1+\\frac{1}{2\\lambda\\gamma}\\lVert y-u\\rVert_2^2)$. Trois scénarios sont possibles. Tout d'abord :\n",
    "\n",
    "$$0=1+\\frac{y_i-u_i}{\\lambda\\gamma}\\text{ et }y_i>0\\Leftrightarrow y_i=u_i-\\lambda\\gamma\\text{ et }u_i>\\lambda\\gamma.$$\n",
    "\n",
    "Les deux autres scénarios se construisent exactement de la même manière. On obtient au final :\n",
    "\n",
    "$$\\textbf{prox}_{\\gamma \\lambda \\lVert \\cdot\\rVert_1}(u)_i=\\begin{cases}u_i-\\lambda\\gamma&\\text{ si }u_i>\\lambda\\gamma\\\\ u_i+\\lambda\\gamma&\\text{ si } u_i<-\\lambda\\gamma\\\\ 0&\\text{ si }u_i\\in[-\\lambda\\gamma,\\lambda\\gamma].\\end{cases}$$\n",
    "\n",
    "**La fonction objectif non régularisée du Lasso :** Soit $f(\\beta)=\\lVert X\\beta-y\\rVert_2^2$. On a comme nous l'avons déjà vu plusieurs fois :\n",
    "\n",
    "$$\\nabla f(\\beta)=(X^TX)\\beta-X^Ty.$$\n",
    "\n",
    "**L'algorithme proximal appliqué au Lasso :** Soit le problème Lasso suivant : \n",
    "\n",
    "$$\\beta^\\star=\\text{argmin}_{\\beta\\in\\mathbb{R}^d}\\lVert X\\beta-\\boldsymbol{y}\\rVert_2+\\lambda \\lVert \\beta\\rVert_1 = f(\\beta)+g(\\beta).$$\n",
    "\n",
    "L'algorithme proximal est ainsi un algorithme d'optimisation qui réalise une suite de pas d'optimisation. Un pas d'optimisation est construit de la manière suivante : \n",
    "\n",
    "$$\\text{pas d'optimisation : }\\begin{cases}u^{(t+1)}&=\\beta^{(t)}-\\gamma\\nabla f(\\beta^{(t)})\\\\\n",
    "\\beta^{(t+1)}&=\\textbf{prox}_{\\gamma \\lambda \\lVert \\cdot\\rVert_1}(u^{(t+1)})\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-fourth",
   "metadata": {},
   "source": [
    "## III. mise en pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-breach",
   "metadata": {},
   "source": [
    "### Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_beta = np.array([[8.], [-1.]])\n",
    "\n",
    "def construct_dataset(n):\n",
    "    global real_beta\n",
    "    X = np.random.normal(0, 1, size=(n, 2))\n",
    "    X[:, 0] += 2\n",
    "    y = np.dot(X, real_beta) + np.random.normal(0, 1, size=(n, 1))\n",
    "    return X, y\n",
    "X, y = construct_dataset(5)\n",
    "lambda_ = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-liverpool",
   "metadata": {},
   "source": [
    "### Les fonctions à optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-checkout",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant évaluer la formule :**\n",
    "\n",
    "$$\\frac{1}{2}\\lVert X\\beta-y \\rVert_2^2.$$\n",
    "\n",
    "**On appellera cette fonction $\\texttt{main}\\_\\texttt{objective}$.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_objective(X, y, beta):\n",
    "    ####### Complete this part ######## or die ####################\n",
    "    vector = np.dot(X, beta)-y\n",
    "    square = np.dot(vector.T, vector)\n",
    "    return 0.5*square/X.shape[0]\n",
    "    ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-amazon",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant évaluer la formule :**\n",
    "\n",
    "$$\\lambda\\lVert \\beta\\rVert_1.$$\n",
    "\n",
    "**On appellera cette fonction $\\texttt{penalty}$.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penality(beta, lambda_):\n",
    "    ####### Complete this part ######## or die ####################\n",
    "    l1 = np.abs(beta).sum()\n",
    "    return l1*lambda_\n",
    "    ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-gabriel",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **En utilisant les deux fonctions précédentes, donnez le code permettant d'évaluer la formule :**\n",
    "\n",
    "$$\\frac{1}{2}\\lVert X\\beta-y \\rVert_2^2+\\lambda\\lVert \\beta\\rVert_1.$$\n",
    "\n",
    "**On appellera cette fonction $\\texttt{loss}$.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y, beta, lambda_):\n",
    "    ####### Complete this part ######## or die ####################\n",
    "    l1 = np.abs(beta).sum()\n",
    "    return main_objective(X, y, beta)+penality(beta, lambda_)\n",
    "    ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-screw",
   "metadata": {},
   "source": [
    "Le code suivant permet d'afficher la fonction ou ses composantes qu'on cherche à optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(title, obj='loss', param_trace=None, lambda_=lambda_):\n",
    "    plt.figure(figsize=(12.0, 8.0))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    delta = 0.1\n",
    "    x_range = np.arange(-20.0, 20.0+delta, delta)\n",
    "    y_range = np.arange(-20.0, 20.0+delta, delta)\n",
    "    XX, YY = np.meshgrid(x_range, y_range)\n",
    "\n",
    "    ZZ = np.zeros(XX.shape)\n",
    "    for i in range(XX.shape[0]):\n",
    "        for j in range(XX.shape[1]):\n",
    "            if obj == 'loss':\n",
    "                ZZ[i, j] = np.sqrt(loss(X, y, np.array([[XX[i, j]], [YY[i, j]]]), lambda_))\n",
    "            elif obj =='penalty':\n",
    "                ZZ[i, j] = penality(np.array([[XX[i, j]], [YY[i, j]]]), lambda_)\n",
    "            elif obj == 'objective':\n",
    "                ZZ[i, j] = np.sqrt(main_objective(X, y, np.array([[XX[i, j]], [YY[i, j]]])))\n",
    "                \n",
    "\n",
    "    CS = ax.contour(XX, YY, ZZ)\n",
    "    ax.clabel(CS, inline=True, fontsize=10)\n",
    "    # ax.scatter(real_beta[0, :], real_beta[1, :])\n",
    "    ax.set_title(title)\n",
    "    ax.axhline(0, lw=0.5, color='red') # x = 0\n",
    "    ax.axvline(0, lw=0.5, color='red') # y = 0\n",
    "    lines = None\n",
    "    if param_trace is not None:\n",
    "        lines = ax.plot(param_trace[:, 0], param_trace[:, 1], color='blue')\n",
    "    plt.show()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-pearl",
   "metadata": {},
   "source": [
    "On observe clairemant dans l'affichage ci-dessous la non différentiabilité de $\\lVert x\\rVert_1$ en certains endroits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(obj='penalty', title='$\\ell_1$ penalty ($\\\\lambda||\\\\beta||_1$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-forest",
   "metadata": {},
   "source": [
    "À l'inverse, notre objectif principal est clairement \"smooth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(obj='objective', title='$\\\\frac{1}{2}||X\\\\beta-y||_2^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-encyclopedia",
   "metadata": {},
   "source": [
    "Malheureusement, la combinaison des deux rend notre fonction non différentiable en certains endroits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(obj='loss', title='$\\\\frac{1}{2}||X\\\\beta-y||_2^2+\\lambda||\\\\beta||_1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-plane",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **L'algorithme d'optimisation proximal s'appuie sur deux opérations. Le gradient et l'operateur proximal. Complétez les deux fonctions associées ci-dessous.**\n",
    "\n",
    "**Ensuite, proposez la méthode d'optimisation de notre classe $\\texttt{ProximalOptimization}$.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProximalOptimization(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def gradient(self, beta):\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        return (np.dot(np.dot(self.X.T, self.X), beta)-np.dot(self.X.T, self.y))/self.X.shape[0]\n",
    "        ###############################################################\n",
    "    \n",
    "    def gradient_descent_step(self, learning_rate, beta):\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        g = self.gradient(beta)\n",
    "        return beta-learning_rate*g\n",
    "        ###############################################################\n",
    "    \n",
    "    def proxy_step(self, learning_rate, lambda_, u):\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        gamma = lambda_*learning_rate\n",
    "        to_zero = np.abs(u) < gamma\n",
    "        u[to_zero] = 0\n",
    "        neg = u < -gamma\n",
    "        u[neg] = u[neg] + gamma\n",
    "        pos = u > gamma\n",
    "        u[pos] = u[pos] - gamma\n",
    "        return u\n",
    "        ###############################################################\n",
    "        \n",
    "    def optimize(self, learning_rate, beta, lambda_, nb_iterations):\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        param_trace = [np.copy(beta)]\n",
    "        for it in range(nb_iterations):\n",
    "            u = self.gradient_descent_step(learning_rate, beta)\n",
    "            beta = self.proxy_step(learning_rate, lambda_, u)\n",
    "            param_trace.append(np.copy(beta))\n",
    "        return np.array(param_trace)\n",
    "        ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-blood",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Jouez avec les différents paramètres afin d'en observer les effets.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_= 12\n",
    "beta = np.array([[-1], [19]])\n",
    "optim = ProximalOptimization(X, y)\n",
    "param_trace = optim.optimize(0.1, beta, lambda_, 1000)\n",
    "plot(\n",
    "    obj='loss', title='Optimizing $\\\\frac{1}{2}||X\\\\beta-y||_2^2+\\lambda||\\\\beta||_1$', \n",
    "    param_trace=param_trace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-stations",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Question :**</span> **Qu'observez-vous lorsque notre chemin d'optimisation passe trop proche d'un axe ?**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-serve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
