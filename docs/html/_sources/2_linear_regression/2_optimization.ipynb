{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'optimisation ☕️☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette séquence va être de construire des méthodes et des algorithmes permettant de trouver des minimum locaux et/ou globaux de fonctions. Soit $f:\\mathbb{R}^d\\mapsto\\mathbb{R}$, nous souhaitons résoudre (ou du moins sur une partie du domaine de définition de la fonction $f$) le problème suivant :\n",
    "\n",
    "$$x^\\star=\\text{argmin}_{x\\in\\mathbb{R}^d}f(x).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et fonction de plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le code ci-dessous permettra d'afficher notre fonction à optimiser\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_loss_contour(obj_func, param_trace=None, figsize=None, three_dim=False, rotate=12, \n",
    "                      starting=None, title=None):\n",
    "    \n",
    "    x, y = np.mgrid[slice(-5, 5 + 0.1, 0.1),\n",
    "                    slice(-5, 5 + 0.1, 0.1)]\n",
    "    z = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i, j] = obj_func([x[i, j], y[i, j]])\n",
    "    if figsize is not None:\n",
    "        f = plt.figure(figsize=figsize)\n",
    "    else:\n",
    "        f = plt.figure(figsize=(12.0, 8.0))\n",
    "    if three_dim:\n",
    "        ax = f.gca(projection='3d')\n",
    "    else:\n",
    "        ax = f.gca()\n",
    "    \n",
    "    if three_dim:\n",
    "        m = ax.plot_surface(x, y, z, cmap=cm.viridis)\n",
    "    else:\n",
    "        m = ax.contourf(x, y, z, levels = 15)\n",
    "    #\n",
    "    if param_trace is not None:\n",
    "        if three_dim:\n",
    "            eps = 0.5\n",
    "            #ax.scatter(param_trace[:, 0], param_trace[:, 1], param_trace[:, 2] + eps, \n",
    "            #           color='blue', alpha=1)\n",
    "            ax.plot(param_trace[:, 0], param_trace[:, 1], param_trace[:, 2] + eps, \n",
    "                    color='red')\n",
    "            ax.view_init(65, rotate)\n",
    "                \n",
    "        else:\n",
    "            if type(param_trace) is not tuple:\n",
    "                param_trace = [param_trace]\n",
    "            for p in param_trace:\n",
    "                p = np.array(p) if type(p) is list else p\n",
    "                plt.plot(p[:, 0], p[:, 1])\n",
    "                plt.scatter(p[:, 0], p[:, 1])\n",
    "            f.colorbar(m)\n",
    "    if starting is not None:\n",
    "        if three_dim:\n",
    "            z = obj_func(starting)\n",
    "            plt.plot([starting[0], starting[0]], [starting[1], starting[1]], [z, z+0.1], lw=4, \n",
    "                     color='red', label='The start of our optimization')\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plt.scatter(starting[0], starting[1], color='red', \n",
    "                        label='The start of our optimization')\n",
    "            plt.legend()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. La descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons la fonction suivante qui admet plusieurs minimums locaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x, y = x\n",
    "    return np.sqrt((x**2 + y - 11)**2 + (x + y**2 - 7)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_contour(f, three_dim=False, starting=[0, 2], \n",
    "                  title='2D heatmap of the function we want to optimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de la représenter en 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_contour(f, three_dim=True, starting=[4, 4], \n",
    "                  title='3D heatmap of the function we want to optimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit autrement, nous considérons $f:\\mathbb{R}^2\\mapsto\\mathbb{R}$ définie par $f(x, y)=\\sqrt{(x^2+y-11)^2+(x+y^2-7)^2}$. $f$ est continue et infiniment dérivable.\n",
    "\n",
    "Nous avons en particulier les dérivées partielles suivantes : \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial x}(x, y)=\\frac{2x^3+x(2y-21)+y^2-7}{\\sqrt{(x^2+y-11)^2+(x+y^2-7)^2}}\n",
    "\\end{equation}\n",
    "\n",
    "et\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial y}(x, y)=\\frac{x^2+2xy+2y^3-13y-11}{\\sqrt{(x^2+y-11)^2+(x+y^2-7)^2}}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans hypothèse sur la fonction $f$, celle-ci peut être très difficile à minimiser. Soit $x^{(0)}\\in\\mathbb{R}^2$, un algorithme permettant de chercher un minimum local en partant de $x^{(0)}$ est la descente de gradient. Ce dernier suppose que nous avons accès aux informations du premier ordre : le gradient $\\nabla f(x, y)$. Rappelons que le gradient est le vecteur construit à partir des dérivées partielles $\\nabla f (x, y) = [\\partial f(x,y)/\\partial x, \\partial f(x, y)/\\partial y]^T$. Ce dernier donne le sens de la plus forte croissance de la fonction $f$. Son opposé donne la plus forte pente. L'idée de l'algorithme de descente de gradient est de suivre la direction donnée par ce dernier par petits pas. On note $\\boldsymbol{x}=(x,y)$. Nous avons ainsi :\n",
    "\n",
    "$$\\boldsymbol{x}^{(t+1)}=\\boldsymbol{x}^{(t)}-\\eta\\nabla f(\\boldsymbol{x}^{(t)})$$\n",
    "\n",
    "où $\\eta>0$ est justement un paramètre permettant de contrôler la taille du pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant de calculer le gradient de la fonction précédente (en format vecteur ligne).**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x):\n",
    "    ####### Complete this part ######## or die ####################\n",
    "    v = f(x)\n",
    "    x, y = x\n",
    "    return np.array([\n",
    "        (2*x**3+x*(2*y-21)+y**2-7)/v,\n",
    "        (x**2+2*x*y+2*y**3-13*y-11)/v\n",
    "    ])\n",
    "    ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant de calculer une itération de l'algorithme de descente de gradient. Attention, on appelle le pas d'optimisation $\\eta$ le *learning rate*.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    def optimize(self, learning_rate = 0.1, nb_iterations=15, beta=None):\n",
    "        # beta est notre variable ! \n",
    "        # si elle n'est pas fixée on la tire au hasard\n",
    "        if beta is None:\n",
    "            beta = np.random.uniform(-2, 2, size=2)\n",
    "\n",
    "        param_trace = [beta]\n",
    "        loss_trace = [f(beta)]\n",
    "        \n",
    "        for i in range(nb_iterations):\n",
    "            ####### Complete this part ######## or die ####################\n",
    "            beta = beta - learning_rate * grad(beta)\n",
    "            ###############################################################\n",
    "            param_trace.append(beta)\n",
    "            loss_trace.append(f(beta))\n",
    "            \n",
    "        return np.array(param_trace), np.array(loss_trace)\n",
    "        \n",
    "gd = GradientDescent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons un premier résultat d'optimisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, l = gd.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_contour(f, param_trace=p, three_dim=False, \n",
    "                  title='2D heatmap of the function we want to optimize')\n",
    "\n",
    "plot_loss_contour(f, param_trace=np.concatenate([p, l.reshape((l.shape[0], 1))], axis=1), \n",
    "                  three_dim=True,  title='3D heatmap of the function we want to optimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'affichage suivant interactif va nous permettre de tester les différents paramètres de notre optimiseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def interactive_gradient_descent(x, y, learning_rate, iterations):\n",
    "    clear_output()\n",
    "    param_trace , loss_trace = gd.optimize(nb_iterations=iterations,\n",
    "                                           learning_rate=learning_rate, \n",
    "                                           beta=np.array([x, y]))\n",
    "    plot_loss_contour(f, param_trace, figsize=(14.0, 6.0))\n",
    "    \n",
    "widgets.interact(interactive_gradient_descent,\n",
    "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=0.05, step=0.0001, \n",
    "                                                   continuous_update=False, readout_format='.5f'),\n",
    "                 x=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 y=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 iterations=widgets.IntSlider(value=10, min=10, max=500, step=1, continuous_update=False)\n",
    ")\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. La descente de gradient à pas optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le scénario précédent, nous avons du fixer un pas d'optimisation $\\eta$ arbitraire. Ce dernier doit être suffisament petit pour garantir que l'algorithme converge et suffisamment grand pour que l'optimisation se fasse. Il est possible de définir une notion de pas d'optimisation optimal. Cependant, celle-ci est souvent intractable en pratique (trouver le pas est plus couteux que l'optimisation initiale). Dans certains cas, nous pouvons néanmoins le déterminer. C'est ce que nous allons faire ici. Considérons maintenant la fonction suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 0], [0, 2]])\n",
    "b = np.array([[2], [1]])\n",
    "\n",
    "def f(x):\n",
    "    if type(x) is np.ndarray:\n",
    "        x = x.tolist()\n",
    "    return (np.dot(np.dot(A, x).T, x)*0.5+np.dot(b.T, x))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_contour(f, three_dim=False, starting=[0, 2], \n",
    "                  title='2D heatmap of the function we want to optimize')\n",
    "plot_loss_contour(f, three_dim=True, starting=[4, 4], \n",
    "                  title='3D heatmap of the function we want to optimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme de descente de gradient nous permet d'avancer dans la bonne direction. Cependant, le choix du pas $\\eta$ peut nous sembler insuffisant. \n",
    "\n",
    "Soit $\\boldsymbol{\\nu}=[x, y]^T$, la direction d'optimisation $\\boldsymbol{d}^{(t)}=-\\nabla f(\\boldsymbol{\\nu}^{(t)})$ et la fonction $\\gamma:t\\mapsto f(\\boldsymbol{\\nu}^{(t)}+t\\boldsymbol{d}^{(t)})$. La valeur de $t$ qui minimise la fonction $\\gamma$ est un pas optimal pour une minimisation dans la direction du gradient. Sans contrainte particulière sur la fonction $f$, $\\gamma$ pourrait admettre un certain nombre de points critiques de natures et de valeurs différentes.\n",
    "\n",
    "Les points critiques sont les points d'annulation de la dérivée : $\\{t\\in\\mathbb{R}:\\ \\gamma^\\prime(t)=0\\}$. On obtient assez facilement la dérivée de la manière suivante :\n",
    "\n",
    "$$\\gamma^\\prime(t)=\\frac{\\partial f}{\\partial x}(\\boldsymbol{\\nu}^{(t)}+t\\boldsymbol{d}^{(t)})\\frac{\\partial f}{\\partial x}(\\boldsymbol{\\nu}^{(t)})+\\frac{\\partial f}{\\partial y}(\\boldsymbol{\\nu}^{(t)}+t\\boldsymbol{d}^{(t)})\\frac{\\partial f}{\\partial y}(\\boldsymbol{\\nu}^{(t)})$$\n",
    "\n",
    "On remarque que résoudre cette équation est rapidement problématique et nécessite l'utilisation d'un autre algorithme de descente de gradient. En réalité, il y a grossièrement deux possibilités :\n",
    "1. On peut trouver une valeur $t$ analytiquement et c'est le choix qu'on doit faire,\n",
    "2. Il n'est pas possible de calculer $t$ et on doit le calculer numériquement. Cependant, si on doit le calculer numériquement, alors, il devient nécessaire de calculer le gradient à chaque étape, et dans ce cas, pourquoi ne pas juste se déplacer dans l'espace des paramètres avec notre vecteur $\\boldsymbol{[x, y]}$ ce qui nous donnerait une meilleure direction dans l'espace des paramètres...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il se trouve que la fonction définie ci-dessus est : $f(\\boldsymbol{x})=\\frac{1}{2}\\langle Ax, x\\rangle+\\langle b, x\\rangle$ où :\n",
    "\n",
    "\n",
    "$$A=\\begin{bmatrix} 1& 0\\\\ 0& 2\\end{bmatrix}$$\n",
    "\n",
    "est symétrique définie positive et \n",
    "\n",
    "\n",
    "$$b=\\begin{bmatrix}2\\\\1\\end{bmatrix}$$\n",
    "\n",
    "Notons \n",
    "\n",
    "$$\\begin{aligned}\n",
    "f(\\boldsymbol{x}+t\\boldsymbol{d})&=\\frac{1}{2}\\langle A(x+t\\boldsymbol{d}), x+t\\boldsymbol{d}\\rangle+\\langle b, x+t\\boldsymbol{d}\\rangle\\\\\n",
    "&=\\frac{1}{2}(\\langle A\\boldsymbol{x},\\boldsymbol{x}\\rangle+t\\langle A\\boldsymbol{d},\\boldsymbol{x}\\rangle+t\\langle A\\boldsymbol{x},\\boldsymbol{d}\\rangle+t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle)+\\langle \\boldsymbol{b},\\boldsymbol{x}\\rangle+t\\langle \\boldsymbol{b},\\boldsymbol{d}\\rangle\\\\\n",
    "&=f(\\boldsymbol{x})+\\frac{1}{2} t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle+t\\langle A\\boldsymbol{x}+\\boldsymbol{b},\\boldsymbol{d}\\rangle\n",
    "\\end{aligned}$$\n",
    "\n",
    "Notons de plus que $\\partial f(\\boldsymbol{x})/\\partial \\boldsymbol{x}=A\\boldsymbol{x}+\\boldsymbol{b}=-\\boldsymbol{d}$. Nous avons donc :\n",
    "\n",
    "\\begin{equation}\n",
    "f(\\boldsymbol{x}+t\\boldsymbol{d})=f(\\boldsymbol{x})+\\frac{1}{2} t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle-t\\langle \\boldsymbol{d},\\boldsymbol{d}\\rangle=f(\\boldsymbol{x})+\\frac{1}{2} t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle-\\left\\lVert\\boldsymbol{d}\\right\\lVert^2 t\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La direction $\\boldsymbol{d}=-\\nabla f(\\boldsymbol{x})$ est celle qui indique la plus forte pente. La variable $t$ recherchée indique la taille du pas que l'on souhaite faire. Pour cela, nous devons chercher les points critiques de la fonction $\\gamma(t)=f(\\boldsymbol{x}+t\\boldsymbol{d})$ qui sont donnés en recherchant les points d'annulation de la dérivée. De plus, $A$ (la Hessienne) étant définie positive, nous savons que ces points critiques seront des minimums. Nous avons donc :\n",
    "\n",
    "$$\\frac{\\partial \\gamma}{\\partial t}(t)=t\\langle A\\boldsymbol{d}, \\boldsymbol{d}\\rangle - \\left\\lVert\\boldsymbol{d}\\right\\lVert^2=0$$\n",
    "\n",
    "Et le point critique est donné par :\n",
    "\n",
    "$$t=\\frac{\\left\\lVert\\boldsymbol{d}\\right\\lVert^2}{\\langle A\\boldsymbol{d}, \\boldsymbol{d}\\rangle}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant de calculer le gradient (i.e. la direction d'optimisation).**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x):\n",
    "    ####### Complete this part ######## or die ####################\n",
    "    return np.dot(A, x)+b\n",
    "    ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant de calculer une itération de l'algorithme de descente de gradient avec un pas optimal.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalStepGradientDescent(object):\n",
    "    def optimize(self, learning_rate=0.1, nb_iterations=15, beta=None):\n",
    "        if beta is None:\n",
    "            beta = np.random.uniform(-2, 2, size=(2, 1))\n",
    "        else:\n",
    "            beta = beta.reshape((2, 1))\n",
    "            \n",
    "        beta2 = beta.copy()\n",
    "\n",
    "        param_trace = [beta]\n",
    "        param_trace2 = [beta2]\n",
    "        loss_trace = [f(beta)]\n",
    "        loss_trace2 = [f(beta2)]\n",
    "        it = 0\n",
    "        stop = False\n",
    "        \n",
    "        for i in range(nb_iterations):\n",
    "            d = -grad(beta)\n",
    "            if d[0, 0] == d[1, 0] == 0.:\n",
    "                stop = True\n",
    "            else:\n",
    "                ####### Complete this part ######## or die ####################\n",
    "                t = np.linalg.norm(d)**2/np.dot(np.dot(A, d).T, d)\n",
    "                beta = beta + t[0, 0] * d\n",
    "                ###############################################################\n",
    "                \n",
    "                param_trace.append(beta)\n",
    "                loss_trace.append(f(beta))\n",
    "            \n",
    "            # cette partie du code permet de calculer le gradient classique\n",
    "            # afin que nous puissions le comparer avec la descente de gradient\n",
    "            # à pas optimal.\n",
    "            beta2 = beta2 - learning_rate * grad(beta2)\n",
    "            param_trace2.append(beta2)\n",
    "            loss_trace2.append(f(beta2))\n",
    "            it += 1\n",
    "        return (np.array(param_trace), np.array(loss_trace), \n",
    "                np.array(param_trace2), np.array(loss_trace2))\n",
    "        \n",
    "gd = OptimalStepGradientDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def interactive_gradient_descent(learning_rate, x, y, iterations):\n",
    "    clear_output()\n",
    "    p1, l1, p2, l2 = gd.optimize(learning_rate=learning_rate, nb_iterations=iterations,\n",
    "                                           beta=np.array([x, y]))\n",
    "    plot_loss_contour(f, (p1, p2), figsize=(14.0, 6.0))\n",
    "    \n",
    "widgets.interact(interactive_gradient_descent,\n",
    "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=1., step=0.0001, \n",
    "                                                   continuous_update=False, readout_format='.5f'),\n",
    "                 x=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 y=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 iterations=widgets.IntSlider(value=1, min=1, max=20, step=1, continuous_update=False)\n",
    ")\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. La méthode de Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "L'élément de base de la méthode de Newton est le développement limité d'une fonction $f$ en $x_0$. Soit $f\\in C^n(\\mathbb{R})$ une fonction $n$ fois dérivable de dérivée $n^{eme}$ continue de $\\mathbb{R}$ dans $\\mathbb{R}$, son développement limité à l'ordre $n$ est donné par la formule suivante :\n",
    "\n",
    "$$f(x)=\\sum_{i=1}^n \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n+o\\big((x-x_0)^n\\big)$$\n",
    "\n",
    "Ainsi, la tangente à notre fonction au point $x_0$, ou approximation linéaire de notre fonction en $x_0$, est donnée par :\n",
    "\n",
    "$$f(x)\\approx f(x_0)+f^\\prime(x_0)(x-x_0)$$\n",
    "\n",
    "et l'approximation à l'ordre $2$ par :\n",
    "\n",
    "$$f(x)\\approx f(x_0)+f^\\prime(x_0)(x-x_0)+\\frac{f^{\\prime\\prime}(x_0)}{2}(x-x_0)^2$$\n",
    "\n",
    "\n",
    "Ces idées se généralisent à des fonctions $f:\\mathbb{R}^n\\mapsto\\mathbb{R}$ :\n",
    "\n",
    "$$f(x)\\approx f(x_0)+\\langle \\nabla f(x_0), x-x_0\\rangle + \\frac{1}{2} (x-x_0)^TH_f(x-x_0)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La méthode\n",
    "Soit $f:\\mathbb{R}\\mapsto\\mathbb{R}$ une fonction deux fois dérivables de dérivée seconde continue, l'objectif de la méthode de Newton est de minimiser $f$ :\n",
    "\n",
    "$$\\min_{x\\in\\mathbb{R}}f(x)$$\n",
    "\n",
    "Supposons de plus $f$ strictement convexe. Cette minimisation est séquentielle est produit une suite d'itérés $\\{x_0, x_1, ..., x_k\\}$ où $x_0$ est notre point de départ. chaque itéré se rapproche un peu plus du minimiseur recherche $x^\\star$.\n",
    "\n",
    "À chaque itérée, l'approximation à l'ordre $2$ de $f$ est elle-même une fonction (strictement) convexe et coercive. Elle admet donc un minimum que l'on peut trouver en annulant la dérivée :\n",
    "\n",
    "$$f(x_k+t)\\approx f(x_k)+f^\\prime(x_k)t+\\frac{f^{\\prime\\prime}(x_k)}{2}t^2$$\n",
    "\n",
    "On a donc :\n",
    "\n",
    "$$\\frac{d}{dt}(f(x_k)+f^\\prime(x_k)t+\\frac{f^{\\prime\\prime}(x_k)}{2}t^2)=f^\\prime(x_k)+f^{\\prime\\prime}(x_k)t=0\\Leftrightarrow t=-\\frac{f^\\prime(x_k)}{f^{\\prime\\prime}(x_k)}$$\n",
    "\n",
    "Ce qui nous permet de fixer l'itéré suivant : $x_{k+1}=x_k-f^\\prime(x_k)/f^{\\prime\\prime}(x_k)$.\n",
    "\n",
    "Cette méthode se généralise bien sûr à des fonctions à plusieurs variables comme nous allons le voir lors d'une autre section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons la fonction suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.power(x-0.85, 2) + 12+np.power(x, 4)+np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(x_start, optimization_steps=None):\n",
    "    x = np.linspace(-3, 3, 301)\n",
    "    plt.figure(figsize=(12.0, 8.0))\n",
    "    plt.plot(x, f(x), label='Function $f$')\n",
    "    plt.scatter([x_start], f(x_start), label='Optimization starting point')\n",
    "    if optimization_steps is not None:\n",
    "        plt.scatter(optimization_steps[:, 0], optimization_steps[:, 1], \n",
    "                    color='blue', label='Optimization steps')\n",
    "    plt.title('Notre fonction $f$')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_curve(x_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant de calculer une itération de la méthode d'optimisation de Newton. Jouez ensuite avec l'affichage interactif.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_prime(x):\n",
    "    return 2*x-1.7+4*x**3+np.exp(x)\n",
    "\n",
    "def f_prime_prime(x):\n",
    "    return 2+12*x**2+np.exp(x)\n",
    "\n",
    "class NewtonMethod(object):\n",
    "    def optimize(self, x_start, nb_iterations=15):\n",
    "        \n",
    "        \n",
    "\n",
    "        optimization_steps = []\n",
    "        x_t = x_start\n",
    "        \n",
    "        for i in range(nb_iterations):\n",
    "            ####### Complete this part ######## or die ####################\n",
    "            x_t = x_t - f_prime(x_t)/f_prime_prime(x_t)\n",
    "            ###############################################################\n",
    "            \n",
    "            optimization_steps.append([x_t, f(x_t)])\n",
    "            \n",
    "        return np.array(optimization_steps)\n",
    "        \n",
    "newton = NewtonMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def interactive_gradient_descent(x, iterations):\n",
    "    clear_output()\n",
    "    optimization_steps = newton.optimize(x, nb_iterations=iterations)\n",
    "    plot_curve(x, optimization_steps)\n",
    "    \n",
    "widgets.interact(interactive_gradient_descent,\n",
    "                 x=widgets.FloatSlider(value=-3, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 iterations=widgets.IntSlider(value=1, min=1, max=10, step=1, continuous_update=False)\n",
    ")\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. La descente de coordonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descente de coordonnées ou *coordinate descent* consiste à optimiser une fonction multivariée variable par variable. Soit $f:\\mathbb{R}^d\\mapsto\\mathbb{R}$ et le problème d'optimisation suivant :\n",
    "\n",
    "$$x^\\star=\\text{argmin}_{x\\in\\mathbb{R}^d}f(x).$$\n",
    "\n",
    "Contrairement à la descente de gradient classique, ici, lors d'une étape d'optimisation, une unique variable est mise à jour à la fois : \n",
    "\n",
    "$$x^{(t)}_i=\\text{argmin}_{x\\in\\mathbb{R}}f(x^{(t)}_1,\\ldots, x_{i-1}^{(t)}, x, x_{i+1}^{(t-1)}, \\ldots, x_d^{(t-1)}).$$\n",
    "\n",
    "Considérons la fonction à deux variables suivantes : $f(x, y)=5x^2-6xy+5y^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 5*np.power(x[0], 2)-6*x[0]*x[1]+5*np.power(x[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_contour(f, three_dim=False, starting=[0, 2], \n",
    "                  title='2D heatmap of the function we want to optimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons $g_y(x)=f(x, y)$ comme une fonction de $x$ uniquement (i.e. $y$ est fixé) et dérivons :\n",
    "\n",
    "$$g_y^\\prime(x)=10x-6y.$$\n",
    "\n",
    "Ainsi, l'itéré suivant pour la variable $x$ s'obtient de la manière suivante : $x^{(t)}=x^{(t-1)}-\\eta g_y^\\prime(x^{(t-1)})$. Le même raisonement s'étend de manière totalement symétrique pour obtenir l'itéré de la variable $y$ (remarquez que $f(x, y)= f(y, x)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Donnez le code permettant de calculer une itération de la méthode *coordinate descent*.**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordinateDescent(object):\n",
    "    def optimize(self, x_start, nb_iterations=15, learning_rate=0.01):\n",
    "        optimization_steps = [np.copy(x_start)]\n",
    "        x_t = x_start\n",
    "        \n",
    "        for i in range(nb_iterations):\n",
    "            ####### Complete this part ######## or die ####################\n",
    "            x_t[0]=x_t[0]-learning_rate*(10*x_t[0]-6*x_t[1])\n",
    "            ###############################################################\n",
    "\n",
    "            optimization_steps.append(np.copy(x_t))\n",
    "            \n",
    "            ####### Complete this part ######## or die ####################\n",
    "            x_t[1]=x_t[1]-learning_rate*(10*x_t[1]-6*x_t[0])\n",
    "            ###############################################################\n",
    "            \n",
    "            optimization_steps.append(np.copy(x_t))\n",
    "\n",
    "            \n",
    "        return np.array(optimization_steps)\n",
    "        \n",
    "coordinate = CoordinateDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def interactive_gradient_descent(learning_rate, x, y, iterations):\n",
    "    clear_output()\n",
    "    param_trace = coordinate.optimize(x_start=np.array([x, y]),\n",
    "                                      nb_iterations=iterations,\n",
    "                                      learning_rate=learning_rate)\n",
    "    plot_loss_contour(f, param_trace, figsize=(14.0, 6.0))\n",
    "    \n",
    "widgets.interact(interactive_gradient_descent,\n",
    "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=0.1, step=0.0001, \n",
    "                                                   continuous_update=False, readout_format='.5f'),\n",
    "                 x=widgets.FloatSlider(value=-2, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 y=widgets.FloatSlider(value=-2, min=-4, max=4, step=0.1, continuous_update=False),\n",
    "                 iterations=widgets.IntSlider(value=1, min=1, max=20, step=1, continuous_update=False)\n",
    ")\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
