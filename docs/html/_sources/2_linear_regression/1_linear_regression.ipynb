{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La régression linéaire ☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques liens pour aller plus loin :\n",
    "* [Overfitting](https://github.com/maximiliense/lmpirp/blob/main/Notes/Overfitting.pdf)\n",
    "* [Regularization](https://github.com/maximiliense/lmpirp/blob/main/Notes/Regularization.pdf)\n",
    "* [Least square QR decomposition](https://github.com/maximiliense/lmpirp/blob/main/Notes/D_composition_QR_et_les_moindres_carr_s.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression linéaire est un modèle cherchant à établir un lien linéaire entre des données d'observation et des données à prédire. Plus concrètement, les données observées sont décrites par un vecteur $\\mathbf{x} \\in \\mathbb{R}^d$ et la variable à prédire, par une quantité scalaire (un réel) $y \\in \\mathbb{R}$ (par un abus de langage important, $\\mathbf{x}$ et $y$ expriment à la fois une variable aléatoire et sa réalisation) et le lien s'exprime sous le format suivant :\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\beta_0 +  x_1 \\beta_1 + x_2 \\beta_2 + x_3 \\beta_3 + ... + x_d \\beta_d +\\epsilon = \\beta_0 + \\sum_i^d x_i \\beta_i+\\epsilon,\\ \\epsilon\\sim\\mathcal{N}(0, \\sigma)\n",
    "\\end{equation}\n",
    "\n",
    "que l'on peut aussi écrire en notation vectorielle:\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\beta_0  + \\langle \\boldsymbol{\\beta}, \\mathbf{x} \\rangle +\\epsilon,\\ \\epsilon\\sim\\mathcal{N}(0, \\sigma)\n",
    "\\end{equation}\n",
    "\n",
    "où $\\boldsymbol{\\beta} \\in \\mathbb{R}^d$ et $\\beta_0\\in\\mathbb{R}$ correspondent respectivement au vecteur et au scalaire contenant les paramètres du \"vrai\" modèle qui défini le lien entre les données et que l'on va vouloir apprendre pour prédire la bonne valeur de $y$ en fonction du vecteur $\\mathbf{x}$. Le modèle linéaire ne peut prédire la variable $y$ qu'à un bruit $\\epsilon$ près. Une fois ces paramètres appris par notre algorithme d'apprentissage, on pourra utiliser la fonction de prédiction $f_{\\boldsymbol{\\beta}}(\\mathbf{x}) : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ apprise pour prédire la valeur $y_{new}$ associée à un nouveau vecteur $\\mathbf{x_{new}}$ que l'on n'a pas encore observé:\n",
    "\n",
    "\n",
    "$$\\hat{y}_{new} = f_{\\boldsymbol{\\beta}}(\\boldsymbol{x_{new}}) = \\beta_0  + \\langle \\boldsymbol{\\beta}, \\boldsymbol{x_{new}} \\rangle$$\n",
    "\n",
    "Pour simplifier les calculs et les notations, on préfère que la fonction de prédiction puisse se calculer à partir d'une notation complètement vectorielle. C'est ce que l'on fait en pratique, en ajoutant une composante supplémentaire $x_0$ au vecteur $\\mathbf{x}$ égale à $1$:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{x} &= \\begin{bmatrix}\n",
    "          1 \\\\\n",
    "           x_{1} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{d}\n",
    "         \\end{bmatrix},\n",
    "\\end{align}\n",
    "\n",
    "de sorte à ce que la fonction de prédiction linéaire puisse s'exprimer simplement sous la forme du produit scalaire: \n",
    "\n",
    "\\begin{align}\n",
    "    f_{\\boldsymbol{\\beta}}(\\mathbf{x}) &= \\langle \\boldsymbol{\\beta}, \\mathbf{x} \\rangle &=\n",
    "          \\begin{bmatrix}\n",
    "           \\beta_{0} \\\\           \n",
    "           \\vdots \\\\\n",
    "           \\beta_{d}\n",
    "          \\end{bmatrix}^T\n",
    "          \\begin{bmatrix}\n",
    "           1 \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{d}\n",
    "         \\end{bmatrix} &= \\sum_{i=0}^d x_i \\beta_i=\\langle \\boldsymbol{x}, \\boldsymbol{\\beta}\\rangle_{\\mathbb{R}^{d+1}}\n",
    "\\end{align}\n",
    "\n",
    "où cette fois $\\boldsymbol{\\beta} \\in \\mathbb{R}^{d+1}$, $\\boldsymbol{x} \\in \\mathbb{R}^{d+1}$ et $\\langle \\cdot, \\cdot\\rangle_{\\mathbb{R}^{d+1}}$ est le produit scalaire dans $\\mathbb{R}^{d+1}$. Le but d'un algorithme d'apprentissage sera de trouver un estimateur $\\boldsymbol{\\hat{\\beta}}$ de $\\boldsymbol{\\beta}$ à partir d'un ensemble fini de $n$ exemples d'apprentissage $(\\boldsymbol{x}, \\langle \\boldsymbol{\\beta}, \\boldsymbol{x} \\rangle + \\epsilon) \\in \\mathbb{R}^2$ préalablement collectés. On notera $\\mathcal{S}=\\{(\\boldsymbol{x_i}, y_i)\\}_{i\\leq n}$ le jeu de données.\n",
    "\n",
    "Nous commencerons par implémenter le cas simple d'une régréssion linéaire à une seule variable d'entrée et une seule variable de sortie qui pourra donc s'écrire sous la forme :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = f_{\\boldsymbol{\\beta}}(\\mathbf{x}) = \\beta_0  + \\beta_1 x\n",
    "\\end{equation}\n",
    "\n",
    "C'est à dire une \"brave\" fonction affine dont on pourra afficher la représentation graphique (une droite) sur une figure en 2 dimensions. Par la suite vous aurez donc à implémenter le calcul de la fonction de coût du modèle sur l'ensemble d'apprentissage, le calcul du gradient de cette fonction de coût ainsi que l'algorithme de descente de gradient qui, à partir du gradient, permet d'obtenir le vecteur $\\hat{\\beta}$.\n",
    "\n",
    "La seconde partie de ce notebook étendra ces notions à des concepts plus compliqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Construction d'un jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons tout d'abord par simuler notre jeu de données avec le modèle génératif suivant :\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{x} \\sim \\mathcal{N}(\\mu, \\sigma) \\in \\mathbb{R}\n",
    "\\end{equation}\n",
    "\n",
    "ou $\\sigma$ correspond à la variance de la variable explicative. Nous choissons une règle arbitraire pour générer aléatoirement les paramètres du \"vrai\" modèle :\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\beta} \\sim \\mathbb{U}(-1, 1)^2 \\in \\mathbb{R}^2\n",
    "\\end{equation}\n",
    "\n",
    "où $\\mathbb{U}^2$ est la loi uniforme dans $\\mathbb{R}^2$. Enfin, le bruit est construit de la manière suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "\\epsilon \\sim \\mathcal{N}(0, 1).\n",
    "\\end{equation}\n",
    "\n",
    "Chaque exemple d'apprentissage correspond donc à un couple de réels $(x_j, y_j = \\beta_0  + \\beta_1 x_j + \\epsilon) \\in \\mathbb{R}^2$. Le code ci dessous construit et affiche le jeux de données ainsi que la représentation graphique de $f(x)=\\beta_1x+\\beta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# on simule le vecteur de parametre\n",
    "beta = np.random.uniform(-1, 1, size=(2,1))\n",
    "\n",
    "# on construit un jeu de donnees de 10 points selon la methode \n",
    "# decrite ci-dessus.\n",
    "def sample_data(n, sigma=5, add_noise=True):\n",
    "    X = np.random.normal(0, sigma, size=n)\n",
    "    noise = np.random.normal(0, 1, size=n)*(add_noise*1)\n",
    "    y = beta[1] * X + noise + beta[0]\n",
    "    return X, y\n",
    "\n",
    "X, y = sample_data(10, add_noise=True)  # jouer avec le bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configuration generale de matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# plot de la fonction\n",
    "def plot(X, y, beta=None, func=None):\n",
    "    eps = 0.1\n",
    "    plt.scatter(X, y)\n",
    "    ymin_ = y.min() - eps\n",
    "    ymax_ = y.max() - eps\n",
    "    min_ = X.min() - eps\n",
    "    max_ = X.max() + eps\n",
    "    if beta is not None or func is not None:\n",
    "        x_ = np.linspace(min_, max_, 500)\n",
    "        if func is None:\n",
    "            y_ = beta[1] * x_ + beta[0]\n",
    "            plt.plot(x_, y_)\n",
    "        else:\n",
    "            func = [(func, '')] if type(func) is not list else func\n",
    "            disp_legend = False\n",
    "            for t in func:\n",
    "                y_ = t[0](x_.reshape((x_.shape[0], 1)))\n",
    "                plt.plot(x_, y_, label=t[1])\n",
    "                disp_legend = disp_legend or t[1] != ''\n",
    "            if disp_legend:\n",
    "                plt.legend()\n",
    "\n",
    "    plt.xlim((min_, max_))\n",
    "    plt.ylim((ymin_, ymax_))\n",
    "    plt.show()\n",
    "    \n",
    "# on plot le dataset precedent\n",
    "plot(X, y, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Que se passe-t-il si le bruit $\\epsilon$ est nul ? Quelle est alors la méthode la plus rapide pour trouver les paramètres du vrai modèle ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:green\">Réponse:</span>** Prenons le cas d'une régression $f_\\beta:\\mathbb{R}\\mapsto\\mathbb{R}$. Si le bruit $\\epsilon$ est nul, alors l'ensemble des couples $(x, y)$ sont alignés sur la même droite. Ainsi, étant donné un jeu de données de taille $2$, $(x_1, y_1)$ et $(x_2, y_2)$ tel que $x_1\\neq x_2$, nous pouvons calculer le coefficient directeur de la droite, noté $\\beta_1$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta_1=\\frac{y_2-y_1}{x_2-x_1}\n",
    "\\end{equation}\n",
    "\n",
    "Le coefficient directeur obtenu, nous pouvons calculer le biais $\\beta_0$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta_0=y_1-\\beta_1x_1.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Du modèle statistique à l'optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La fonction objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons en pratique trouver un paramêtre $\\boldsymbol{\\hat{\\beta}}$ qui minimise le risque du modèle, c'est-à-dire la quantité d'erreur en espérance de n'importe quel modèle $\\boldsymbol{\\beta}$. On notera $\\boldsymbol{\\beta}^\\star$ le \"vrai\" modèle, soit celui qui minimise le risque en espérance. Pour la régression linéaire, on peut définir ce risque comme :\n",
    "\n",
    "\n",
    "$$R(\\boldsymbol{\\beta}) = \\mathbb{E}_{X\\times Y}\\Big[ (f_{\\boldsymbol{\\beta}}(\\mathbf{X}) - Y)^2 \\Big].$$\n",
    "\n",
    "On ne sait pas calculer cette fonction. Cependant, on peut en avoir un estimateur via un jeu de données $\\mathcal{S}$, où $\\mathcal{S} = \\Big\\{ \\big(\\boldsymbol{x_j}, y_j \\big) \\Big\\}_{j\\leq n}$ est un jeu de données composé de $n$ points indépendants et identiquement distribués selon le modèle génératif décrit précédement. \n",
    "\n",
    "\n",
    "A défaut d'avoir accès au risque (i.e. à l'erreur en espérance), on peut utiliser une autre quantité qui consiste en la somme des carrés des erreurs de prédictions pour chaque exemple d'apprentissage, c'est **le risque emprique** :\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\boldsymbol{\\beta}) = R_{emp}(\\boldsymbol{\\beta}) = \\frac{1}{n}\\sum_j^n (f_{\\boldsymbol{\\beta}}(x_j) - y_j)^2\n",
    "\\end{equation}\n",
    "\n",
    "où $f_{\\boldsymbol{\\beta}}(x_j) = \\beta_0  + \\beta_1 x_j$. On montre assez facilement que pour un $\\boldsymbol{\\beta}$ quelconque :\n",
    "\n",
    "\\begin{equation}\n",
    "R(\\boldsymbol{\\beta})=\\mathbb{E}_{\\mathcal{S \\sim \\mathbb{P}_S}}\\big[J(\\boldsymbol{\\beta})\\big],\n",
    "\\end{equation}\n",
    "\n",
    "Notons que minimiser ce risque empirique revient à chercher le maximum de vraisemblance du modèle statistique. Effectivement, avec l'hypothèse gaussienne, la vraissemblance de n'importe quel modèle de paramètres $\\boldsymbol{\\beta}$ pour un jeu de données $\\mathcal{S}$ peut s'écrire :\n",
    "\n",
    "\\begin{equation}\n",
    "L_{\\mathcal{S}}(\\boldsymbol{\\beta}) \\propto \\prod_{\\boldsymbol{x}\\times y\\in\\mathcal{S}} \\exp\\Bigg(-\\frac{\\big(f_{\\boldsymbol{\\beta}}(\\mathbf{x}) - y\\big)^2}{2}\\Bigg)\n",
    "\\end{equation}\n",
    "\n",
    "Le paramètre maximisant la vraissamblance est aussi celui minimisant la log-vraissamblance négative :\n",
    "\n",
    "$$- \\text{log} \\Big( L_{\\mathcal{S}}(\\boldsymbol{\\beta})\\Big) = \\sum_{\\boldsymbol{x}\\times y\\in\\mathcal{S}}\\frac{\\big(f_{\\boldsymbol{\\beta}}(\\mathbf{x}) - y\\big)^2}{2}\\propto\\sum_{\\boldsymbol{x}\\times y\\in\\mathcal{S}}\\big(f_{\\boldsymbol{\\beta}}(\\mathbf{x}) - y\\big)^2$$\n",
    "\n",
    "N'ayant accès au véritable risque, on cherche $\\boldsymbol{\\hat{\\beta}}$ tel que :\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\hat{\\beta}} = argmin_{\\boldsymbol{\\beta}} \\Big[ - \\log \\Big( L_{\\mathcal{S}}(\\boldsymbol{\\beta})\\Big) \\Big]\n",
    "\\end{equation}\n",
    "\n",
    "Minimiser le risque emprique se traduit donc naturellement par un problème d'optimisation de la fonction de coût $J(\\boldsymbol{\\beta}) : \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ ($\\mathbb{R}^2$ dans notre exemple courant, $\\mathbb{R}^{d+1}$ dans le cas général) par rapport à $\\boldsymbol{\\beta}$.\n",
    "\n",
    "En pratique et pour des raisons de simplicité, on ne minimise pas $\\sum_{\\boldsymbol{x}\\times y\\in\\mathcal{S}}\\big(f_{\\boldsymbol{\\beta}}(\\mathbf{x}) - y\\big)^2$ mais :\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\boldsymbol{\\beta}) = \\frac{1}{2n}\\sum_{\\boldsymbol{x}\\times y\\in\\mathcal{S}} (f_{\\boldsymbol{\\beta}}(x) - y)^2\n",
    "\\end{equation}\n",
    "\n",
    "Le résultat est bien évidemment le même. La division par $2$ est là pour simplifier l'expresion du gradient que l'on calculera et la division par $n$ permet de rendre la norme du gradient indépendente de la taille de notre jeu de données. C'est une propriété importante pour l'algorithme de descente de gradient dont la taille des déplacements affecte sa stabilité.\n",
    "\n",
    "**Note - Notation vectorielle de la régression linéaire :** On peut aussi exprimer ce calcul avec une simple équation en notation vectorielle. Pour cela, on exprime dans un premier temps le résultat de la fonction de prédiction en notation vectorielle (il s'agit de la prédiction pour tout notre jeu de données) :\n",
    "\n",
    "\\begin{equation}\n",
    "f_{\\boldsymbol{\\beta}}(\\mathbf{X}) = \\mathbf{X}\\boldsymbol{\\beta}\\in\\mathbb{R}^n\n",
    "\\end{equation}\n",
    "\n",
    "où $\\boldsymbol{\\beta} \\in \\mathbb{R}^{d+1}$ est une matrice de dimensions $(d+1)\\times 1$ et $\\mathbf{X}$ est une matrice de dimensions $n\\times (d+1)$ dont les $n$ vecteurs lignes correspondent aux vecteurs d'apprentissage d'entrée. Dans notre cas (celui de la régression linéaire à $1$ variable) la matrice prend la forme suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \n",
    "\\begin{pmatrix} \n",
    "1 & x_{1} \\\\\n",
    ". & .\\\\\n",
    "1 & x_{j} \\\\\n",
    ". & .\\\\\n",
    "1 & x_{n} \n",
    "\\end{pmatrix},\\ \\boldsymbol{\\beta}=\n",
    "\\begin{bmatrix}\n",
    "\\beta_{0} \\\\           \n",
    "\\beta_{1}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "La fonction de coût peut ainsi s'exprimer :\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\boldsymbol{\\beta}) = \\frac{1}{2n} (\\mathbf{X}\\boldsymbol{\\beta} - \\mathbf{y})^T(\\mathbf{X}\\boldsymbol{\\beta} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "que l'on peut réécrire :\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\boldsymbol{\\beta}) = \\frac{1}{2n} (\\mathbf{\\hat{y}} - \\mathbf{y})^T(\\mathbf{\\hat{y}} - \\mathbf{y}) =  \\frac{1}{2n} ||\\mathbf{\\hat{y}} - \\mathbf{y}||_2^2\n",
    "\\end{equation}\n",
    "\n",
    "où $\\mathbf{y} \\in  \\mathbb{R}^n$ est le vecteur dont chacune des composantes $y_j$ sont les valeurs à prédire à partir de leur $x_j$ correspondant, et $\\hat{y} \\in  \\mathbb{R}^n$ correspond aux valeurs prédites par le modèle. On note ici que la fonction objectif à optimiser peut se calculer aisément en utilisant la norme euclidienne du vecteur d'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation par Descente de gradient\n",
    "La descente de gradient est une méthode d'optimisation numérique permettant de trouver les valeurs des paramètres qui minimisent une fonction. Dans notre cas, nous voulons minimiser l'erreur de prédiction moyenne de notre modèle, fonction définie précédemment. Cette méthode d'optimisation consiste à calculer le gradient de notre fonction objectif par rapport aux paramètres courant du modèles et de les déplacer \"petite\" translation dans la direction opposée au gradient (i.e. le gradient donne la plus forte croissance et son opposé la plus forte décroissance).\n",
    "\n",
    "**Définition générale du gradient d'une fonction à plusieurs variables :** Il s'agit simplement du vecteur contenant les dérivées partielles de la fonction, c-à-d les dérivées de la fonction par rapport à chaque variable indépendamment des autres:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\boldsymbol{\\beta}} J(\\boldsymbol{\\beta}) = \\frac{\\partial J(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial J(\\beta)}{\\partial \\beta_0}\\\\\n",
    "\\frac{\\partial J(\\beta)}{\\partial \\beta_1}\\\\\n",
    " \\vdots \\\\\n",
    "\\frac{\\partial J(\\beta)}{\\partial \\beta_d}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "En descente de gradient, la mise à jour de chaque paramètre $\\beta_j$ du modèle à l'itération $t$ se fait donc avec la règle suivante:\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta_j^{(t+1)} = \\beta_j^{(t)} - \\rho  \\frac{\\partial J(\\beta^{(t)})}{\\partial \\beta_j}\n",
    "\\end{equation}\n",
    "\n",
    "ou bien, en notation vectorielle:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} - \\rho  \\nabla_{\\boldsymbol{\\beta}} J(\\boldsymbol{\\beta})^{(t)}\n",
    "\\end{equation}\n",
    "\n",
    "où $\\rho$ est le learning rate (pas d'apprentissage). Un pas d'apprentissage $\\rho$ trop petit nous fera nous déplacer trop lentement et trop grand rendra l'optimisation instable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### À vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question 1 :**</span> **Complétez la méthode $\\texttt{val}$ de l'objet $\\texttt{LeastSquare}$ ci-dessous.**\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Question 2 :**</span> **Calculez les dérivées partielles $\\partial J(\\beta)/\\partial \\beta_0$ et $\\partial J(\\beta)/\\partial \\beta_1$ de la fonction de coût de notre modèle de régréssion linéaire. Complétez la méthode $\\texttt{grad}$ de l'objet $\\texttt{LeastSquare}$ ci dessous.**\n",
    "\n",
    "**<span style=\"color:orange\">Indice</span>**  Rappellez vous que la dérivée d'une composition de fonction s'écrit $(g \\circ f)^\\prime (x) = f^\\prime(x) g^\\prime(f(x))$ et que la fonction de coût de notre modèle s'écrit :\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\boldsymbol{\\beta}) = \\frac{1}{2n}\\sum_j^n g(f_{\\boldsymbol{\\beta}}(x_j) - y_j)\n",
    "\\end{equation}\n",
    "\n",
    "avec $g(z) = z ^ 2$ et $f_{\\boldsymbol{\\beta}}(x_j) = \\beta_0  + \\beta_1 x_j$.\n",
    "\n",
    "**<span style=\"color:green\">Réponse :</span>**\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial J(\\beta)}{\\partial \\beta_j} = \\frac{1}{n}\\sum_i^n (f_{\\boldsymbol{\\beta}}(\\mathbf{x_i}) - y_i)   x_i^j\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Question 2${}^\\star$ :**</span> **Calculez le gradient de la fonction $J(\\boldsymbol{\\beta})$ en utilisant les dérivées matricielles. Complétez la méthode $\\texttt{grad}$ de l'objet $\\texttt{LeastSquare}$ avec le gradient en notation vectorielle.**\n",
    "\n",
    "**<span style=\"color:green\">Réponse:</span>**\n",
    "\n",
    "Le gradient est obtenu par $\\nabla_\\beta J(\\boldsymbol{\\beta})=X^TX\\boldsymbol{\\beta}-X^T\\boldsymbol{y}$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le code ci-dessous permettra d'afficher notre fonction de cout (le risque empirique)\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_loss_contour(l, param_trace=None, figsize=None, three_dim=False, rotate=12):\n",
    "    \n",
    "    x, y = np.mgrid[slice(-4, 4 + 0.1, 0.1),\n",
    "                    slice(-4, 4 + 0.1, 0.1)]\n",
    "    z = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i, j] = l.val([x[i, j], y[i, j]])\n",
    "    if figsize is not None:\n",
    "        f = plt.figure(figsize=figsize)\n",
    "    else:\n",
    "        f = plt.figure(figsize=(12.0, 8.0))\n",
    "    if three_dim:\n",
    "        ax = f.gca(projection='3d')\n",
    "    else:\n",
    "        ax = f.gca()\n",
    "    \n",
    "    if three_dim:\n",
    "        m = ax.plot_surface(x, y, np.sqrt(z), cmap=cm.viridis)\n",
    "    else:\n",
    "        m = ax.contourf(x, y, np.sqrt(z), levels = 10)\n",
    "    #\n",
    "    if param_trace is not None:\n",
    "        if three_dim:\n",
    "            eps = 0.5\n",
    "            #ax.scatter(param_trace[:, 0], param_trace[:, 1], param_trace[:, 2] + eps, \n",
    "            #           color='blue', alpha=1)\n",
    "            ax.plot(param_trace[:, 0], param_trace[:, 1], param_trace[:, 2] + eps, \n",
    "                    color='red')\n",
    "            ax.view_init(50, rotate)\n",
    "                \n",
    "        else:\n",
    "            param_trace = np.array(param_trace) if type(param_trace) is list else param_trace\n",
    "            plt.plot(param_trace[:, 0], param_trace[:, 1])\n",
    "            plt.scatter(param_trace[:, 0], param_trace[:, 1])\n",
    "            f.colorbar(m)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquare(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.insert(LeastSquare._format_ndarray(X), 0, 1, axis=1)\n",
    "        self.y = LeastSquare._format_ndarray(y)\n",
    "        self.idx = np.array([i for i in range(self.X.shape[0])])\n",
    "        self._pos = 0\n",
    "        \n",
    "    def _format_ndarray(arr):\n",
    "        arr = np.array(arr) if type(arr) is not np.ndarray else arr\n",
    "        return arr.reshape((arr.shape[0], 1)) if len(arr.shape) == 1 else arr\n",
    "    \n",
    "    def val(self, beta):\n",
    "        beta = LeastSquare._format_ndarray(beta)\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        prediction = np.dot(beta.T, self.X.T)\n",
    "        errors = np.power(prediction - self.y.T, 2)\n",
    "        val = errors.sum()/(2*self.X.shape[0])\n",
    "        ###############################################################\n",
    "        return val\n",
    "    \n",
    "    def _shuffle(self):\n",
    "        np.random.shuffle(self.idx)\n",
    "    \n",
    "    def grad(self, beta, batch_size=-1):\n",
    "        batch_size = self.X.shape[0] if batch_size == -1 else batch_size\n",
    "        idx = self.idx[self._pos:self._pos+batch_size]\n",
    "\n",
    "        self._pos = (self._pos+batch_size) % self.X.shape[0]\n",
    "        if self._pos == 0:\n",
    "            self._shuffle()\n",
    "            \n",
    "        X, y = self.X[idx], self.y[idx]\n",
    "\n",
    "        beta = LeastSquare._format_ndarray(beta)\n",
    "        \n",
    "        ####### Complete this part ######## or die ####################\n",
    "        grad = (np.dot(np.dot(X.T, X), beta)-np.dot(X.T, y))/X.shape[0]\n",
    "        ###############################################################\n",
    "        return grad\n",
    "    \n",
    "\n",
    "l = LeastSquare(X, y)\n",
    "print('La valeur de la loss pour le vrai parametre est', l.val(beta))\n",
    "print('La valeur du gradient pour le vrai parametre est\\n', l.grad(beta))\n",
    "plot_loss_contour(l, three_dim=True)\n",
    "plot_loss_contour(l, three_dim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, pour des raisons de temps de calcul, l'estimation du gradient n'est pas tout le temps faite sur tout le jeu de données mais sur une partie de celui-ci. Un estimateur calculé de cette manière là aura en espérance la même valeur qu'un gradient calculé sur toutes les données. On appelle généralement Descente de Gradient Stochastique oiu SGD une approche qui ne fait qu'estimer le gradient à partir d'un batch de données.\n",
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Saurez-vous retrouver dans le code ci-dessus ce qui permet de jouer sur la taille du batch lors du calcul du gradient ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  L'algorithme de descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Complétez le code de descente de gradient.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    init = np.random.uniform(-4, 4, size=2).reshape((2, 1))\n",
    "    def __init__(self, X, y, loss=LeastSquare):\n",
    "        self.loss = loss(X, y)\n",
    "        \n",
    "    def optimize(self, learning_rate = 0.005, nb_iterations=100, beta=init, batch_size=-1):\n",
    "        param_trace = [beta.T[0]]\n",
    "        loss_trace = [self.loss.val(beta)]\n",
    "        for i in range(nb_iterations):\n",
    "            ####### Complete this part ######## or die ####################\n",
    "            beta = beta - learning_rate * self.loss.grad(beta, batch_size=batch_size)\n",
    "            ###############################################################\n",
    "            param_trace.append(beta.T[0])\n",
    "            loss_trace.append(self.loss.val(beta))\n",
    "            \n",
    "        return param_trace, loss_trace\n",
    "        \n",
    "gd = GradientDescent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trace, loss_trace = gd.optimize(nb_iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_trace = np.array(param_trace)\n",
    "loss_trace = np.array(loss_trace)\n",
    "loss_trace = loss_trace.reshape((loss_trace.shape[0], 1))\n",
    "xyz = np.concatenate([param_trace, np.sqrt(loss_trace)], axis=1)\n",
    "\n",
    "plot_loss_contour(l, param_trace=xyz, three_dim=True)\n",
    "plot_loss_contour(l, param_trace=param_trace, three_dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def interactive_gradient_descent(learning_rate, batch_size):\n",
    "    clear_output()\n",
    "    param_trace , loss_trace = gd.optimize(learning_rate = learning_rate, batch_size = batch_size)\n",
    "    plot_loss_contour(gd.loss, param_trace, figsize=(14.0, 6.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(interactive_gradient_descent,\n",
    "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=0.05, step=0.0001, \n",
    "                                                   continuous_update=False, readout_format='.5f'),\n",
    "                 batch_size=widgets.IntSlider(value=X.shape[0], min=1, max=X.shape[0], step=1, \n",
    "                                              continuous_update=False)\n",
    ")\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques et questions sur GD** : On constate que la descente de gradient (GD) se déplace bien orthogonalement aux lignes de niveaux de la fonction de coût. C'est une propriété du gradient d'une fonction. À mesure qu'on avance vers le minimum de la fonction, on se déplace de plus en plus lentement vers ce dernier. Pouvez vous dire pourquoi intuitivement ou analytiquement en regardant l'expression du gradient que vous avez dérivé plus haut ? Soit $\\boldsymbol{\\beta}^{(0)} = [0.0,  0.0]^T$ et $\\rho$, montrez que GD converge necessairement vers la solution otpimale (cette question est interessante par rapport à la partie suivante sur les équations normales de la régression linéaire et la notion de solution par pseudo inverse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques et questions sur SGD (avec un gradient estimé sur un sous-ensemble)** : La propriété d'orthogonalité par rapport aux lignes de niveau de la fonction de coût est elle conservée dans ce cas ? Pourquoi ? Ne suit-on pourtant toujours pas le gradient ? Que pouvez vous dire sur la nature et la \"vitesse\" de convergence vers le minimum de la fonction ? Réfléchissez d'un point de vue calculatoire sur ce qui se passe sur des tailles d'échantillons très grandes ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les équations normales de la régression linéaire : la solution par pseudo-inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme calculé plus haut, l'expression du gradient est donnée par $X^TX\\boldsymbol{\\beta}-X^T\\boldsymbol{y}$.  La fonction $J$ étant coercive et convexe, elle admet au moins un minimum local/global. Les points critiques sont donnés en annulant le gradient :\n",
    "\n",
    "\\begin{equation}\n",
    "X^TX\\boldsymbol{\\beta}-X^T\\boldsymbol{y} = 0 \\Leftrightarrow X^TX\\boldsymbol{\\beta}=X^t\\boldsymbol{y}.\n",
    "\\end{equation}\n",
    "\n",
    "Il s'agit des équations dites \"normales\". Tout vecteur $\\boldsymbol{\\beta}$ solution de ces équations est donc nécessairement un minimiseur de $J(\\boldsymbol{\\beta})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dans le cas standard** où chaque variable explicative est linéairement indépendante des autres et où le nombre d'échantillons de notre jeu de données est supérieur ou égal à la dimension du problème considéré, la matrice $X^TX$ est inversible (i.e. $\\text{det}(X^TX)\\neq 0$). Dit autrement, il existe une unique solution aux équations normales donnée par :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\boldsymbol{\\beta}}=(X^TX)^{-1}X^T\\boldsymbol{y}.\n",
    "\\end{equation}\n",
    "\n",
    "On appelle $X^\\dagger = (X^TX)^{-1}X^T$  pseudo-inverse de $X$ (ou inverse généralisé) et la solution analytique à notre problème est donnée par $\\hat{\\boldsymbol{\\beta}}=X^\\dagger \\boldsymbol{y}$.\n",
    "\n",
    "**Dans le cas non standard** où certaines variables peuvent être des combinaisons linéaires d'autres variables (inutile en pratique) ou si le nombre d'échantillons est inférieur à la dimension, $X^TX$ n'est plus inversible. Dans ce cas de figure, il existe une infinité de solutions aux équations normales (i.e. une infinité de minimiseurs). E. H. Moore (1920), A. Bjerhammar (1951) et R. Penrose (1955) proposent indépendamment une expression générale de $X^\\dagger$ appelée pseudo-inverse de Moore-Penrose et calculable à partir d'une décomposition en valeur singulière, notée $X^\\dagger$. Celle-ci coïncide bien sûr avec l'expression standard lorsqu'elle existe. On obtient donc une expression analytique générale, solution des équations normales :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\boldsymbol{\\beta}}=X^\\dagger\\boldsymbol{y},\n",
    "\\end{equation}\n",
    "\n",
    "où $X^\\dagger$ est le pseudo-inverse de Moore-Penrose. \n",
    "\n",
    "***Quelques précisions d'algèbre*** : finalement, quel est le lien entre une pseudo-inverse et l'inverse classique. Soit une application linéaire $A:\\mathbb{R}^n\\mapsto\\mathbb{R}^n$ représentée par une matrice $A\\in\\mathbb{R}^{n\\times n}$. On appelle inverse de $A$ l'unique matrice, notée $A^{-1}$, telle que  $A^{-1}A=\\text{Id}$. Dans le cas inversible, l'inverse de $A^{-1}$ est donc de manière évidente $A$. Cela revient à transformer un vecteur $x\\in\\mathbb{R}^n$ par $A$ puis à annuler sa transformation par $A^{-1}$. L'inverse n'existe cependant pas toujours. Ainsi, par exemple, si $\\text{ker}(A)\\neq \\{\\boldsymbol{0}\\}$ (i.e. le noyau ne se résume pas à l'élément null, nous avons $\\forall x\\in\\mathbb{R}^n,\\ u\\in\\text{ker}(A)$ que $A(x+u)=Ax$. Finalement l'inverse de $Ax$ est-il $x$ ou $x+u$ ?\n",
    "\n",
    "Reprenons le cas inversible. Quelques propriétés qui peuvent sembler évidentes émergent :\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "AA^{-1}A&=A\\text{ (appliquer }A\\text{, son inverse }A^{-1}\\text{ puis }A\\text{ à nouveau revient à appliquer }A\\text{)}\\\\\n",
    "A^{-1}AA^{-1}&=A^{-1}\\text{ (c'est la même chose du point de vu de l'inverse)}\\\\\n",
    "(AA^{-1})^T&=AA^{-1}\\text{ (la transposition n'a pas d'effet)}\\\\\n",
    "(A^{-1}A)^T&=A^{-1}A\\text{ (même chose que précédemment du point de vu de l'inverse)}\n",
    "\\end{aligned}$$\n",
    "\n",
    "La pseudo inverse est l'unique matrice $A^\\dagger$ satisfaisant les propriétés précédentes. Dans le cas où $A$ est inversible, on a alors $A^\\dagger=A^{-1}$. Intuitivement, l'idée est de ne considérer \"que\" les éléments qui ne sont pas dans le noyaux. Ainsi $\\text{Im}(A)=\\text{Ker}(A^\\dagger)^\\perp$ et inversement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La structure de la solution** peut s'étudier en remplaçant $\\boldsymbol{y}$ par sa construction, à savoir, une combinaison linéaire et du bruit :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\beta}=X^\\dagger y = X^\\dagger(X\\boldsymbol{\\beta} + \\eta) = (X^\\dagger X)\\boldsymbol{\\beta} + X^\\dagger\\eta\n",
    "\\end{equation*}\n",
    "\n",
    "où on utilise $\\eta$ plutôt que $\\epsilon$ pour différentier la réalisation effective du bruit de la variable aléatoire.\n",
    "\n",
    "On observe, par propriété de la pseudo-inverse, que la première contribution est la projection orthogonale du vrai modèle sur l'espace des vecteurs ligne de $X$. Il est donc une combinaison linéaire des vecteurs que l'on voit pendant l'apprentissage ! La deuxième contribution est l'effet du bruit sur la solution optimale. Nous discuterons plus loin de ces contributions et d'effets étranges qui peuvent se produire notament quand la matrice $X$ est mal conditionnée (le ratio entre la plus grande valeur propre de $X^TX$ et sa plus petite valeur propre est très grand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### À vous de jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Calculez la solution du problème de régression linéaire en utilisant la pseudo-inverse de Moore-Penrose proposée par $\\texttt{numpy}$ via $\\texttt{np.linalg.pinv}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "# descente de gradient\n",
    "\n",
    "# descente de gradient sans stochasticite\n",
    "param_trace , loss_trace = gd.optimize(learning_rate = 0.04, nb_iterations=50) \n",
    "\n",
    "####### Complete this part ######## or die ####################\n",
    "# solution par pseudo inverse\n",
    "X_inv = np.linalg.pinv(np.insert(X.reshape((X.shape[0], 1)), 0, 1, axis=1))\n",
    "beta_pinv = np.dot(X_inv, y)\n",
    "###############################################################\n",
    "\n",
    "print('La loss pour la solution par pseudo-inverse est', l.val(beta_pinv))\n",
    "print('La loss pour la solution obtenue par descente de gradient est', loss_trace[-1])\n",
    "\n",
    "plot(X, y, beta_pinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Remarques et question :**</span> **On remarque ici que la valeur de la loss atteinte par GD est plus haute que celle atteinte par la solution de la pseudo-inverse. A votre avis pourquoi ? Augmentez le nombre d'itérations de GD. Que constatez vous par rapport ? Est-ce étonnant par rapport à votre brillante démonstration sur GD dans la section précédente ? Au passage, on pourrait s'amuser à montrer qu'avec l'initialisation $\\beta=\\boldsymbol{0}$, chaque step reste bien dans l'espace engendré par les vecteurs lignes de X. Qui veut passer au tableau ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Proposez une régression linéaire sur le même problème en utilisant $\\texttt{sklearn}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "####### Complete this part ######## or die ####################\n",
    "model = LinearRegression()\n",
    "model.fit(X.reshape((X.shape[0], 1)), y)\n",
    "###############################################################\n",
    "coef = list(model.coef_)\n",
    "coef.insert(0, model.intercept_)\n",
    "\n",
    "print('La loss pour la solution obtenue par Sklearn est', l.val(coef))\n",
    "\n",
    "plot(X, y, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Features - Variables explicatives transformées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans beaucoup de problèmes réels, la variable à expliquer n'est pas une simple combinaison linéaire des variables explicatives. Cela peut-être une dépendence non linéaire (e.g. quadratique), ou des dépendences croisées entre nos variables explicatives. La stratégie permettant d'aborder cette problématique consiste à transformer notre vecteur $\\boldsymbol{x}$ en rajoutant par exemple des transformations quadratiques et à optimiser notre modèle linéaire sur le vecteur transformé. Afin de simplifier les notations, nous allons volontairement omettre le biais $\\beta_0$ de nos notations.\n",
    "\n",
    "Construire nos *features* consiste à chercher une fonction $\\phi:\\mathbb{R}^d\\mapsto\\mathbb{R}^p$ qui transforme non-linéairement nos variables explicatives initiales.\n",
    "\n",
    "\n",
    "Le problème se reformule ainsi de la manière suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}=\\langle \\phi(\\boldsymbol{x}), \\boldsymbol{\\beta}\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "Le gradient est alors calculé en fonction de $\\boldsymbol{z}=\\phi(\\boldsymbol{x})$ et non en fonction de $\\boldsymbol{x}$. Il suffit donc de transformer nos variables explicatives par $\\phi$ et de considérer le résultat comme nos nouvelles variables explicatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du jeu de données polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# vrais parametres\n",
    "beta_cube = np.random.uniform(-4, 4, size=(4,1))\n",
    "\n",
    "def sample_data_cube(n, sigma=1):\n",
    "    X = np.random.normal(0, sigma, size=n)\n",
    "    noise = np.random.normal(1, 1, size=n)/2\n",
    "    y = beta_cube[3] * X ** 3 + beta_cube[2] * X ** 2 + beta_cube[1] * X + beta_cube[0] + noise\n",
    "    return X, y\n",
    "X, y = sample_data_cube(6)\n",
    "X_test, y_test = sample_data_cube(150)\n",
    "\n",
    "#affichage du polynome\n",
    "plot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution par pseudo-inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Complétez le code ci-dessous en utilisant une solution par pseudo-inverse via $\\texttt{numpy}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polynomial(object):\n",
    "    def __init__(self, deg):\n",
    "        self.deg = deg\n",
    "\n",
    "    def _transform(self, X):\n",
    "        # here we transform the input into a polynomial\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        t = []\n",
    "        X = X.reshape((X.shape[0], 1)) if len(X.shape) == 1 else X\n",
    "        for i in range(0, self.deg+1):\n",
    "            t.append(X**i)\n",
    "        return np.concatenate(t, axis=1)\n",
    "        ###############################################################\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        X_transformed = self._transform(X)\n",
    "        self.beta = np.dot(np.linalg.pinv(X_transformed), y)\n",
    "        ###############################################################\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.beta is None:\n",
    "            print('You must fit the model first')\n",
    "        else:\n",
    "            X_transformed = self._transform(X)\n",
    "            return np.dot(X_transformed, self.beta)\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        errors = (prediction - y) **2\n",
    "        return errors.sum()/errors.shape[0]\n",
    "    \n",
    "# vraie solution\n",
    "real_model = Polynomial(deg=3)\n",
    "real_model.beta = beta_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Remarques et exercice :**</span> **Le plot est affiché avec un jeu dit de test. Il s'agit d'un ensemble de points qui n'ont pas été utilisés lors de notre apprentissage (par pseudo-inverse). Le jeu de données $\\texttt{X, y}$ d'une taille différente est celui qui a été utilisé.**\n",
    "\n",
    "**Jouez avec le degré du polynôme que vous manipulez et observez le résultat. Que constatez-vous ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 6\n",
    "model = Polynomial(deg)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "plot(X_test, y_test, func=[(model.predict, 'Our model'), (real_model.predict, 'Real model')])\n",
    "\n",
    "print('Empirical risk: ', model.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Remarque et question :**</span> **Le risque empirique est celui calculé directement sur les données utilisées lors du calcul du pseudo-inverse. Que constatez-vous par rapport à ce dernier lorsque vous jouez avec le degré du polynôme ?**\n",
    "\n",
    "**Est-il un bon indicateur du véritable risque de généralisation ? Autrement dit, est-il un bon indicateur de la qualité du polynôme obtenu.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Proposez la même solution polynomiale via $\\texttt{sklearn}$. Choisissez le même degré qu'utilisé au-dessus et comparez les résultats.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = make_pipeline(PolynomialFeatures(deg), LinearRegression())\n",
    "model.fit(X.reshape((X.shape[0], 1)), y)\n",
    "###############################################################\n",
    "\n",
    "plot(X_test, y_test, func=[(model.predict, 'sklearn'), (real_model.predict, 'Real model')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez pu constater qu'en fonction du degré du polynôme choisi dans l'exercice précédent, le modèle obtenu était plus ou moins loin de la solution idéale. De plus, le risque empirique s'est montré être un piètre estimateur de la qualité de notre solution estimée.\n",
    "\n",
    "En réalité, le risque empirique est un estimateur sans biais du risque de généralisation pour un vecteur de paramètres quelconque. Ce n'est plus vrai si on choisit la solution estimée via notre optimisation. Dit autrement :\n",
    "\n",
    "$$R(\\boldsymbol{\\beta})=\\mathbb{E}_{\\mathcal{S}}\\Big[J(\\boldsymbol{\\beta})\\Big],\\text{ }\\boldsymbol{\\beta}\\text{ quelconque, et }R(\\text{argmin}_{\\boldsymbol{\\beta}}J(\\boldsymbol{\\beta}))\\neq \\mathbb{E}_{\\mathcal{S}}\\Big[\\text{argmin}_{\\boldsymbol{\\beta}}J(\\boldsymbol{\\beta})\\Big]$$\n",
    "\n",
    "Cela implique de mettre en place une procédure expérimentale permettant d'évaluer la qualité de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta_cube = np.random.uniform(-4, 4, size=(4,1))\n",
    "\n",
    "def sample_data_cube(n, sigma=1):\n",
    "    X = np.random.normal(0, sigma, size=n)\n",
    "    noise = np.random.normal(1, 1, size=n)/2\n",
    "    y = beta_cube[3] * X ** 3 + beta_cube[2] * X ** 2 + beta_cube[1] * X + beta_cube[0] + noise\n",
    "    return X, y\n",
    "X, y = sample_data_cube(50)\n",
    "X_test, y_test = sample_data_cube(150)\n",
    "\n",
    "X = X.reshape((X.shape[0], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1))\n",
    "\n",
    "plot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser une fonction est-il suffisant pour parler d'apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe deux stratégies d'évaluation sans biais de la qualité de notre modèle :\n",
    "* La validation non croisée où une partie de notre jeu de donnée est cachée pendant l'apprentissage puis utilisée afin d'évaluer les performances du modèle. Il s'agit du découpage train/test. Cette stratégie est un estimateur sans biais de la qualité de notre modèle mais possède une variance plus forte que la validation croisée. Elle peut-être particulièrement utile lorsque le coup d'apprentissage d'un modèle est très élevé (e.g. *deep learning*)\n",
    "* La validation croisée où notre jeu de données est divisé en *k* parties (on parle aussi de *k-fold*). Évidemment, $k\\in\\{2, ..., n\\}$ où $n$ est la taille du jeu de données. Chacune des parties jouera successivement le rôle de jeu de test pendant que les $k-1$ autres parties serviront à calculer notre modèle. Le résultat de cette procédure est un vecteur de $k$ scores dont on peut calculer la moyenne, la variance, etc.\n",
    "\n",
    "On peut illustrer la méthode des *k-folds* via l'exemple suivant :\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Appartient au train set: } \\color{red}{\\boxed{}}&\\text{ et appartient au test set: }\\color{green}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 1: }\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 2: }\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 3: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 4: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 5: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 6: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 7: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\n",
    "\\end{align}\n",
    "\n",
    "La méthode $\\texttt{cross_val_score}$ de $\\texttt{sklearn}$ permet de réaliser cette procédure. On pourra renseigner le paramètre $\\texttt{cv}$ qui indique le nombre $k$ et le paramètre $\\texttt{scoring}$ qui donne la métrique que l'on souhaite calculer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Proposez un *5-fold* avec la métrique $R^2$ que vous appliquerez à une régression polynomiale de degré $5$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "####### Complete this part ######## or die ####################\n",
    "model = make_pipeline(PolynomialFeatures(5), LinearRegression())\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Le score R2 sur chacun des splits de notre k-fold:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Comparez le score obtenu lors de votre validation croisée à un plot de la fonction estimée sur tout le jeu d'apprentissage.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model.fit(X, y)\n",
    "###############################################################\n",
    "plot(X_test, y_test, func=model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. L'effet \"double descente\" (Bonus ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu précédemment, l'effet du bruit sur l'estimateur depend du conditionnement de $X^TX$. Le conditionnement d'une matrice $A$ inversible est donné par :\n",
    "\n",
    "\\begin{equation}\n",
    "C(A)=\\lVert A^{-1}\\rVert\\lvert A\\rVert\n",
    "\\end{equation}\n",
    "\n",
    "Il est évident que si $A\\in{\\mathbb{R}^{1\\times 1}}^\\star$, alors $C(A)=1$. Ce n'est absolument pas vrai dans le cas général.\n",
    "\n",
    "L'exemple ci-dessous illustre cela via la norme de Frobenius (norme Euclidienne appliquée à une matrice, $\\text{Tr}(A^TA)^{0.5}$). On préfèrera en pratique la norme d'opérateur qui quantifie les effets d'amplification d'un vecteur $\\boldsymbol{x}$ lorsqu'on calcule $A\\boldsymbol{x}$. Cette norme d'opérateur est directement liée aux valeurs propres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.diag([1, 0.0001])\n",
    "print('A=\\n', A)\n",
    "print('C(A)=A^{-1}A=' + str(np.linalg.norm(np.linalg.inv(A))*np.linalg.norm(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque dans l'exemple que la matrice $A$ possède une toute petite valeur propre qui est responsable de cet écart. L'exercice ci-dessous montre qu'au-delà des considérations théoriques, cela a des répercussions importantes et totalement inattendues en réalité.\n",
    "\n",
    "Les simulations suivantes permettent de mettre en lumière cela. Elles sont construites comme décrit ci-dessous :\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta\\sim\\mathbb{U}(-2, 2)^d,\\ d\\in\\mathbb{N}^\\star\n",
    "\\end{equation}\n",
    "\n",
    "dit autrement, on fixe un vecteur de paramètres selon une loi uniforme qui dépend de la dimension du problème.\n",
    "Nous avons ensuite :\n",
    "\n",
    "\\begin{equation}\n",
    "x\\sim\\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I_d}) + \\epsilon,\\ \\epsilon\\sim\\mathcal{N}(0, \\sigma^2)\n",
    "\\end{equation}\n",
    "\n",
    "On construit ensuite un jeu de test de taille $500$ et un jeu d'apprentissage de taille variable. L'objectif ici sera d'étudié l'effet de la taille du jeu d'apprentissage sur la qualité de notre modèle, qualité que l'on aura calculée sur le test. Pour chaque taille de jeu de données, l'expérience est répétée $50$ fois ($\\texttt{redo}$) afin de lisser les courbes obtenues.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Exécutez une première fois le code puis jouez avec $\\texttt{noise}$ (i.e. $\\sigma$) afin de voir ce qui se passe selon la quantité de bruit. Essayez de décrire rigoureusement ce que vous observez.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "####### Play with the noise #########\n",
    "noise = 1.\n",
    "#####################################\n",
    "\n",
    "d = 50\n",
    "redo = 50\n",
    "\n",
    "beta = np.random.uniform(-2, 2, size=(d, 1))\n",
    "\n",
    "mu = [0 for _ in range(d)]\n",
    "cov = np.diag([1 for _ in range(d)])\n",
    "\n",
    "test_size = 500\n",
    "X_test = np.random.multivariate_normal(mean=mu, cov=cov, size=test_size)\n",
    "y_test = np.dot(X_test, beta) + np.random.normal(0, 1, size=(test_size, 1)) * noise\n",
    "\n",
    "errors = []\n",
    "train_errors = []\n",
    "for m in range(1, 100):\n",
    "    error = 0\n",
    "    train_error = 0\n",
    "    for j in range(redo):\n",
    "        # dataset construction\n",
    "        X = np.random.multivariate_normal(mean=mu, cov=cov, size=m)\n",
    "        y = np.dot(X, beta) + np.random.normal(0, 1, size=(m, 1)) * noise\n",
    "        \n",
    "        # param estimation\n",
    "        beta_pinv = np.dot(np.linalg.pinv(X), y)\n",
    "        \n",
    "        # risk estimation\n",
    "        error += ((np.dot(X_test, beta_pinv)-y_test)**2).sum()/(test_size*redo)\n",
    "        train_error += ((np.dot(X, beta_pinv)-y)**2).sum()/(m*redo)\n",
    "    train_errors.append(train_error)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot([i for i in range(1, len(errors)+1)], train_errors, label=\"Train error\")\n",
    "plt.axvline(x=d, color='k', linewidth=2.0, linestyle='--', label='Dimension')\n",
    "plt.plot([i for i in range(1, len(errors)+1)], errors, label=\"Risk estimation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot([i for i in range(1, len(errors)+1)], errors, label=\"Risk estimation\")\n",
    "plt.axvline(x=d, color='k', linewidth=2.0, linestyle='--', label='Dimension')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot([i for i in range(1, len(train_errors)+1)], train_errors, label=\"Train error\")\n",
    "plt.axvline(x=d, color='k', linewidth=2.0, linestyle='--', label='Dimension')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ligne en pointillé sépare visuellement deux régimes différents. La transition d'un régime à l'autre se produit par une augmentation catastrophique de l'erreur de généralisation de notre modèle.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Question :</span>** **Quelle particularité différentie les deux phases ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En réalité, les méthodes de *machine learning* traditionnelles se situent plutôt dans le régime de \"droite\". L'étude de ce phénomène est poussée par les approches comme le *deep learning* qui sont souvent dans le régime de gauche. Comprendre ces phénomènes nous permet par exemple d'éclairer les raisons du succès du *deep learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme illustré par les quelques scénarios précédents dont le cas catastrophique de la double descente, une certaine parcimonie est attendue par notre modèle. On a pu notamment observer que les \"mauvaises\" fonctions du point de vue du risque de généralisation avaient une forte tendance à osciller n'importe comment. Au lieu de laisser jouer le \"hasard\" (ou plutôt le conditionnement de $X^TX$), nous pouvons contraindre notre optimisation à favoriser les solutions parcimonieuses ; c'est-à-dire des solutions qui n'oscillent pas n'importe comment.\n",
    "\n",
    "Intuitivement, on va choisir une solution qui minimise à la fois le risque empirique $J(\\boldsymbol{\\beta})$, mais aussi une pénalité sur la quantité \"d'oscillation\". En réalité, les oscillations sont directement contrôlées par la norme des paramètres : un grand poids rendra notre modèle très sensible à la moindre perturbation de la variable explicative associée.\n",
    "\n",
    "Nous parlons d'optimisation régularisée lorsque la fonction à optimiser s'écrit de la manière suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\boldsymbol{\\beta})=\\frac{1}{m}\\sum_{i=1}^nr(f_{\\boldsymbol{\\beta}}(\\boldsymbol{x_i}), y_i)+\\lambda P(\\boldsymbol{\\beta})\n",
    "\\end{equation}\n",
    "\n",
    "où $r:\\mathcal{Y}\\times\\mathcal{Y}\\mapsto \\mathbb{R}^+$ est notre risque élémentaire et $P:\\mathbb{R}^d\\mapsto\\mathbb{R}^+$ une pénalité sur notre vecteur de paramètres. Plus précisément, dans le cas de la régression linéaire, nous avons :\n",
    "\n",
    "\\begin{equation}\n",
    "r(\\hat{y}, y)=(\\hat{y}-y)^2\n",
    "\\end{equation}\n",
    "\n",
    "et\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\boldsymbol{\\beta})=\\lVert \\boldsymbol{\\beta} \\rVert,\n",
    "\\end{equation}\n",
    "\n",
    "où $\\lVert \\cdot \\rVert$ est une norme quelconque. Les choix classiques sont la norme $\\ell_1$ :\n",
    "\n",
    "\\begin{equation}\n",
    "\\lVert \\boldsymbol{\\beta} \\rVert_1=\\sum_j |\\boldsymbol{\\beta}_j|\n",
    "\\end{equation}\n",
    "\n",
    "et la norme $\\ell_2$ :\n",
    "\n",
    "\\begin{equation}\n",
    "\\lVert \\boldsymbol{\\beta} \\rVert_2 = \\sqrt{\\sum_j\\boldsymbol{\\beta}_j^2}=\\sqrt{\\boldsymbol{\\beta}^T\\boldsymbol{\\beta}} \n",
    "\\end{equation}\n",
    "\n",
    "Une stratégie intermédiaire consiste à prendre la combinaison convexe des deux normes :\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\boldsymbol{\\beta})=\\eta \\lVert \\boldsymbol{\\beta} \\rVert_1 + (1-\\eta) \\lVert \\boldsymbol{\\beta} \\rVert_2.\n",
    "\\end{equation}\n",
    "\n",
    "avec $\\eta\\in\\big[0,1\\big]$. On parle alors d'*elastic-net*.\n",
    "\n",
    "Ces différentes régularisations ne se comportent pas de la même manière. Ainsi la régularisation $\\ell_1$, aussi appelée Lasso, va forcer certains paramètres à atteindre la valeur $0$. Cela permet par exemple de favoriser l'explicabilité de notre modèle. En pratique, $\\ell_2$, appelée Ridge, a tendance à donner les meilleurs résultats d'un point de vue prédictif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta_cube = np.random.uniform(-4, 4, size=(4,1))\n",
    "\n",
    "def sample_data_cube(n, sigma=1):\n",
    "    X = np.random.normal(0, sigma, size=n)\n",
    "    noise = np.random.normal(1, 1, size=n)/2\n",
    "    y = beta_cube[3] * X ** 3 + beta_cube[2] * X ** 2 + beta_cube[1] * X + beta_cube[0] + noise\n",
    "    return X, y\n",
    "X, y = sample_data_cube(20)\n",
    "X_test, y_test = sample_data_cube(150)\n",
    "\n",
    "X = X.reshape((X.shape[0], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1))\n",
    "\n",
    "plot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(10), LinearRegression())\n",
    "model.fit(X, y)\n",
    "\n",
    "plot(X_test, y_test, func=model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec régularisation $\\ell_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on parle de régresion linéaire avec régularisation $\\ell_1$, on parle aussi de Lasso.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Testez plusieurs valeurs de $\\alpha$ ($=\\lambda$ dans notre texte). Quelle est la fonction la plus parcimonieuse que vous arrivez à obtenir ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(10), Lasso(alpha=15.))\n",
    "model.fit(X, y)\n",
    "\n",
    "plot(X_test, y_test, func=model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Les paramètres du modèle sont sparses :\\n', model[1].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez du constater que selon la quantité de régularisation, les paramètres étaient plus ou moins sparse. Il se trouve qu'une fois qu'un paramètre est à 0, il le sera pour toutes les valeurs de $\\alpha$ suppérieures. Afin d'observer visuellement, l'effet de la régularisation sur la sparsité, il est possible d'afficher ce qu'on appelle les \"chemins Lasso\" ou Lasso paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lars_path\n",
    "features = PolynomialFeatures(10)\n",
    "X_transformed = features.fit_transform(X)\n",
    "_, _, coefs = lars_path(X_transformed, y, method='lasso', verbose=True)\n",
    "\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "# plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gauche se trouve le paramètre le plus parcimonieux (la plus grande valeur de $\\alpha$). Tous les paramètres y sont donc nuls. Plus la valeur de $\\alpha$ est réduite, plus le nombre de paramètres différents de $0$ augmente et leur valeur aussi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec régularisation $\\ell_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on parle de régresion linéaire avec régularisation $\\ell_2$, on parle aussi de Ridge.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Testez plusieurs valeurs de $\\alpha$ ($=\\lambda$ dans notre texte). Quelle est la fonction la plus parcimonieuse que vous arrivez à obtenir ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(10), Ridge(alpha=1000))\n",
    "model.fit(X, y)\n",
    "\n",
    "plot(X_test, y_test, func=model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec régularisation *elastic-net*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on parle de régresion linéaire avec régularisation *elastic-net*.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Testez plusieurs valeurs de $\\alpha$ ($=\\lambda$ dans notre texte). Quelle est la fonction la plus parcimonieuse que vous arrivez à obtenir (Essayez de trouver la réponse en raisonnant) ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(10), ElasticNet(alpha=20, l1_ratio=0.8))\n",
    "model.fit(X, y)\n",
    "\n",
    "plot(X_test, y_test, func=model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Selection de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pratique, nous ne pouvons pas choisir la valeur des paramètres (e.g. degré, régularisation) à l'oeil comme précédemment. Il nous faut (1) un algorithme qui automatise cette tâche et (2) une stratégie d'évaluation rigoureuse afin d'éviter les biais de confirmation (sur-apprentissage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta_cube = np.random.uniform(-4, 4, size=(4,1))\n",
    "\n",
    "def sample_data_cube(n, sigma=1):\n",
    "    X = np.random.normal(0, sigma, size=n)\n",
    "    noise = np.random.normal(1, 1, size=n)/2\n",
    "    y = beta_cube[3] * X ** 3 + beta_cube[2] * X ** 2 + beta_cube[1] * X + beta_cube[0] + noise\n",
    "    return X, y\n",
    "X, y = sample_data_cube(50)\n",
    "X_test, y_test = sample_data_cube(150)\n",
    "\n",
    "X = X.reshape((X.shape[0], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1))\n",
    "\n",
    "plot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche exhaustive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme de recherche par grille va exhaustivement testé tous les paramètres donnés. Pour chacun combinaison, une validation *k-fold* est réalisée. Le modèle retenu sera celui qui aura maximisé son score moyen lors du *k-fold*.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Utilisez l'objet $\\texttt{GridSearchCV}$ afin de trouver la meilleure combinaison de paramètres selon le dictionnaire décrit ci-dessous. Toutes les combinaisons seront-elles réellement testées ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet, Ridge, LinearRegression, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'model': [LinearRegression()], \n",
    "   'poly__degree': [1, 2, 3, 4, 5]},\n",
    "  {'model': [Ridge()], \n",
    "   'poly__degree': [1, 2, 3, 4, 5], \n",
    "   'model__alpha': [0., 0.1, 0.2, 0.5, 0.8, 10., 100., 100.]},\n",
    "  {'model': [Lasso()], \n",
    "   'poly__degree': [1, 2, 3, 4, 5],\n",
    "   'model__alpha': [0., 0.1, 0.2, 0.5, 0.8]},\n",
    "  {'model': [ElasticNet()], 'poly__degree': [1, 2, 3, 4, 5],\n",
    "  'model__alpha': [0., 0.1, 0.2, 0.5, 0.8, 10., 100., 100.],\n",
    "  'model__l1_ratio': [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9, 1.]},\n",
    " ]\n",
    "\n",
    "pipe = Pipeline(steps=[('poly', PolynomialFeatures(10)), ('model', LinearRegression())])\n",
    "####### Complete this part ######## or die ####################\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(X, y)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Le meilleur modele est', search.best_estimator_)\n",
    "plot(X_test, y_test, func=search.best_estimator_.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une recherche exhaustive peut rapidement être limitante. Imaginons que nous testions déjà $10000$ combinaisons de paramètres. Rajoutons maintenant un paramètre avec 50 modalités. Le nombre de combinaisons est donc multiplié par $50$ et on monte à $500000$ combinaisons. L'algorithme devient $50$ fois plus lent. \n",
    "\n",
    "Une stratégie alternative est de s'appuyer sur le hasard. On peut spécifier a priori des distributions sur les paramètres en supposant que certaines combinaisons fourniront probablement plus de bons résultats que d'autres. Par défaut, le tirage est uniforme. Cette méthode n'est pas absurde car plusieurs combinaisons peuvent très bien obtenir des résultats très proches. L'approche aléatoire sera ainsi beaucoup plus efficaces que la recherche exhaustive pour des performances généralement assez proches.\n",
    "\n",
    "---\n",
    "**<span style=\"color:blue\"> Exercice :</span>** **Complétez le code ci-dessous afin de réaliser une recherche randomisée. Quel paramètre permet de jouer sur le nombre de tirages ?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'model': [LinearRegression()], \n",
    "   'poly__degree': [d for d in range(1, 20)]},\n",
    "  {'model': [Ridge()], \n",
    "   'poly__degree': [d for d in range(1, 20)], \n",
    "   'model__alpha': [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1., 10., 100., 100.]},\n",
    "  {'model': [Lasso()], \n",
    "   'poly__degree': [d for d in range(1, 20)],\n",
    "   'model__alpha': [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]},\n",
    "  {'model': [ElasticNet()], 'poly__degree': [d for d in range(1, 20)],\n",
    "  'model__alpha': [0.1, 0.2, 0.5, 0.8, 10., 100., 100.],\n",
    "  'model__l1_ratio': [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9, 1.]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('poly', PolynomialFeatures(10)), ('model', LinearRegression())])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Le meilleur modele est', search.best_estimator_)\n",
    "plot(X_test, y_test, func=search.best_estimator_.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "search = RandomizedSearchCV(pipe, param_grid, n_jobs=-1, n_iter=200)\n",
    "search.fit(X, y)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Le meilleur modele est', search.best_estimator_)\n",
    "plot(X_test, y_test, func=search.best_estimator_.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Le mot de la fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce propos introductif nous a permis de toucher du doigt la notion de sur-apprentissage. Quand est-ce que le meilleur modèle sur notre jeu d'apprentissage est suffisament bon en général ? Quand peut-on considérer qu'un modèle est suffisamment bon ? Aurions-nous pu trouver un meilleur modèle avec une procédure d'apprentissage différente ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
