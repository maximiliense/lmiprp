{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strategic-appeal",
   "metadata": {},
   "source": [
    "# *Machine learning* et malédiction de la dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-conference",
   "metadata": {},
   "source": [
    "Quelques liens pour plus de détails :\n",
    "* [Overfitting](https://github.com/maximiliense/lmpirp/blob/main/Notes/Overfitting.pdf)\n",
    "* [KNN](https://github.com/maximiliense/lmpirp/blob/main/Notes/KNN.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-switch",
   "metadata": {},
   "source": [
    "**Objectif :** Cette séquence a pour objectif d'introduire les bases du *machine learning* illustrées via quelques algorithmes particuliers. Il s'agit de sensibiliser à l'idée de classification, régression, supervisé ou non supervisé, à la notion de sur-apprentissage ainsi qu'à la malédiction de la dimension.\n",
    "\n",
    "Des approfondissements et d'autres modèles seront présentés au travers des différentes séquences qui composent ce cours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-gallery",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-myanmar",
   "metadata": {},
   "source": [
    "Imaginons que nous souhaitions construire une application qui prendrait en entrée une image de chien ou de chat et doive prédire laquelle des deux espèces est représentée. Imaginons encore une application qui prendrait en entrée un mail qu'elle classifierait comme SPAM ou NONSPAM. Supposons qu'il existe deux catégories de clients qu'on ne connait pas *a priori* et que l'entreprise souhaite prédire pour chacun des clients sa catégorie. On peut vouloir prédire la température qu'il fera demain à partir de données relevées aujourd'hui.\n",
    "\n",
    "Une constante est partagée par l'ensemble de ces scénarios. Il y a tout d'abord une donnée d'entrée plus ou moins complexe et structurée. On notera $\\mathcal{X}$ l'espace auquel elle appartient. Ensuite, à partir de cette donnée, l'objectif est de faire une prédiction. Notons $\\mathcal{Y}$ l'espace auquel appartient cette prédiction. On appelle ça aussi nos labels ou nos variables à expliquer. Notre objectif, en tant que *machine learner* est de construire une fonction $h:\\mathcal{X}\\mapsto\\mathcal{Y}$ qui aura de *bonnes performances* \"en production\", c'est-à-dire sur des données nouvelles que nous n'avons jamais vu (i.e. on ne veut pas prédire la météo d'hier à partir d'avant hier, mais bien de demain à partir d'aujourd'hui). \n",
    "\n",
    "Deux types d'apprentissage sont généralement opposés : l'apprentissage supervisé (AS) et non-supervisé (ANS).\n",
    "\n",
    "### A. L'apprentissage supervisé\n",
    "\n",
    "L'apprentissage supervisé part du principe que (1) nos labels (i.e. l'espace $\\mathcal{Y}$) est bien défini et (2) que nous avons accès à des données associant des éléments de $\\mathcal{X}$ à leur label $\\mathcal{Y}$.\n",
    "\n",
    "On parlera de problème de régression si par exemple $\\mathcal{Y}\\subseteq\\mathbb{R}$ ou de problème de classification si $\\mathcal{Y}=\\{1, \\ldots, C\\}$ où l'ordre n'est pas important. Par exemple, prédire la température est un problème de régression alors que prédire si la photo représente un chien ou un chat est un problème de classification.\n",
    "\n",
    "A fortiori, toutes les observations dans $\\mathcal{X}$ ne sont pas nécessairement équiprobables. Certains clients ont peut-être, par exemple, un profil plus commun que d'autres. Afin de pouvoir définir plus rigoureusement ce qu'on entend pas *bonnes performances*, notons $X\\in\\mathcal{X}$ une variable aléatoire qui décrit nos données observées et $Y\\in\\mathcal{Y}$ la variable aléatoire associée à nos labels. Assez naïvement, notons $\\mathbb{P}$ la loi de notre couple $X,Y$ :\n",
    "\n",
    "$$X, Y\\sim \\mathbb{P}.$$\n",
    "\n",
    "Notons $r:\\mathcal{Y}\\times\\mathcal{Y}\\rightarrow\\mathbb{R}^+$ une mesure d'erreur, un risque élémentaire. On a par exemple, dans le cas d'un problème de régression, l'erreur quadratique :\n",
    "\n",
    "$$r(\\hat{y}, y)=(\\hat{y}-y)^2,$$\n",
    "\n",
    "où $\\hat{y}$ est la prédiction que ferait notre modèle. Ou encore, dans le cas de la classification cette fois-ci l'erreur $0.1$ :\n",
    "\n",
    "$$r(\\hat{y}, y)=\\textbf{1}\\{\\hat{y}\\neq y\\},$$\n",
    "\n",
    "qui vaut $1$ si la prédiction est mauvaise ou $0$ sinon.\n",
    "\n",
    "Notre objectif est tout naturellement de trouver une application $h:\\mathcal{X}\\mapsto\\mathcal{Y}$ telle que $R(h)=\\mathbb{E}\\big[r(h(X), Y)\\big]$ est petit. On veut un bon modèle sur de nouvelles données. L'idée va être de collecter des données représentatives (dans le sens iid) et de construire notre modèle avec ces dernières. Notons :\n",
    "\n",
    "$$S_n=\\{(X_i, Y_i)\\}_{i\\neq n}$$\n",
    "\n",
    "un jeu de données de taille $n$.\n",
    "\n",
    "### B. L'apprentissage non-supervisé\n",
    "\n",
    "Ici, c'est l'inverse. Nous avons accès à l'espace des observations $\\mathcal{X}$ duquel on peut collecter des données (toujours selon la loi de la variable aléatoire $X$). On sait qu'il existe un espace $\\mathcal{Y}$ cible mais (1) il n'est pas nécessairement connu et (2) nous ne connaissons pas d'exemple de liens entre exemples d'apprentissage et cibles associées. \n",
    "\n",
    "Par exemple, si $\\mathcal{X}$ représente des données clients, on peut savoir (se douter) qu'il existe des groupes de clients qui se ressemblent mais ne pas les connaître et ne pas savoir combien il y en a. Il s'agit ici d'une tâche de *clustering* où on cherche à regroupe des données entre-elles toujours de manière à ce que le regroupement généralise à de nouvelles données.\n",
    "\n",
    "On peut chercher à transformer nos données dans $\\mathcal{X}$ dans un espace qu'on notera cette fois-ci $\\mathcal{Z}$ où ces dernières auront de meilleures propriété. On note cet \"espace de représentation\" $\\mathcal{Z}$ et non $\\mathcal{Y}$ car il s'agit souvent d'une étape intermédiaire avant une tâche supervisé où on chercherait à prédire un label dans $\\mathcal{Y}$. C'est ce qu'on appelle l'apprentissage de représentation. Ainsi, si $\\mathcal{X}$ est l'ensemble des photos de chiens et de chats, $\\mathcal{Z}$ est l'ensemble de ces dernières où on a mis \"d'un côté\" les photos de chiens et de \"l'autres\" celles de chats. Il devient simple de construire une tâche supervisée permettant de prédire le bon label \"chien/chat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-racing",
   "metadata": {},
   "source": [
    "## II. On casse une idée préconçue (AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-audit",
   "metadata": {},
   "source": [
    "Soit $S=\\{(x_i, y_i)\\}_{i\\leq n}$ un jeu de données représentatif de taille $n$. Un modèle très performant sur ces données est-il performant sur des données nouvelles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "under-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-stomach",
   "metadata": {},
   "source": [
    "Chargeons et affichons notre jeu de données. Ce dernier consiste en des chiffres écrits à la main. L'objectif va être de faire un modèle qui permet de prédire ces derniers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "golden-region",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAACXCAYAAAARS4GeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAALBUlEQVR4nO3dX2yd510H8O+vi8ooW2tnE0wU1sSdBAK0mqZTmZBQqjnSuJgcMRJNDDRXmhJxA5G4cG5gjsZQghByxYYWEGoZMFgjIJ2QCmq0uqMXgGLhTipsF2lamNikQp1uHfsjwcvFcUbUpmnzvufkxE8+HymSz+n5vs9j95dzvnlfH7u6rgsAQMtumvYGAAAmTeEBAJqn8AAAzVN4AIDmKTwAQPMUHgCgeU0Xnqp6tKo+NO7HcmMxRwxlhhgHczRMXW8/h6eqXrrk5i1Jvp3kf7ZuH+667s+u/a7Gq6rek+QTSd6e5B+TLHVd99x0d9WW1ueoqm5O8ukk9yS5I8l9XdetTXVTjbkBZuinknw0yZ6MPq+1JL/Sdd1Xprmv1twAc/RjST6V5M6tu9YzmqN/md6uLu+6O8PTdd2bLv5J8m9J3nfJfd8djKraMb1d9ldVb03yV0l+PcnOJGeTfGaqm2pQ63O05ckkv5jkq9PeSItugBmaTfIHSXZlVJq/nuTBaW6oRTfAHP1Hkp/P6PXsrUk+m+QvprqjV3HdFZ5XU1V7q+rLVbVcVV9N8mBVzVbV31TV81W1ufXxD12SWauqD299vFRVT1bV72w99nxV/WzPx+6uqs9X1der6kxVfaKq/vR1fio/l+TprutOdV33rSQrSe6qqh8d/lXitbQyR13XfafrutWu657M//9rkWugoRl6dOt56Gtd1/13ko8n+ekxfZl4DQ3N0YWu657tRpeLKqPno3eM56s0Xtum8Gx5W0Yt8o4khzLa/4Nbt9+e5JsZ/aV9Nfcm+VJGLfS3k/xRVVWPx346yT8leUtGheWXLg1W1Req6hde5bg/nuSpize6rvtGknNb93NttDBHTFeLM/QzSZ5+nY9lPJqZo6q6kORbSX4vyW9d6bHTst1Oof1vko90XfftrdvfTPKXF/9jVX0syeNXyD/Xdd0fbj32j5P8fpIfyOUvCVz2sTX63ol3JXlP13XfSfJkVX320mDXde+8wh7elOT5l933YpI3XyHDeLUwR0xXUzNUVe9M8htJFl/P4xmbZuao67qZqvq+JB9Kcl1+T+p2O8Pz/NZloCRJVd1SVSer6rmq+lqSzyeZqao3vEr+u0OwdQo3GRWQq3nsDyZ54ZL7kuTfr+JzeCnJrS+779aMrp9zbbQwR0xXMzNUVe9I8miSX+267u+vNs8gzczR1nG/keSTST5VVd/f5xiTtN0Kz8vfUvZrSX4kyb1d192a0SnZZHQdcVK+kmRnVd1yyX0/fBX5p5PcdfHGViO+M04lX0stzBHT1cQMVdUdSc4k+WjXdX8yzs3xujQxRy9zU0bvRrt90K4mYLsVnpd7c0anAC9U1c4kH5n0gltvHz+bZKWqbq6qdyd531Uc4q+T/ERVvb+q3pjRaeQvdF33xQlsl9dnO85Rqup7tmYoSW6uqjde4fo9k7XtZqiqbk/yuSQf77rukxPaJldnO87Rvqr6yap6Q1XdmuR3k2wm+dfJ7Li/7V54VpN8b5L/TPIPSf72Gq37wSTvTvJfSX4zo7eVX7wGm6p6uqo+eLlg13XPJ3l/ko9lNBT3JvnApDfMFa1mm83Rli9l9OR4e5K/2/r4jontlitZzfaboQ8nmcvohe6li38mvWGuaDXbb45mkvx5Rt+Lei6jKxbvvfRS3fXiuvvBg9tRVX0myRe7rpt4G6dd5oihzBDj0OocbfczPFNRVe+qqjur6qaqem9G72w4PeVtsc2YI4YyQ4zDjTJH2+1t6deLt2X005LfkuTLSX6567p/nu6W2IbMEUOZIcbhhpgjl7QAgOa5pAUANO+1LmlN5fTPqVOnBuWXl5d7Z/ft29c7e/z48d7Z2dnZ3tkxmPRbmbflacS9e/f2zl64cKF39tixY72zi4tT/UG5k5yjbTlDa2trvbP79+/vnZ2fn++dHbLnMWjyuejEiROD8kePHu2d3b17d+/s+vp67+z1+JrmDA8A0DyFBwBonsIDADRP4QEAmqfwAADNU3gAgOYpPABA8xQeAKB5Cg8A0DyFBwBonsIDADRP4QEAmqfwAADNU3gAgObtmPYGLmd5eXlQ/vz5872zm5ubvbM7d+7snX344Yd7Z5PkwIEDg/K80szMTO/sE0880Tv7+OOP984uLi72zvJKGxsbg/L33Xdf7+xtt93WO/vss8/2znJ5R48e7Z0d+vx+8uTJ3tnDhw/3zq6vr/fOLiws9M5OijM8AEDzFB4AoHkKDwDQPIUHAGiewgMANE/hAQCap/AAAM1TeACA5ik8AEDzFB4AoHkKDwDQPIUHAGiewgMANE/hAQCat2NSBx7ya+XPnz8/aO1z5871zs7NzfXO7tu3r3d2yNcrSQ4cODAo36KNjY1B+bW1tbHs42rNz89PZV1e6fTp04Pyd911V+/s/v37e2ePHTvWO8vlHTp0qHd2eXl50Np79uzpnd29e3fv7MLCQu/s9cgZHgCgeQoPANA8hQcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDmKTwAQPMUHgCgeQoPANA8hQcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDm7ZjUgTc3N3tn77777kFrz83NDcr3tWfPnqms27LV1dXe2ZWVlUFrv/jii4Pyfe3du3cq6/JKR44cGZTftWvXVNZeXFzsneXyhryuPPPMM4PWPn/+fO/swsJC7+yQ1/HZ2dne2UlxhgcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDmKTwAQPMUHgCgeQoPANA8hQcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDmKTwAQPN2TOrAQ36t/L59+8a4k2tnyOc8Ozs7xp2048iRI72zS0tLg9ae1v+TCxcuTGXdVg35eq6urg5a+/Tp04PyfT300ENTWZfLm5ubG5R/4YUXemcXFhamkj1z5kzvbDKZ519neACA5ik8AEDzFB4AoHkKDwDQPIUHAGiewgMANE/hAQCap/AAAM1TeACA5ik8AEDzFB4AoHkKDwDQPIUHAGiewgMANG/HpA485Fe7r6+vj3EnV2dzc7N39uzZs72zBw8e7J2lLRsbG72z8/PzY9tHK1ZWVnpnH3jggfFt5CqdPn26d3ZmZmZs+2D6hryenjlzpnf28OHDvbMnTpzonU2S48ePD8pfjjM8AEDzFB4AoHkKDwDQPIUHAGiewgMANE/hAQCap/AAAM1TeACA5ik8AEDzFB4AoHkKDwDQPIUHAGiewgMANE/hAQCat2NSB56bm+udPXv27KC1T506NZXsEMvLy1NZF1q3tLTUO7u2tjZo7aeeeqp3dv/+/b2zi4uLvbP3339/7+zQtVt19OjRQfmFhYXe2c3Nzd7Zxx57rHf24MGDvbOT4gwPANA8hQcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDmKTwAQPMUHgCgeQoPANA8hQcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDmKTwAQPN2TOrAc3NzvbMnTpwYtPby8nLv7D333NM7u76+3jvL+M3MzAzKLy4u9s4+8sgjvbNra2u9s0tLS72zrZqfn++d3djYGLT2kPzKykrv7JD527VrV+9sMuzvTatmZ2cH5Q8dOjSmnVydgwcP9s6ePHlyjDsZD2d4AIDmKTwAQPMUHgCgeQoPANA8hQcAaJ7CAwA0T+EBAJqn8AAAzVN4AIDmKTwAQPMUHgCgeQoPANA8hQcAaJ7CAwA0r7qum/YeAAAmyhkeAKB5Cg8A0DyFBwBonsIDADRP4QEAmqfwAADN+z+hHt0iyNm/ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-canon",
   "metadata": {},
   "source": [
    "Construisons notre premier modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memorize(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            memorized = False\n",
    "            for j in range(self.X.shape[0]):\n",
    "                if (self.X[j] == X[i]).sum() == X.shape[1]:\n",
    "                    y[i] = self.y[j]\n",
    "                    memorized = True\n",
    "                    break\n",
    "            if not memorized:\n",
    "                y[i] = np.random.randint(0, 10)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-ontario",
   "metadata": {},
   "source": [
    "Les données de test nous permettront de tester notre modèle sur des données qu'il n'a pas utilisé pour se construire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Memorize(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-person",
   "metadata": {},
   "source": [
    "On commence par tester les performances de notre modèle sur notre jeu d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Classification report for classifier Memorize on train:\\n'\n",
    "      f'{metrics.classification_report(y_train, predicted)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-stroke",
   "metadata": {},
   "source": [
    "Notre modèle est parfait ! Aucune erreur. On ne peut pas faire mieux ! Et du côté du test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Classification report for classifier Memorize on test:\\n'\n",
    "      f'{metrics.classification_report(y_test, predicted)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-prison",
   "metadata": {},
   "source": [
    "C'est ridiculement mauvais : on se trompe une fois sur dix, soit exactement ce qu'on attendrait d'une réponse aléatoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-terry",
   "metadata": {},
   "source": [
    "Oui mais on a fait exprès de construire le modèle de cette manière ! En réalité, il existe une infinité fonction, paramétriques ou non, qu'on peut rendre aussi bonne qu'on veut sur nos données mais qui seraient particulièrement mauvaises sur de nouvelles données (cela inclut les modèles usuels et c'est pour cela qu'on a besoin d'experts !)... Toute la difficulté du *machine learner* va être de contrôler cela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-canvas",
   "metadata": {},
   "source": [
    "## III. Une autre première approche logique : le KNN (AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-puppy",
   "metadata": {},
   "source": [
    "Intuitivement, on a envie de dire que nos données ne sont pas complètement déstructurées. Deux clients très similaires achèteront très probablement des produits très similaires. Un trois ressemble plus à un trois qu'à un cinq et un cinq ressemble plus à un cinq qu'à un trois. Finalement, on généralise un petit peu l'exemple précédent. Au lieu de répondre aléatoirement si je ne connais pas la donnée, je cherche l'exemple le plus proche et je prédis le même label ! Plus rigoureusement, notre modèle de prédiction fonctionne comme suit : \n",
    "\n",
    "$$\\hat{y}_\\text{new}=y\\text{ avec }(x, y)=\\text{argmin}_{(x, y)\\in S}\\lVert x-x_{\\text{new}}\\rVert_2.$$\n",
    "\n",
    "On peut imaginer que si plusieurs points sont équidistants, la réponse se fait aléatoirement entre les labels possibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-cinema",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Utilisez l'objet $\\texttt{KNeighborsClassifier}$ avec le paramètre $\\texttt{n}\\_\\texttt{neighbors=1}$ et entraînez le sur $\\texttt{X}\\_\\texttt{train}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-symphony",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train, y_train)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-addiction",
   "metadata": {},
   "source": [
    "On teste maintenant sur le jeu de train pour avoir une idée des performances de notre modèle sur ce dernier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Classification report for classifier {model} on train:\\n'\n",
    "      f'{metrics.classification_report(y_train, predicted)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-right",
   "metadata": {},
   "source": [
    "On est toujours aussi bon sur le jeu d'apprentissage ! Cependant, c'est attendu car l'image qui ressemble le plus à une autre est l'image elle-même. Prédisons maintenant sur le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Classification report for classifier {model} on test:\\n'\n",
    "      f'{metrics.classification_report(y_test, predicted)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "disp = metrics.plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-doubt",
   "metadata": {},
   "source": [
    "Is Machine learning solved ? Minute papillon ! Ce modèle est très sensible au bruit ! Supposons qu'une de nos données soient bruitées (e.g. un 3 qui ressemble à un 8). Si une nouvelle donnée représentant un $8$ se retrouve à côté de cette anomalie, elle sera mal prédite. Nous pouvons adresser cette limite de la manière suivante : au lieu de regarder le point le plus proche, on regarde les $k$ points les plus proches et on fait un vote à la majorité. Plus formellement la prédiction est faite comme suit :\n",
    "\n",
    "$$\\hat{y}_\\text{new}=\\text{majority$\\_$voting}(\\texttt{KNN}.\\texttt{labels})\\text{ où }\\texttt{KNN}=\\text{argmin}_{S^\\prime\\subset S,\\ |S^\\prime|=K}\\sum_i \\lVert x_i- x_{\\text{new}}\\rVert.$$\n",
    "\n",
    "Dans le cas où on chercherait à faire une régression, on remplace le vote à la majorité par une moyenne.\n",
    "\n",
    "Récupérons le jeu de données $\\texttt{iris}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "# décommentez la ligne suivante pour obtenir des informations\n",
    "# sur le dataset iris.\n",
    "# print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-bottom",
   "metadata": {},
   "source": [
    "De la même manière que précédemment, on construit notre jeu d'apprentissage pour construire notre modèle et notre jeu de test pour en tester les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.5, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-syndicate",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Utilisez l'objet $\\texttt{KNeighborsClassifier}$ avec le paramètre $\\texttt{n}\\_\\texttt{neighbors=1}$ et entraînez le sur $\\texttt{X}\\_\\texttt{train}$. Faites une prédiction sur $\\texttt{predicted=X}\\_\\texttt{test}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-navigator",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "disp = metrics.plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-graphic",
   "metadata": {},
   "source": [
    "Les performances sont déjà très bonnes ! Mais il est possible de gagner un tout petit peu de performances en considérant plus de voisins :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-values",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Utilisez l'objet $\\texttt{KNeighborsClassifier}$ avec le paramètre $\\texttt{n}\\_\\texttt{neighbors=10}$ et entraînez le sur $\\texttt{X}\\_\\texttt{train}$. Faites une prédiction sur $\\texttt{predicted=X}\\_\\texttt{test}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-absolute",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "disp = metrics.plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-brunei",
   "metadata": {},
   "source": [
    "## IV. Les arbres de décision ou Classification and regression Tree (CART) (AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-oasis",
   "metadata": {},
   "source": [
    "De la même manière que pour l'algorithme KNN, on supposera ici que nos données admettent une certaine structure et que des points proches possèdent probablement le même label ou une prediction proche dans le cas de la régression. Ici, à la différence du KNN, la notion de voisinage se construit au travers d'hyperrectangles parallèles aux axes. Afin de bien comprendre le fonctionnement, supposons que notre arbre de décision soit déjà construit. Prenons une nouvelle données $x_{\\text{new}}=[3, 5]^T$ et partons de la racine de notre arbre. Cette racine possède deux branches sortantes. Le choix de la branche se fait à partir d'un seuil (paramètre associé au noeud racine) et d'une coordonnée de notre $x$. Dans notre exemple imaginons que le seuil soit $7$ et que la coordonnée à regarder soit $x_{\\text{new}}^{(1)}=5$. C'est clairement inférieur à $7$ et nous partons donc la branche de gauche de notre arbre. Nous somme sur un nouveau noeud associé à un nouveau seuil et une nouvelle coordonnée de notre donnée. On répète cette opération jusqu'à ce qu'on arrive aux feuilles de notre arbre. Chaque feuille regroupe les données du jeu d'apprentissage qui y aboutisse lorsqu'on les classe. Le choix du label se fait par un vote à la majorité sur ces données ou en moyennant. L'image suivante illustre cette idée :\n",
    "\n",
    "![Decision tree](https://miro.medium.com/max/360/1*XMId5sJqPtm8-RIwVVz2tg.png)\n",
    "\n",
    "\n",
    "\n",
    "Le choix de la règle de décision à chaque noeud peut être adapter afin d'obtenir des régions à la géométrie variable. La construction d'un arbre se fait en partant de la racine vers les feuilles et en choisissant intérativement les variables explicatives qui ont le plus d'effet sur notre prédiction (via diverses critères)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-scope",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Utilisez l'objet $\\texttt{DecisionTreeClassifier}$ avec le paramètre $\\texttt{n}\\_\\texttt{max}\\_\\texttt{depth=10}$ et entraînez le sur $\\texttt{X}\\_\\texttt{train}$. Faites une prédiction sur $\\texttt{predicted=X}\\_\\texttt{test}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-check",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "disp = metrics.plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-future",
   "metadata": {},
   "source": [
    "## V. Les forêts aléatoires ou Random Forest (RF) (AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-narrow",
   "metadata": {},
   "source": [
    "Les arbres de décision peuvent être sujets au surapprentissage. Une manière de compenser le problème est d'en construire plusieurs où chaque arbre est construit en ne voyant qu'une partie des données. Enfin leurs prédictions sont aggrégées. Ces approches sont généralement beaucoup plus performantes que les arbres simples. Malheureusement, autant avec un arbre simple on pouvait essayer de comprendre la prédiction, autant ici, cela devient difficile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-august",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Utilisez l'objet $\\texttt{RandomForestClassifier}$ et entraînez le sur $\\texttt{X}\\_\\texttt{train}$. Faites une prédiction sur $\\texttt{predicted=X}\\_\\texttt{test}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-mention",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "disp = metrics.plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-british",
   "metadata": {},
   "source": [
    "## VI. Choix des hyperparamètres (AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-armstrong",
   "metadata": {},
   "source": [
    "Nous avons du, pour les modèles précédents, choisir différents paramètres qui affectaient les performances de notre modèle. Nous les avons choisi en regardant les performances de notre modèle sur le jeu de test. Cependant, les bonnes performances étaient peut-être un coup de chance !\n",
    "\n",
    "Il existe deux stratégies d'évaluation sans biais de la qualité de notre modèle :\n",
    "* La validation non croisée où une partie de notre jeu de donnée est cachée pendant l'apprentissage puis utilisée afin d'évaluer les performances du modèle. Il s'agit du découpage train/test. Cette stratégie est un estimateur sans biais de la qualité de notre modèle mais possède une variance plus forte que la validation croisée. Elle peut-être particulièrement utile lorsque le coup d'apprentissage d'un modèle est très élevé (e.g. *deep learning*)\n",
    "* La validation croisée où notre jeu de données est divisé en *k* parties (on parle aussi de *k-fold*). Évidemment, $k\\in\\{2, ..., n\\}$ où $n$ est la taille du jeu de données. Chacune des parties jouera successivement le rôle de jeu de test pendant que les $k-1$ autres parties serviront à calculer notre modèle. Le résultat de cette procédure est un vecteur de $k$ scores dont on peut calculer la moyenne, la variance, etc.\n",
    "\n",
    "On peut illustrer la méthode des *k-folds* via l'exemple suivant :\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Appartient au train set: } \\color{red}{\\boxed{}}&\\text{ et appartient au test set: }\\color{green}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 1: }\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 2: }\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 3: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 4: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 5: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 6: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\\color{red}{\\boxed{}}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\text{Step 7: }\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}&\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{red}{\\boxed{}}\\color{green}{\\boxed{}}\n",
    "\\end{align}\n",
    "\n",
    "La méthode $\\texttt{cross_val_score}$ de $\\texttt{sklearn}$ permet de réaliser cette procédure. On pourra renseigner le paramètre $\\texttt{cv}$ qui indique le nombre $k$ et le paramètre $\\texttt{scoring}$ qui donne la métrique que l'on souhaite calculer.\n",
    "\n",
    "Si on cherche à trouver une valeur d'un paramètre, l'objet $\\texttt{GridSearchCV}$ applique une validation croisée en cherchant différentes valeurs d'un paramètres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [2, 3, 4, 5, 10, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-status",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Utilisez l'objet $\\texttt{GridSearchCV}$ pour faire une recherche par grille sur le modèle $\\texttt{RandomForestClassifier}$ et entraînez le sur $\\texttt{X}\\_\\texttt{train}$.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-attempt",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "model = GridSearchCV(RandomForestClassifier(), params)\n",
    "model.fit(X_train, y_train)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "disp = metrics.plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-current",
   "metadata": {},
   "source": [
    "Notre RandomForest de base était déjà très bon !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-execution",
   "metadata": {},
   "source": [
    "## VII. L'algorithme des K-Moyennes (ANS)\n",
    "\n",
    "Il s'agit ici d'un algorithme non supervisé. Imaginons que nous ayons un collecté un jeu de données $S_n=\\{(X_i)\\}_{i\\leq n}$. On sait qu'il existe des groupes dans nos données. Supposons même qu'on sâche qu'il existe $K$ groupes. L'idée de l'algorithme des K-Moyennes va être de détecter ces $K$ groupes en trouvant une solution au problème d'optimisation suivant : \n",
    "\n",
    "$$\\text{KMeans}=\\text{argmin}_{m_1, \\ldots, m_K\\in\\mathcal{X}, c_1,\\ldots,c_n\\in\\{1,\\ldots,K\\}}\\sum_{i=1}^K\\sum_{j=1}^n\\textbf{1}\\{c_1=i\\}\\lVert m_i-x_j\\rVert_2=\\text{argmin}_{m_1, \\ldots, m_K\\in\\mathcal{X}, c_1,\\ldots,c_n\\in\\{1,\\ldots,K\\}}\\sum_{j=1}^n\\lVert x_j-m_{c_j}\\rVert_2.$$\n",
    "\n",
    "Dit autrement, chaque groupe est représentée par une coordonnée $c_i$ (qui s'avère être la moyenne des éléments du groupe) et chaque élément de notre jeu de données n'est associé qu'à un seul groupe. L'objectif va être que leur distance quadratique au centre de leur groupe doit être minimale !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-battlefield",
   "metadata": {},
   "source": [
    "Considérons le jeu de données suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "normal-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_data(n):\n",
    "    means = np.array([[-0.5, 0.5], [1, 1], [0.5, -0.5]])\n",
    "    cov = np.diag([1, 1])/15\n",
    "    X = np.concatenate([\n",
    "        np.random.multivariate_normal(m, cov, size=n) for m in means\n",
    "    ], axis=0)\n",
    "    y = [i//n for i in range(3*n)]\n",
    "    return X, y\n",
    "    \n",
    "X, y = sample_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "final-bradford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_clusters(X, c, means=None, path=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.axis('off')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=c)\n",
    "    plt.title('Nos données et leur label inconnu')\n",
    "    if means is not None:\n",
    "        for m in means:\n",
    "            plt.scatter([m[0]], [m[1]], s=55, color='red')\n",
    "    if path is not None:\n",
    "        for p in path:\n",
    "            plt.plot(p[:, 0], p[:, 1], color='red')\n",
    "    plt.show()\n",
    "plot_clusters(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-bishop",
   "metadata": {},
   "source": [
    "Le problème de K-Means est NP-Difficile. Pour cela, nous utilisons en pratique un heuristique appelé \"algorithme de LLoyd\" qui fonctionnde la manière suivante :\n",
    "\n",
    "1.  On initialise les k moyennes\n",
    "2.  On assigne tous nos points à leur moyenne la plus proche\n",
    "3.  On met à jour les moyennes avec les nouveaux points\n",
    "4.  Si le déplacement des moyennes est significatif, on reprend à l'étape 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-ribbon",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Le problème est NP-Difficile et un algorithme permettant de le résoudre est l'algorithme de LLoyd. Implémentez le.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "hybrid-establishment",
   "metadata": {
    "scrolled": false,
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class KMeans(object):\n",
    "    def __init__(self, k=3, epsilon=0.001):\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, X):\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        # K means initialization\n",
    "        X_ = X.copy()\n",
    "        np.random.shuffle(X_)\n",
    "        means = X_[:self.k]\n",
    "        \n",
    "        variation = float('inf')\n",
    "        \n",
    "        assignment = [0 for _ in range(len(X))]\n",
    "        \n",
    "        path = [means.copy()]\n",
    "        \n",
    "        while variation > self.epsilon:\n",
    "            # Step 1\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                closest = 0\n",
    "                closest_dist = np.linalg.norm(X[i]-means[0])\n",
    "\n",
    "                for k in range(1, self.k):\n",
    "                    dist = np.linalg.norm(X[i]-means[k])\n",
    "                    if dist  < closest_dist:\n",
    "                        closest_dist = dist\n",
    "                        closest = k\n",
    "\n",
    "                assignment[i] = closest\n",
    "\n",
    "            # Step 2\n",
    "            kmeans = {\n",
    "                k : [] for k in range(self.k)\n",
    "            }\n",
    "            for i in range(len(X)):\n",
    "                kmeans[assignment[i]].append(X[i])\n",
    "\n",
    "            variation = -float('inf')\n",
    "\n",
    "            for k in range(self.k):\n",
    "\n",
    "                new_mean = np.mean(kmeans[k], axis=0)\n",
    "\n",
    "\n",
    "                if np.linalg.norm(new_mean-means[k]) > variation:\n",
    "                    variation = np.linalg.norm(new_mean-means[k])\n",
    "                means[k] = new_mean\n",
    "            path.append(means.copy())\n",
    "        path = np.array(path).transpose(1, 0, 2)\n",
    "        ###############################################################\n",
    "        return assignment, means, path\n",
    "            \n",
    "\n",
    "model = KMeans(3)\n",
    "plot_clusters(X, *model.fit(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-respect",
   "metadata": {},
   "source": [
    "On se rend compte qu'on arrive à retrouver les 3 groupes automatiquement (Les couleurs sont celles calculées par notre modèle des K-Moyennes) !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-backing",
   "metadata": {},
   "source": [
    "## VIII. La malédiction de la dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-transaction",
   "metadata": {},
   "source": [
    "Nous avons pu observer des scénarios où l'erreur sur notre jeu de données d'apprentissage était $0$ alors que notre modèle n'était pas si bon que cela sur notre jeu de test. Cet écart peut même devenir catastrophique ! De manière plus rigoureuse, le gap de généralisation de notre estimateur $\\hat{h}$ est la quantité suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{gap}(\\hat{h})=|Re(\\hat{h})-R(\\hat{h})|.\n",
    "\\end{equation}\n",
    "\n",
    "Où $Re$ fait référence à notre risque empirique, c'est-à-dire l'erreur sur le jeu d'apprentissage et $R$ à l'erreur en espérance.\n",
    "\n",
    "Il est possible d'avoir une idée de $R(\\hat{h})$ en passant par un jeu de test ou par une autre stratégie d'évaluation via un jeu de test par exemple, comme nous avons pu le voir.\n",
    "\n",
    "\n",
    "Deux facteurs principaux sont admis comme entrant en jeu dans $\\text{gap}(\\hat{h})$ : \n",
    "* la taille de l'ensemble $\\mathcal{H}$ qui est généralement liée au nombre de paramètres de notre modèle,\n",
    "* la taille du jeu de données $\\mathcal{S}$.\n",
    "\n",
    "Plus $\\mathcal{H}$ est grand, plus on s'attend à voir l'erreur augmenter. L'effet de double descente montre qu'avec un choix réfléchi de paramétrisation, cette tendance n'est pas nécessairement monotone. De la même manière, augmenter la taille du jeu de données $\\mathcal{S}$ permet de réduire l'erreur de généralisation.\n",
    "\n",
    "La taille de $\\mathcal{H}$ est intrinsèquement liée au nombre de paramètres qui lui-même dépend très souvent de la dimension $d$ de nos données.\n",
    "\n",
    "Nous allons ici nous rendre compte que les modèles qui regardent le voisinage de nos données souffre d'une grosse limite liée à ce qu'on appelle *la malédiction de la dimension*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-arthur",
   "metadata": {},
   "source": [
    "### En détails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-museum",
   "metadata": {},
   "source": [
    "La malédiction de la dimension fait référence aux résultats contre-intuitifs qui apparaissent lorsque la dimension augmente. Une première manière de l'observer est possible grâce au KNN. Ce dernier classe un nouvel élément en fonction de ses voisins dans le jeu d'apprentissage. Nous allons en particulier étudier l'évolution du risque de généralisation en fonction de la dimension. Plus précisément, les données synthétiques sont construites de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample_data(n, k=3, d=3, mu=1):\n",
    "    y = np.random.randint(0, 2, size=(n, 1))\n",
    "    \n",
    "    X = np.random.normal(mu, 1, size=(n, k))\n",
    "    X = y*X-(1-y)*X # positive have mean mu and negative, -mu\n",
    "    noise = np.random.normal(0, 1, size=(n, d-k))\n",
    "    X = np.concatenate([X, noise], axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-outdoors",
   "metadata": {},
   "source": [
    "Dit autrement, $k$ dimensions contiennent le signal intéressant pour notre tâche et $d$ dimensions ne servent à rien. Nous observons ci-dessous ce qui se passe lorsqu'on rajouter des dimensions de bruits (i.e. qui ne servent à rien). C'est typiquement ce pourrait se passer avec des images. Une photo de chien ne contient pas que des pixels descriptifs du concept de chien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scores = []\n",
    "redo = 5\n",
    "max_dim = 5000\n",
    "first_dim = 10\n",
    "steps = 100\n",
    "\n",
    "for d in range(first_dim, max_dim, steps):\n",
    "    s = 0\n",
    "    for _ in range(redo):\n",
    "        X, y = sample_data(100, d=d)\n",
    "        X_test, y_test = sample_data(200, d=d)\n",
    "        c = KNeighborsClassifier()\n",
    "        c.fit(X, y.reshape((y.shape[0],)))\n",
    "        s += c.score(X_test, y_test.reshape((y_test.shape[0],)))/redo\n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configuration generale de matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.plot(list(range(first_dim, max_dim, steps)), scores)\n",
    "plt.title('Evolution de l\\'erreur en fonction de la dimension du probleme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-silver",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice 1 :**</span> **Quelle est le risque de généralisation pour l'erreur 0/1 (1 si la classe est mal prédite, 0 sinon) d'un classifieur aléatoire ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "<span style=\"color:blue\">**Exercice 2 :**</span> **Expliquez pourquoi l'erreur de généralisation diminue lorsqu'on rajoute des dimensions sans signal.**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-rebate",
   "metadata": {},
   "source": [
    "De manière similaire, affichons ci-dessous l'évolution des distances entre nos points en fonction de la dimension du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_data(n, d):\n",
    "    return np.random.uniform(-1, 1, size=(n, d))/np.sqrt(d)\n",
    "X = sample_data(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = 50\n",
    "def experiment_(d):\n",
    "    min_ = 0\n",
    "    max_ = 0\n",
    "    mean_ = 0\n",
    "    for _ in range(redo):\n",
    "        X = sample_data(100, d)\n",
    "        vec = np.sqrt((X**2).sum(axis=1))\n",
    "        min_ += vec.min()/redo\n",
    "        max_ += vec.max()/redo\n",
    "        mean_ += vec.mean()/redo\n",
    "    return min_, max_, mean_\n",
    "idx = []\n",
    "val = []\n",
    "for d in range(10, 1000, 100):\n",
    "    idx.append([d])\n",
    "    val.append(experiment_(d))\n",
    "for d in range(2000, 10000, 1000):\n",
    "    idx.append([d])\n",
    "    val.append(experiment_(d))\n",
    "arr = np.concatenate([np.array(idx), np.array(val)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(arr[:, 0], arr[:, 1], label='Min')\n",
    "plt.plot(arr[:, 0], arr[:, 2], label='Max')\n",
    "plt.plot(arr[:, 0], arr[:, 3], label='Moy')\n",
    "plt.legend()\n",
    "plt.title('Evolution des distances en fonction de la dimension du probleme')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-paper",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Quelle phénomène mathématique pouvons nous invoquer afin d'expliquer ce phénomène ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---\n",
    "\n",
    "Soit $x_\\text{new}$ une nouvelle donnée. Une petite perturbation du point de notre jeu d'apprentissage le plus différent de $x_\\text{new}$ peut le transformer en le point le plus proche est inversement... C'est une grosse limite des modèles précédents. Il faut soit réfléchir à réduire la dimension, soit injecter de la connaissance dans nos modèles, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
