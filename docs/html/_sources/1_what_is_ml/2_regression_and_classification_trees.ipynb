{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "potential-feature",
   "metadata": {},
   "source": [
    "# Les arbres de régression et de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-saver",
   "metadata": {},
   "source": [
    "## I. Introduction\n",
    "\n",
    "Les arbres de décisions forment une catégorie de modèles clé en *marchine learning*. Bien que n'étant pas les modèles les plus performants par eux-mêmes, ils composent les briques de bases des forêts aléatoires, souvent sur le podium des modèles les plus performants. De plus, leur facilité d'interprétation leur offre un atout non négligeable.\n",
    "\n",
    "Les arbres de décisions s'appuient sur une structure de données qu'on appelle un [arbre](https://fr.wikipedia.org/wiki/Arbre_(théorie_des_graphes)). Il 'agit en particulier de ce qu'on appelle un [arbre de décision](https://fr.wikipedia.org/wiki/Arbre_de_décision). Le principe de ce dernier est illustré par la figure suivante :\n",
    "\n",
    "\n",
    "![Decision tree](https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Introduction/cart.jpg)\n",
    "\n",
    "Imaginons l'étudiant John Smith caractérisé par une note en licence en informatique de 14, une note en mathématiques de 15 et qui écoute en cours. Sa classification se fera comme suit.\n",
    "1.  On regarde la racine : l'étudiant écoute en cours, on prend donc la branche de droite,\n",
    "2.  On regarde sa note en math : elle est supérieure à 10, on en conclut qu'il obtiendra son module de *machine learning*.\n",
    "\n",
    "L'idée est qu'à chaque nœud notre arbre va découper le sous-espace dont \"il s'occupe par un hyperplan de manière à définir deux hyperrectangles. L'un sera traité par les nœuds de la branche droite et l'autre par ceux de la branche gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_student_dataset(n):\n",
    "    # la premiere colonne est la note d'informatique,\n",
    "    # la seconde la note de math\n",
    "    X = np.random.uniform(0, 20, size=(n, 2))\n",
    "    conditions = np.stack([\n",
    "        X[:, 0] > 11,\n",
    "        X[:, 1] > 8,\n",
    "        X[:, 1] > 18\n",
    "    ]).T\n",
    "    y = np.any(np.stack(\n",
    "         [np.all(conditions[:, 0:2], axis=1), X[:, 1] > 18]), axis=0\n",
    "             )\n",
    "    return X, y\n",
    "    \n",
    "X, y = create_student_dataset(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_student(X, y, tree=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X[y, 0], X[y, 1], color='green', label='Réussi le module de machine learning')\n",
    "    plt.scatter(X[(1-y).astype(bool), 0], X[(1-y).astype(bool), 1], \n",
    "                c='red', label='Échoue le module de machine learning')\n",
    "    plt.xlabel('Informatique')\n",
    "    plt.ylabel('Mathématiques')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_student(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(\n",
    "    np.arange(x_min, x_max, 0.1),\n",
    "    np.arange(y_min, y_max, 0.1)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(1, 4):\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    tree = DecisionTreeClassifier(max_depth=i)\n",
    "    tree.fit(X, y)\n",
    "    Z = tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "    plt.xlabel('Informatique')\n",
    "    plt.ylabel('Mathématiques')\n",
    "    plt.title('Arbre de décision avec une profondeur de ' + str(i))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "_ = plot_tree(tree, rounded=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-longer",
   "metadata": {},
   "source": [
    "## II. Construction d'un arbre de classification\n",
    "\n",
    "La question importante est de définir la manière de séparer les données à chaque nœud. À la première itération, l'idée va être de considérer toutes les valeurs possibles de seuil $t$ et des variables $j$ qui séparerait notre jeu de données $S$ en deux groupes $S^{(l)}$ et $S^{(r)}$ tels que $\\forall x\\in S_n^{(l)}\\Rightarrow x_j \\leq t$ et $\\forall x\\in S_n^{(r)}\\Rightarrow x_j > t$. Le choix du seuil se fera sur un critère qu'on appelle \"le gain d'information\" :\n",
    "\n",
    "$$\\mathcal{IG}(S^{l}, S^{r})=\\mathcal{I}(S)-\\frac{n_l}{n}\\mathcal{I}(S^{l})-\\frac{n_r}{n}\\mathcal{I}(S^{r}),$$\n",
    "\n",
    "où $n_r=|S^{(r)}|$ et $n_l=|S^{(l)}|$ et $\\mathcal{I}$ est une \"mesure d'impureté\" d'un groupe que nous définierons plus tard. L'idée est de mesure à quel point notre seuil $t$ a bien séparé notre jeu de données en deux groupes où les classes sont moins mélangées que dans le jeu complet $S$.\n",
    "\n",
    "Plusieurs métriques d'impureté existent dont nous listons quelques exemples :\n",
    "\n",
    "* Impureté de Gini\n",
    "* Entropie\n",
    "* Erreur de classification\n",
    "\n",
    "L'impureté de Gini se calcule de la manière suivante :\n",
    "\n",
    "$$\\mathcal{I}_{\\mathcal{G}}(S)=\\sum_i p_i(1-p_i),$$\n",
    "\n",
    "où $p_i$ indique la proportion d'éléments de la classe $i$ dans l'ensemble $S$. L'entropie est donnée par la formule $\\mathcal{I}_\\mathcal{E}(S)=-\\sum_i p_i \\text{log}_2 p_i$ et l'erreur de classification par $\\mathcal{I}_{EC}(S)=1-\\text{max}_i(p_i)$. On remarque que dans les figures de l'exemple ci-dessus, nous avons utilisé l'impureté de Gini ! \n",
    "\n",
    "L'étape précédente est ensuite répétée pour chaque sous-groupe. Plusieurs stratégies d'arrêts sont possibles. Tout d'abord, lorsque chaque feuille ne contient qu'un seul élément et ne peut plus être divisée en deux. Où lorsque le split améliore l'*accuracy* d'un gain relatif d'au moins $\\alpha$ (hyperparamètre qu'on fixe). Une autre stratégie consiste à construire l'arbre complet et à ensuite élimner les branches qui ne satisfont pas certains critères par exemple au travers d'une validation croisée.\n",
    "\n",
    "## III. Construction d'un arbre de régression\n",
    "Dans le cas d'un arbre de régression, le critère de *split* est différent du cas précédent. Nous considérons cette fois-ci comme critère d'erreur (l'impureté précédente) le *mean-squared error* ou MSE :\n",
    "\n",
    "$$MSE = \\sum_i(\\bar{y} – y_i)^2/n.$$\n",
    "\n",
    "Et le split minimisant la quantité suivante est choisie : \n",
    "$$\\frac{n_l}{n}MSE(S^{(l)})+\\frac{n_r}{n}MSE(S^{(r)}).$$\n",
    "Ce n'est rien d'autre que la moyenne pondérée des erreurs.\n",
    "\n",
    "## IV. Applications\n",
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Pour les différents jeux de données suivants, proposez un type d'arbre de classification (régression ou classification). Quel critère est split a été utilisé ? Quel est la profondeur de l'arbre calculé. Quelle règle de décision (i.e. le chemin de décision dans l'arbre) a été utilisée pour le premier élément du jeu de test (uniquement les jeux de données 1 avec max_depth=3 et 2) ?**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-wrist",
   "metadata": {},
   "source": [
    "**Jeu de données 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.5, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-board",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Le score R2:', model.score(X_test, y_test))\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "_ = plot_tree(model, rounded=True, fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "print('On prédit:', model.predict(X_test[:1]), 'pour', X_test[:1])\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-press",
   "metadata": {},
   "source": [
    "**Jeu de données 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.5, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-relation",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('L\\'accuracy de notre modèle:', model.score(X_test, y_test))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "_ = plot_tree(model, rounded=True, fontsize=14)\n",
    "plt.show()\n",
    "print('On prédit:', model.predict(X_test[:1]), 'pour', X_test[:1])\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-burden",
   "metadata": {},
   "source": [
    "**Jeu de données 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_covtype()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.5, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-paragraph",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('L\\'accuracy de notre modèle:', model.score(X_test, y_test))\n",
    "\n",
    "print('On prédit:', model.predict(X_test[:1]), 'pour', X_test[:1])\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-party",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
