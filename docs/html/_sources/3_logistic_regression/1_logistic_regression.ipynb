{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoFZYuLKaBB8"
   },
   "source": [
    "# La Régression Logistique ☕️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6XPOcE_aBCA"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsjqxNxAaBCA"
   },
   "source": [
    "Dans cette partie, nous allons implémenter un algorithme de classification supervisée. Contrairement à la régression linéaire qui consiste à prédire une valeur scalaire, la régression logistique a pour but d'estimer la probabilité d'une variable catégorielle. Une variable catégorielle correspond à un nombre entier compris entre $1$ et $K$ pour un problème à $K$ classes où la notion de proximité (1 est plus proche de 2 que de 3) est oubliée. Nous considererons ici un cas simple à deux classes. Puis nous mettrons en place un classificateur de chiffre manuscrit compris entre 0 et 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJ1490zpaBCA"
   },
   "source": [
    "**La régression logistique** cherche à estimer la probabilité $\\mathbb{P}(y=1|\\boldsymbol{x})$ où $y\\in\\{0,1\\}$. On obtient la probabilité inverse de la manière suivante : $\\mathbb{P}(y=0|\\boldsymbol{x})$=1-$\\mathbb{P}(y=1|\\boldsymbol{x})$. Pour cela, on suppose que le paramètre naturel $\\eta$ de notre loi est estimable à partir d'une combinaison linéaire des variables explicatives :\n",
    "\n",
    "$$\\exists\\boldsymbol{\\beta}\\in\\mathbb{R}^d,\\ \\eta(\\boldsymbol{x}) = \\langle\\boldsymbol{\\beta}, \\boldsymbol{x}\\rangle$$\n",
    "\n",
    "La fonction de lien $\\sigma$ est la fonction qui permet du passer du paramètre naturel à notre probabilité. Dans le cas d'une loi de Bernoulli (loi d'une variable binaire), la fonction de lien est la sigmoid :\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\sigma:\\mathbb{R}&\\rightarrow \\big[0, 1\\big]\\\\\n",
    "z&\\mapsto (1+\\text{exp}(-z))^{-1}\n",
    "\\end{aligned}$$\n",
    "\n",
    "\n",
    "La fonction sigmoid est illustrée par la figure suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ib8Z2rgZaBCB",
    "outputId": "1af53520-224f-4169-e8f9-5d27a9974b99"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# configuration generale de matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = (1+np.exp(-x))**(-1)\n",
    "plt.plot(x, y, label=\"fonction sigmoid\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sowVRoo_aBCC"
   },
   "source": [
    "Si le paramètre naturel $\\eta$ est négatif, la probabilité estimée sera inférieure à $0.5$ et notre échantillon appartiendra plus probablement à la classse $0$ ($y=0$). À l'inverse, si $\\eta$ est positif, on dira que notre échantillon appartient à la classe positive.\n",
    "\n",
    "il est ainsi possible d'obtenir notre probabilité de la manière suivante :\n",
    "\n",
    "\n",
    "$$\\mathbb{P}(y_{\\text{new}}=1|\\boldsymbol{x_{\\text{new}}}, \\boldsymbol{\\beta})=\\sigma(\\boldsymbol{\\beta}^T\\boldsymbol{x_{\\text{new}}} ).$$\n",
    "\n",
    "De la même manière que pour la régression linéaire, on supposera que le vecteur $\\boldsymbol{x}$ possède une dimension $0$ avec la valeur $1$ faisant office de biais.\n",
    "\n",
    "---\n",
    "On dit que deux vecteurs $u$ et $v$ sont orthogonaux si leur produit scalaire est nul :\n",
    "\n",
    "$$\\langle u, v \\rangle = 0$$\n",
    "\n",
    "\n",
    "La frontière de décision est l'ensemble de tous les points qu'il n'est pas possible de classer $1$ ou $0$. C'est l'ensemble des points tels que $\\mathbb{P}(y=1|\\boldsymbol{x}, \\boldsymbol{\\beta})=0.5$. Dit encore autrement, et en nous référant à la figure ci-dessus, il s'agit de l'ensemble des points tels que le paramètre naturel estimé $\\eta(\\boldsymbol{x})=\\boldsymbol{\\beta}^T\\boldsymbol{x}=0$. Dit encore autrement, il s'agit de l'ensemble des points orthogonaux au vecteur de paramètres $\\boldsymbol{\\beta}$. Le vecteur $\\boldsymbol{\\beta}$ est appelé vecteur normal à l'hyperplan séparateur.  \n",
    "\n",
    "---\n",
    "\n",
    "La régression logistique nous donne la probabilité $\\mathbb{P}(y_{\\text{new}}=1|\\boldsymbol{x_{\\text{new}}}, \\boldsymbol{\\beta})$. Il est trivial d'obtenir la classe à partir de ce score. On dira que l'échantillon appartient à la classe $1$ si la probabilité est supérieure à $0.5$ et à la classe $0$ dans le cas contraire.\n",
    "\n",
    "On peut parfois vouloir bouger ce seuil. Ainsi, si on prédit qu'un patient a $45\\%$ de chance d'avoir un cancer, on voudra refaire des tests plutôt que lui dire que tout est bon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaQY3BmRaBCC"
   },
   "source": [
    "## Construction d'un jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaT-KDxVaBCC"
   },
   "source": [
    "Considérons le modèle génératif suivant :\n",
    "\n",
    "\n",
    "$$\\boldsymbol{\\beta} \\sim \\mathcal{N}(0, 1)^3 \\in \\mathbb{R}^3$$\n",
    "\n",
    "Nos échantillons sont simulés via une loi normale de moyenne centrée sur la frontière de décision. Notons $\\boldsymbol{\\beta^\\prime}=\\begin{bmatrix}\\beta_1\\\\ \\beta_2\\end{bmatrix}$. On fixera cette moyenne de la manière suivante :\n",
    "\n",
    "$$\\boldsymbol{\\mu}=\\boldsymbol{\\beta^\\prime}\\Bigg(-\\frac{\\beta_0}{\\lVert \\boldsymbol{\\beta^\\prime}\\rVert^2}\n",
    "\\Bigg).$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Vérifier qu'on obtient bien :\n",
    "\\begin{equation}\n",
    "\\langle \\boldsymbol{\\beta^\\prime}, \\boldsymbol{\\mu}\\rangle + \\beta_0=0\n",
    "\\end{equation}\n",
    "Dit autrement, il s'agit de vérifier que $\\boldsymbol{\\mu}$ est bien sur la frontière.**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---\n",
    "\n",
    "La moyenne de notre loi normale étant maintenant fixée, nous pouvons simuler nos données :\n",
    "\\begin{equation}\n",
    "\\boldsymbol{x}\\sim\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{1})\\in\\mathbb{R}^2\n",
    "\\end{equation}\n",
    "\n",
    "La classe d'un échantillon est donnée par :\n",
    "\n",
    "$$\\begin{aligned}\n",
    "y_i=\\begin{cases}\n",
    "1\\text{ si }\\langle\\boldsymbol{\\beta^\\prime},\\boldsymbol{x_i}\\rangle +\\beta_0>0\\\\\n",
    "0\\text{ sinon.}\n",
    "\\end{cases}\\end{aligned}$$\n",
    "\n",
    "Notre problème est donc par construction totalement linéairement séparable dans le sens où la frontière de décision définie par le vecteur normal $\\boldsymbol{\\beta^\\prime}$ et par le biais $\\beta_0$ sépare totalement et sans erreur notre jeu de données.\n",
    "\n",
    "Le code ci dessous affiche le jeux de données ainsi que la représentation graphique de la frontière de decision $f(x)=-\\frac{\\beta_1}{\\beta_2}x_1-\\frac{\\beta_0}{\\beta_2}$. On vérifie facilement que le vecteur construit tel que $\\beta_2=f(x)$ pour $\\beta_1$ et $\\beta_0$ quelconques (à part les cas particuliers) sont bien sur la frontière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q72vZKIpaBCD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "real_beta = np.random.normal(0, 1, size=3)\n",
    "\n",
    "def sample_data(n, beta):\n",
    "    # constructing mean \n",
    "    mu = beta[1:3]*(-beta[0]/(np.linalg.norm(beta[1:3])**2))\n",
    "    # covariance is the same for each class\n",
    "    cov  = np.diag(np.ones(2))\n",
    "    \n",
    "    # sampling x and adding the bias\n",
    "    X = np.insert(np.random.multivariate_normal(mu, cov, size=n), 0, 1, axis=1)\n",
    "    \n",
    "    # the label is deterministic\n",
    "    y = (np.dot(X, beta)>0)*1\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "X, y = sample_data(100, real_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yw8QfHMraBCD",
    "outputId": "2ded8c01-c6ad-4aec-f854-78edf4c8861a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot(X, y, beta=None, predictor=None, title=None):\n",
    "    ymin_ = X[:,2].min()\n",
    "    ymax_ = X[:,2].max()\n",
    "    min_ = X[:,1].min()\n",
    "    max_ = X[:,1].max()\n",
    "    \n",
    "    if predictor is not None:\n",
    "        h = 0.02\n",
    "        xx, yy = np.meshgrid(np.arange(min_, max_, h), np.arange(ymin_, ymax_, h))\n",
    "        Z = predictor.predict(np.insert(np.c_[xx.ravel(), yy.ravel()], 0, 1, axis=1))\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.pcolormesh(xx, yy, Z,shading='auto', alpha=0.01)\n",
    "    \n",
    "    plt.scatter(X[:,1], X[:,2], c=y)\n",
    "    \n",
    "    if beta is not None:\n",
    "        x_ = np.linspace(min_, max_, 500)\n",
    "        y_  = -beta[0]/beta[2] - x_ * beta[1] / beta[2]\n",
    "        plt.plot(x_, y_)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.xlim(min_, max_)\n",
    "    plt.ylim(ymin_, ymax_)\n",
    "    plt.show()\n",
    "plot(X, y, real_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwpfZNZRaBCD"
   },
   "source": [
    "## Fonction objectif et gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hbb8ejMaBCE"
   },
   "source": [
    "De la même manière que pour la régression linéaire, nous pouvons obtenir notre fonction objectif à partir de la formulation de la vraisemblance de notre problème :\n",
    "\n",
    "$$\\mathcal{L}_{\\boldsymbol{\\beta}}(\\mathcal{S})=\\prod_{(\\boldsymbol{x}, y)\\in\\mathcal{S}}\\mathbb{P}(y=1|\\boldsymbol{x},\\boldsymbol{\\beta})^y\\mathbb{P}(y=0|\\boldsymbol{x},\\boldsymbol{\\beta})^{1-y}$$\n",
    "\n",
    "\n",
    "Le paramètre maximisant la vraisemblance est aussi celui minimisant la log vraisemblance négative :\n",
    "\n",
    "$$-\\text{log}\\big(\\mathcal{L}_{\\boldsymbol{\\beta}}(\\mathcal{S})\\big)=-\\sum_{(\\boldsymbol{x}, y)\\in\\mathcal{S}}y\\text{log}(p)+(1-y)\\text{log}(1-p)$$\n",
    "\n",
    "\n",
    "où $p=\\mathbb{P}(y=1|\\boldsymbol{x},\\boldsymbol{\\beta})=\\sigma(\\boldsymbol{\\beta}^T\\boldsymbol{x})$. Cette fonction objectif, ou *loss* s'appelle la *cross entropy* ou entropie croisée. On obtient donc :\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\beta}}=\\text{argmin}_{\\boldsymbol{\\beta}}\\Big[-\\sum_{(\\boldsymbol{x}, y)\\in\\mathcal{S}}y\\text{log}(\\sigma(\\boldsymbol{\\beta}^T\\boldsymbol{x}))+(1-y)\\text{log}(1-\\sigma(\\boldsymbol{\\beta}^T\\boldsymbol{x}))\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABTO8Hf5aBCE"
   },
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question 1 :**</span> **Compléter la méthode $\\texttt{val}$ de l'objet $\\texttt{CrossEntropy}$ ci-dessous.**\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Question 2 :**</span> **Calculez les dérivées partielles $\\partial J(\\beta)/\\partial \\beta_0$, $\\partial J(\\beta)/\\partial \\beta_1$ et  $\\partial J(\\beta)/\\partial \\beta_2$ de la fonction de coût de notre modèle de régréssion logistique. Complétez la méthode $\\texttt{grad}$ de l'objet $\\texttt{CrossEntropy}$ ci dessous.**\n",
    "\n",
    "**<span style=\"color:orange\">Indice</span>**  Rappellez-vous que la dérivée d'une composition de fonction s'écrit $(g \\circ f)^\\prime (x) = f^\\prime(x) g^\\prime(f(x))$ et que la fonction de coût de notre modèle s'écrit:\n",
    "\n",
    "\n",
    "$$J(\\boldsymbol{\\beta}) = \\frac{1}{n}\\sum_j^n g_1(f_{\\boldsymbol{\\beta}}(x_j)) + g_2(f_{\\boldsymbol{\\beta}}(x_j))$$\n",
    "\n",
    "avec $g$, $f$, etc. choisis intelligemment.\n",
    "\n",
    "**<span style=\"color:green\">Réponse:</span>**\n",
    "\n",
    "\n",
    "$$\\frac{\\partial J(\\boldsymbol{\\beta})}{\\partial \\beta_j} = \\frac{1}{n}\\sum_i^n (f_{\\boldsymbol{\\beta}}(\\mathbf{x_i}) - y_i)   x_i^j$$\n",
    "\n",
    "<span style=\"color:blue\">**Question 2${}^\\star$ :**</span> **Calculez le gradient de la fonction $J(\\boldsymbol{\\beta})$ en utilisant les dérivées matricielles et modifiez la méthode $\\texttt{grad}$ ci-dessous en conséquence.**\n",
    "\n",
    "**<span style=\"color:green\">Réponse:</span>**\n",
    "\n",
    "\n",
    "$$\\nabla J(\\boldsymbol{\\beta})=\\frac{1}{n}X^T(\\sigma(X\\boldsymbol{\\beta})-\\boldsymbol{y})$$\n",
    "\n",
    "Il est intéressant de constater qu'on retombe presque sur le gradient de la régression linéaire à la différence près que les prédictions sont \"tassées\" grâce à la sigmoid $\\sigma$ entre $0$ et $1$.\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Question 3 :**</span> **Complétez la méthode $\\texttt{predict}$ de l'objet ci-dessous**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx6oI5WYaBCE",
    "outputId": "41773a7d-39b2-4854-e400-50f00fb16e8a"
   },
   "outputs": [],
   "source": [
    "class CrossEntropy(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.idx = np.array([i for i in range(self.X.shape[0])])\n",
    "        self._pos = 0\n",
    "        \n",
    "    def _format_ndarray(arr):\n",
    "        arr = np.array(arr) if type(arr) is not np.ndarray else arr\n",
    "        return arr.reshape((arr.shape[0], 1)) if len(arr.shape) == 1 else arr\n",
    "    \n",
    "    def predict(self, X):\n",
    "    \n",
    "        ####### Complete this part ######## or die ####################\n",
    "        y_pred = (1+np.exp(-np.dot(X, self.beta)))**(-1) # self._sigmoid(X, self.beta)\n",
    "        ###############################################################\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def _sigmoid(X, beta):\n",
    "        return (1+np.exp(-np.dot(X, beta)))**(-1)\n",
    "    \n",
    "    def val(self, beta):\n",
    "        beta = CrossEntropy._format_ndarray(beta)\n",
    "\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        p = CrossEntropy._sigmoid(self.X, beta)\n",
    "        log_p = -np.concatenate([np.log(1-p), np.log(p)], axis=1)[np.arange(len(self.X)), y]\n",
    "        return log_p.sum()/len(self.X)\n",
    "        ###############################################################\n",
    "    \n",
    "    def _shuffle(self):\n",
    "        np.random.shuffle(self.idx)\n",
    "    \n",
    "    def grad(self, beta, batch_size=-1):\n",
    "        batch_size = self.X.shape[0] if batch_size == -1 else batch_size\n",
    "        idx = self.idx[self._pos:self._pos+batch_size]\n",
    "\n",
    "        self._pos = (self._pos+batch_size) % self.X.shape[0]\n",
    "        if self._pos == 0:\n",
    "            self._shuffle()\n",
    "            \n",
    "        X, y = self.X[idx], self.y[idx]\n",
    "        y = CrossEntropy._format_ndarray(y)\n",
    "\n",
    "        \n",
    "        beta = CrossEntropy._format_ndarray(beta)\n",
    "        \n",
    "        ####### Complete this part ######## or die ####################\n",
    "        grad = np.dot(X.T, CrossEntropy._sigmoid(X, beta)   - y)\n",
    "        return grad/len(X)\n",
    "        ###############################################################\n",
    "    \n",
    "\n",
    "l = CrossEntropy(X, y)\n",
    "print('La valeur de la loss pour beta est', l.val(real_beta))\n",
    "\n",
    "print('Le gradient pour beta est\\n', l.grad(real_beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7V8AarsaBCF"
   },
   "source": [
    "## Optimisation et dynamique de la descente de gradient dans le cas séparable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx9ZVwqqaBCF"
   },
   "source": [
    "Récupérons l'algorithme de descente de gradient développé lors du TP 1. Il s'agit exactement du même code à la différence près qu'on optimise la fonction $\\texttt{CrossEntropy}$ et non $\\texttt{LeastSquare}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79l1bt4jaBCF"
   },
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    init = np.random.uniform(-4, 4, size=3).reshape((3, 1))\n",
    "    def __init__(self, X, y, loss=CrossEntropy):\n",
    "        self.loss = loss(X, y)\n",
    "        \n",
    "    def optimize(self, learning_rate = 0.5, nb_iterations=10, beta=init, batch_size=-1):\n",
    "        param_trace = [beta.T[0]]\n",
    "        loss_trace = [self.loss.val(beta)]\n",
    "        for i in range(nb_iterations):\n",
    "            beta = beta - learning_rate * self.loss.grad(beta, batch_size=batch_size)\n",
    "            param_trace.append(beta.T[0])\n",
    "            loss_trace.append(self.loss.val(beta))\n",
    "            \n",
    "        return param_trace, loss_trace\n",
    "\n",
    "\n",
    "gd = GradientDescent(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA90hvQtaBCG"
   },
   "source": [
    "La dimension de l'espace des paramètres est $3$ et il n'est plus possible de visualiser ce dernier pour voir si notre algorithme d'optimisation fonctionne. \n",
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Proposez une stratégie permettant d'évaluer la convergence de notre algorithme. Jouez sur le *learning rate* et sur le nombre d'itérations afin d'améliorer la qualité de notre estimateur.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUcgAbVBaBCG",
    "outputId": "235bf038-ed3b-4bc0-a2d3-935e2713948d"
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "def plot_loss(loss):\n",
    "    plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.show\n",
    "    \n",
    "params, loss_trace = gd.optimize()\n",
    "plot_loss(loss_trace)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKQTMcaJaBCG"
   },
   "source": [
    "---\n",
    "\n",
    "Analysons maintenant l'évolution de notre paramètres en terme de distance par rapport au \"vrai\" paramètre ainsi que l'évolution de la *loss* pour plusieurs configurations d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5x2BcuaaBCH",
    "outputId": "d0628bd6-baeb-408e-fb2c-820f0a730045"
   },
   "outputs": [],
   "source": [
    "distance = []\n",
    "loss_evolution = []\n",
    "for it in range(10, 1000, 10):\n",
    "    params, loss_trace = gd.optimize(nb_iterations=it, learning_rate=1.)\n",
    "    distance.append(np.linalg.norm(params[-1]-real_beta))\n",
    "    loss_evolution.append(loss_trace[-1])\n",
    "plt.figure()\n",
    "plt.plot(list(range(10, 1000, 10)),distance)\n",
    "plt.title(\"Distance Euclidienne entre les parametres estimes et la vraie solution en fonction du\"+\n",
    "          \" nombre d'itérations\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.title(\"Évolution de la loss en fonction du nombre d'itérations\")\n",
    "plt.plot(list(range(10, 1000, 10)), loss_evolution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mct2qLf7aBCH"
   },
   "source": [
    "On remarque que notre vecteur de paramètres se rapproche dans un premier temps de la vraie solution (voire même pas) puis s'en écarte inéxorablement. Il est légitime de se poser la question du bug dans l'algorithme. Cependant, l'affichage de la *loss* nous montre que plus on s'écarte du vrai paramètre, plus notre modèle *fit* correctement les données dans le sens où il minimise bien la fonction objectif. De plus un affichage de la frontière de décision ainsi calculée montre que notre frontière de décision semble visuellement assez proche de la vraie solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgIYBjKxaBCH",
    "outputId": "fc9e17f7-2e3e-4e4d-a441-38cbbf1ccc7c"
   },
   "outputs": [],
   "source": [
    "plot(X, y, params[-1], title='Solution estimee')\n",
    "plot(X, y, real_beta, title='Vraie solution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VykU0n8kaBCH"
   },
   "source": [
    "Il se produit donc un phénomène qu'il convient de comprendre. Ce phénomène est en réalité le pendant du régime interpolatoire (i.e. 0 erreur) de la régression linéaire pour la régression logistique.\n",
    "\n",
    "Étudions cela plus en détails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJhOKlrzaBCH"
   },
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice 1 :**</span> **Montrer que si $\\beta$ est le vecteur normal d'un hyperplan qui sépare correctement (i.e. aucune erreur) les deux classes de notre jeu de données, alors $k\\beta,\\ k\\in\\mathbb{R}^{\\star+}$ est aussi un vecteur normal séparateur pour notre jeu de données.**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "<span style=\"color:blue\">**Exercice 2 :**</span> **Montrer que si $\\beta$ est le vecteur normal d'un hyperplan qui sépare correctement (i.e. aucune erreur) les deux classes de notre jeu de données, alors $J(\\beta)>J(k\\beta)$ si $k>1$.**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdFoWTIfaBCH"
   },
   "source": [
    "Autrement dit, s'il existe un vecteur $\\beta$ qui définit une bonne frontière de décision avec aucune erreur, alors tout vecteur $\\gamma=k\\beta,\\ k>0$ définira le même hyperplan. De plus, plus $k$ sera grand, plus notre loss sera petite. Cela nous indique qu'en réalité, la fonction $J(\\beta)$ n'admet **aucun** minimum ou, d'un point de vue statistique, le maximum de vraisemblance n'existe pas. On se rapproche du minimum de la fonction $J$ lorsque $\\beta$ diverge vers l'infini.\n",
    "\n",
    "D'un point de vue purement prédictif/classification, cela n'est pas gênant car toutes ces solutions définissent le même hyperplan qui n'est décrit que par la direction du vecteur $\\beta$. D'un point de vue statistique, cela est plus gênant car les \"probabilités\" retournées par notre modèle convergent toutes soit vers $1$ soit vers $0$ et ne sont plus interprétables.\n",
    "\n",
    "La figure suivante montre que bien que notre vecteur de paramètres diverge, son cosinus avec le vrai vecteur de paramètres tend vers $1$ : ils sont donc bien colinéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMXZibhvaBCH",
    "outputId": "539170b5-55ac-4dc3-f94d-3b6286ce9a85"
   },
   "outputs": [],
   "source": [
    "cos = []\n",
    "for it in range(10, 1000, 10):\n",
    "    params, loss_trace = gd.optimize(nb_iterations=it, learning_rate=1.)\n",
    "    cos.append(np.dot(params[-1], real_beta)/(np.linalg.norm(params[-1])*np.linalg.norm(real_beta)))\n",
    "plt.figure()\n",
    "plt.title(\"Cosinus entre les parametres estimes et la vraie solution\")\n",
    "plt.plot(list(range(10, 1000, 10)), cos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce n'est bien sûr pas exactement $1$ puisque notre vecteur est estimé sur un jeu de données empirique de taille finie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2AogJLOaBCI"
   },
   "source": [
    "## Optimisation et dynamique de la descente de gradient dans le cas non-séparable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WbOfAxYaBCI"
   },
   "source": [
    "À l'inverse, si le problème n'était pas séparable, une solution optimale existerait et notre algorithme s'en serait approché. Cette solution serait notre maximum de vraisemblance statistique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSb9C_lyaBCI"
   },
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Soit $\\beta^\\star$ le minimum de notre fonction $J$ tel qu'il existe un unique échantillon $(\\boldsymbol{x}, y)$ mal classé. Montrer que $J(k\\beta^\\star)$ diverge lorsque $k$ tend vers l'infini.**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---\n",
    "L'exercice précédent se généralise assez facilement dans un cadre général."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ig-7LXeWaBCI"
   },
   "source": [
    "### Construction d'un jeu de données non-séparable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K19URTPdaBCI"
   },
   "source": [
    "Considérons tout d'abord le modèle génératif suivant:\n",
    "\n",
    "\n",
    "$$\\boldsymbol{x^+} \\sim \\mathcal{N}(\\mu^+, 1)^2 \\in \\mathbb{R}^2, \\boldsymbol{x^-} \\sim \\mathcal{N}(\\mu^-, 1)^2 \\in \\mathbb{R}^2$$\n",
    "\n",
    "Les échantillons $\\boldsymbol{x^+}$ sont associés à $y=1$ et $\\boldsymbol{x^-}$ à $y=0$. La variable $y$ est notre variable binaire à expliquer. Le centre de chaque *cluster* est défini de la manière suivante :\n",
    "\n",
    "$$\\boldsymbol{\\mu^{+/-}}=\\boldsymbol{\\beta^\\prime}\\Bigg(-\\frac{\\beta_0}{\\lVert \\boldsymbol{\\beta^\\prime}\\rVert^2}\\pm\\rho\n",
    "\\Bigg),$$\n",
    "\n",
    "\n",
    "où $\\rho$ nous permet de contrôler l'écart du centre de chaque cluster avec la frontière de décision. De la même manière que précédemment, nous choissons une règle arbitraire pour générer aléatoirement les paramètres du \"vrai\" modèle en incluant un biais:\n",
    "\n",
    "\n",
    "$$\\boldsymbol{\\beta} \\sim \\mathcal{N}(0, 1)^3 \\in \\mathbb{R}^3$$\n",
    "\n",
    "\n",
    "Ainsi $\\beta_1$ et $\\beta_2$ correspondent aux paramètres associés à nos variables explicatives et $\\beta_0$ est le biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "We6HSWp2aBCI"
   },
   "outputs": [],
   "source": [
    "real_beta = np.random.normal(0, 1, size=3)\n",
    "\n",
    "def sample_data(n, beta, rho=1):\n",
    "    # constructing mean of each class\n",
    "    mu_1 = beta[1:3]*((-beta[0]/(np.linalg.norm(beta[1:3])**2))-rho)\n",
    "    mu_0 = beta[1:3]*((-beta[0]/(np.linalg.norm(beta[1:3])**2))+rho)\n",
    "    # covariance is the same for each class\n",
    "    cov  = np.diag(np.ones(2))\n",
    "    \n",
    "    # the two classes have the same number of samples\n",
    "    X = np.concatenate([\n",
    "        np.random.multivariate_normal(mu_1, cov, size=int(n/2)),\n",
    "        np.random.multivariate_normal(mu_0, cov, size=int(n/2))\n",
    "    ], axis=0)\n",
    "    \n",
    "    # the label is deterministic\n",
    "    y = np.array([0 if i < int(n/2) else 1 for i in range(2*int(n/2))])\n",
    "    \n",
    "    # we shuffle the samples\n",
    "    idx = [i for i in range(X.shape[0])]\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    # we insert a bias\n",
    "    return np.insert(X[idx], 0, 1, axis=1), y[idx]\n",
    "    \n",
    "X, y = sample_data(1000, real_beta, rho=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jTvsBqSaBCJ",
    "outputId": "b66451a3-e691-4450-d7a9-5c18e39bb4cc"
   },
   "outputs": [],
   "source": [
    "plot(X, y, real_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKKIY7aGaBCJ"
   },
   "source": [
    "on retrace les mêmes courbes que nous avions réalisées précédemment et on constate la différence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-YdDJyKaBCJ"
   },
   "outputs": [],
   "source": [
    "gd = GradientDescent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti8Z3o0maBCJ",
    "outputId": "1eb8142b-f06e-48ef-c875-e3face8ef065"
   },
   "outputs": [],
   "source": [
    "distance = []\n",
    "loss_evolution = []\n",
    "cos = []\n",
    "for it in range(10, 1000, 10):\n",
    "    params, loss_trace = gd.optimize(nb_iterations=it, learning_rate=1.)\n",
    "    distance.append(np.linalg.norm(params[-1]-real_beta))\n",
    "    loss_evolution.append(loss_trace[-1])\n",
    "    cos.append(np.dot(params[-1], real_beta)/(np.linalg.norm(params[-1])*np.linalg.norm(real_beta)))\n",
    "plt.figure()\n",
    "plt.plot(list(range(10, 1000, 10)),distance)\n",
    "plt.title(\"Distance Euclidienne entre les parametres estimes et la vraie solution en fonction du\"+\n",
    "          \" nombre d'itérations\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.title(\"Évolution de la loss en fonction du nombre d'itérations\")\n",
    "plt.plot(list(range(10, 1000, 10)), loss_evolution)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Cosinus entre les parametres estimes et la vraie solution\")\n",
    "plt.plot(list(range(10, 1000, 10)), cos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am0ujz06aBCJ"
   },
   "source": [
    "On remarque qu'on ne converge pas vers le vecteur que nous avions utilisé lors de la construction du jeu de données. Cela est du au fait que nous ne nous sommes servi de ce vecteur que pour positionner l'hyperplan. Ainsi, nous avons utilisé sa direction et non sa norme. Rajoutons que maintenant le problème n'est plus séparable et notre vecteur estimé converge vers une valeur. On peut également confirmer que le problème n'est plus séparable car notre *loss* ne tend plus vers 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Quel processus génératif aurait pu être utilisé afin que le vecteur $\\beta$ réel soit bien celui vers lequel on retombe lorsqu'on optimise notre problème ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "Soit \n",
    "\n",
    "$$\\boldsymbol{\\beta} \\sim \\mathcal{N}(0, 1)^3 \\in \\mathbb{R}^3$$\n",
    "\n",
    "\n",
    "et \n",
    "\n",
    "$$\\boldsymbol{x}\\sim\\mathcal{U}(-2, 2)^2$$\n",
    "\n",
    "Par abus de langage, notons $x=[1, x_1, x_2]^T$.\n",
    "\n",
    "La construction du label se fait de la manière suivante :\n",
    "\n",
    "$$y\\sim \\mathcal{B}(\\sigma (\\langle \\beta, x\\rangle),$$\n",
    "\n",
    "où $\\mathcal{B}$ est la Bernoulli.\n",
    "\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Testez votre modèle génératif et comparez les résultats.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_beta = np.random.normal(0, 0.1, size=3)\n",
    "real_beta[1:3] *= 10\n",
    "\n",
    "def perfect_data_sampler(n, beta):\n",
    "    ####### Complete this part ######## or die ####################\n",
    "    cov  = np.diag(np.ones(2))\n",
    "    mu = np.ones(2)\n",
    "    \n",
    "    X = np.random.uniform(-4, 4, size=(n, 2))\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "    p = (1+np.exp(-np.dot(X, beta)))**(-1)\n",
    "    y = np.random.binomial(1, p)\n",
    "    ###############################################################\n",
    "    return X, y\n",
    "    \n",
    "X, y = perfect_data_sampler(1000, real_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X, y, real_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = GradientDescent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = []\n",
    "loss_evolution = []\n",
    "cos = []\n",
    "for it in range(10, 1000, 10):\n",
    "    params, loss_trace = gd.optimize(nb_iterations=it, learning_rate=1.)\n",
    "    distance.append(np.linalg.norm(params[-1]-real_beta))\n",
    "    loss_evolution.append(loss_trace[-1])\n",
    "    cos.append(np.dot(params[-1], real_beta)/(np.linalg.norm(params[-1])*np.linalg.norm(real_beta)))\n",
    "plt.figure()\n",
    "plt.plot(list(range(10, 1000, 10)),distance)\n",
    "plt.title(\"Distance Euclidienne entre les parametres estimes et la vraie solution en fonction du\"+\n",
    "          \" nombre d'itérations\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.title(\"Évolution de la loss en fonction du nombre d'itérations\")\n",
    "plt.plot(list(range(10, 1000, 10)), loss_evolution)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Cosinus entre les parametres estimes et la vraie solution\")\n",
    "plt.plot(list(range(10, 1000, 10)), cos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succès !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng-yVRHQaBCJ"
   },
   "source": [
    "## Transformation des variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvKKnediaBCJ"
   },
   "source": [
    "Considérons maintenant un jeu de données tel qu'il n'est pas possible de séparer nos deux classes linéairement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijrQHfgGaBCK",
    "outputId": "d1979b0f-4141-4501-acb4-103151668b6b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sample_data(n, sigma1=0.1, sigma2=0.3, r=2):\n",
    "    class_1 = np.random.uniform(0, 2*np.pi, size=(int(n/2), 1))\n",
    "    class_1 = np.concatenate(\n",
    "        [r*np.cos(class_1), r*np.sin(class_1)], axis=1) + np.random.normal(0, \n",
    "                                                                       sigma1, \n",
    "                                                                       size=(int(n/2), 2))\n",
    "    class_2 = np.random.normal(0, sigma2, size=(int(n/2), 2))\n",
    "    X = np.insert(np.concatenate([class_1, class_2]), 0, 1, axis=1)\n",
    "    y = np.array([1 if i < int(n/2) else 0 for i in range(2*int(n/2))])\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "X, y = sample_data(100)\n",
    "plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA930y2UaBCK"
   },
   "source": [
    "On remarque assez naïvement et rapidement qu'une simple régression logistique n'est plus une solution acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlUCxfpdaBCK",
    "outputId": "45ce8d59-0b77-48ef-cff4-75854526331e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "plot(X, y, beta=model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D7D66t8aBCK"
   },
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Proposez une transformation polynomiale de vos variables explicatives permettant de résoudre correctement ce problème.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YH-YON4UaBCK",
    "outputId": "2249528d-6763-4436-d576-d96351f6fe55"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "####### Complete this part ######## or die ####################\n",
    "deg = 4\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(deg), LogisticRegression())\n",
    "model.fit(X, y)\n",
    "###############################################################\n",
    "\n",
    "plot(X, y, predictor=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdID39YxaBCK"
   },
   "source": [
    "## Classificateur de chiffres manuscrits : Le dataset MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuPs72t6aBCL"
   },
   "source": [
    "#### Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8W10_EMNaBCL"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXRlAAcNaBCL"
   },
   "source": [
    "#### Visualisation d'un exemple representatif du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaVzGczYaBCL",
    "outputId": "d0a68c50-d11f-4e2d-bdb9-eaa8b4a5bb46"
   },
   "outputs": [],
   "source": [
    "X_img = np.reshape(X,(X.shape[0],28*28))\n",
    "\n",
    "#Recuperation du nombre d'exemples d'apprentissage ainsi que la dimension des vecteurs\n",
    "n_samples = X.shape[0]\n",
    "print(\"Nombre d'exemples d'apprentissage n_samples = %d \" % n_samples)\n",
    "\n",
    "def plotImg(X):\n",
    "    plt.figure(figsize=(7.195, 3.841), dpi=100)\n",
    "    for i in range(200):\n",
    "        plt.subplot(10,20,i+1)\n",
    "        plt.imshow(X[i,:].reshape([28,28]), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plotImg(X_img)\n",
    "    \n",
    "n_classes = np.max(y) + 1\n",
    "print(\"Nombre de classes d'objets n_classes = %d \" % n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJZKH49paBCL"
   },
   "source": [
    "#### Construction d'un ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10UvWFdxaBCL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TeIBCvCaBCL"
   },
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice :**</span> **Proposez un modèle de classification permettant de classer correctement nos chiffres. N'hésitez pas à jouer avec de notions non abordées dans ce TP (e.g. régularisation).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MJa7w2eaBCL"
   },
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1O4vr_FaBCL"
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    LogisticRegression(C=0.0001, penalty='l2', solver='saga', tol=0.1)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwY_Em-XaBCM"
   },
   "source": [
    "#### model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvjwu8b0aBCM",
    "outputId": "8e20fc2d-5baa-469b-8315-752550f4bce6"
   },
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "print(\"L'accuracy de notre modele est\", model.score(X_test, y_test))\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3vAsUnYaBCM",
    "outputId": "4092b15b-9638-4aa7-aa87-01eba0c06174"
   },
   "outputs": [],
   "source": [
    "print(\"On teste le modele sur 200 images de test selectionnees aleatoirement\")\n",
    "\n",
    "idx = [i for i in range(X_test.shape[0])]\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "n_test_visu = 10\n",
    "\n",
    "predicted = model.predict(X_test[idx][:n_test_visu])\n",
    "\n",
    "plt.figure(figsize=(12, 17.14), dpi=100)\n",
    "for i in range(n_test_visu):\n",
    "    plt.subplot(n_test_visu,1,i+1)\n",
    "    plt.title('Predicted:' + str(predicted[i]))\n",
    "    plt.imshow(X_test[idx][i,:].reshape([28,28]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(hspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbONfxiCaBCM"
   },
   "source": [
    "## Iterative Re-Weighted Least Square (IRWLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrairement au cas de la regression linéaire, il n'est ici plus possible de résoudre le problème analytiquement, comme nous l'avons vu (i.e. en annulant le gradient). Nous allons cependant voir une autre approche itérative d'optimisation comme alternative à la descente de gradient qui va nous permettre de faire des ponts avec la solution analytique de la regression linéaire. Il s'agit ici d'utiliser une méthode d'optimisation de type Newton que vous avez peut-être vue dans les exercices d'approfondissement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode de type Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de Newton consiste à considerer une fonction (qu'on suppose $C^{n}$) par son approximation au voisinage de $\\beta_0$ (notre point d'initialisation) par une expansion de Taylor:\n",
    "\n",
    "$$\n",
    "  f(\\beta) = f(\\beta_0)\n",
    "  + \\frac{f'(\\beta_0)}{1!}(\\beta - \\beta_0)\n",
    "  + \\frac{f^{(2)}(\\beta_0)}{2!}(\\beta - \\beta_0)^2\n",
    "  + \\cdots\n",
    "  + \\frac{f^{(n)}(a)}{n!}(\\beta - \\beta_0)^n\n",
    "  + R_n(\\beta)\n",
    "$$\n",
    "\n",
    "C'est à dire, de manière générale:\n",
    "\n",
    "$$f(\\beta) = \\sum_{k=0}^n \\frac{f^{(k)}(\\beta_0)}{k!}(\\beta-\\beta_0)^k + R_n(\\beta)$$\n",
    "\n",
    "où $R_n(\\beta)$ est le résidu qui est négligeable par rapport à $(\\beta-\\beta_0)^{n}$. C'est à dire $R_n(\\beta)=o((\\beta-\\beta_0)^n) \\Leftrightarrow \\lim_{\\beta\\to \\beta_0\\atop \\beta\\ne \\beta_0}\\frac{R_n(\\beta)}{(\\beta-\\beta_0)^n}=0$. \n",
    "\n",
    "On a donc:\n",
    "\n",
    "$$f(\\beta) \\approx \\sum_{k=0}^n \\frac{f^{(k)}(\\beta_0)}{k!}(\\beta-\\beta_0)^k $$\n",
    "\n",
    "qu'on définira comme l'approximation de Taylor à l'ordre $n$. La méthode de Newton consiste à approximer la fonction qu'on veut minimiser par son expression à l'ordre 2:\n",
    "\n",
    "$$  f(\\beta) \\approx f(\\beta_0)\n",
    "  + f'(\\beta_0)(\\beta - \\beta_0)\n",
    "  + \\frac{f^{(2)}(\\beta_0)}{2!}(\\beta - \\beta_0)^2$$\n",
    "\n",
    "  Puis de résoudre l'annulation du gradient de cette approximation locale. On trouve donc une valeur qui annule le gradient qu'on nomme $\\beta_1$:\n",
    "\n",
    "$$  f'(\\beta) = f'(\\beta_0) + f^{(2)}(\\beta_0)(\\beta_1 - \\beta_0) = 0 \\Leftrightarrow \\beta_1 = \\beta_0 -\\frac{f'(\\beta_0)}{f^{(2)}(\\beta_0)}$$\n",
    "\n",
    "  on exprime ensuite à nouveau l'approximation à l'ordre 2 au voisinage de $\\beta_1$ et on recommence. On construit ainsi un algorithme itératif pour produire une séquences de solutions convergeants vers celle qui minimise localement la fonction de coût (i.e. la fonction objectif). \n",
    "\n",
    "  Cette procédure se généralise très bien pour des fonctions à plusieurs variables ou l'approximation de Taylor à l'odre 2 est donnée par :\n",
    "\n",
    "$$ f(\\boldsymbol{\\beta}) \\approx f(\\boldsymbol{\\beta_0})\n",
    "  + (\\boldsymbol{\\beta} - \\boldsymbol{\\beta_0})^T\\nabla_{\\boldsymbol{\\beta_0}}f\n",
    "  + \\frac{1}{2}(\\boldsymbol{\\beta} - \\boldsymbol{\\beta_0})^T\\big[H_{\\boldsymbol{\\beta_0}}\\big](\\boldsymbol{\\beta} - \\boldsymbol{\\beta_0})$$\n",
    "\n",
    "  où $\\nabla_{\\boldsymbol{\\beta_0}}f$ et $H_{\\boldsymbol{\\beta_0}}$ sont respeictvement le gradient et la matrice Hessienne de f calculées en $\\boldsymbol{\\beta_0}$. Et on obtient une itération de la forme:\n",
    "\n",
    "\n",
    "$$  \\boldsymbol{\\beta_{t+1}} = \\boldsymbol{\\beta_t} -\\big[H_{\\boldsymbol{\\beta_0}}\\big]^{-1}\\nabla_{\\boldsymbol{\\beta_0}}f$$\n",
    "\n",
    "\n",
    "  <span style=\"color:blue\">**Remarque:**</span> Cela ressemble aux itération de l'algorithme de descente de gradient ou l'inverse de la matrice hessienne jouerait le rôle du learning rate (si on remplace $\\big[H_{\\boldsymbol{\\beta_0}}\\big]^{-1}$ par $\\rho \\big[\\boldsymbol{I}\\big]$ on retrouve bien la même chose). Intuitivement, les méthode du second ordre sont en quelque sorte adaptative en fonction de la courbure local de la fonction de cout. Plus la fonction est courbé localement, plus le pas de gradient sera petit, et vice versa. Ce genre d'approche permettant d'adapter le learning rate en fonction de la courbure a pour avantage de converger plus rapidement mais au prix couteux d'une inversion de la matrice Hessienne qui peut être lourd mais aussi instable numériquement. De nombreuses méthodes on été développées pour approximer cette matrice hessienne par une matrice plus creuses et dont l'inversion est plus stable (méthode de type approximation quasi-diagonale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application au cas de la regression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà vu au dessus l'expression du gradient de la fonction de cout associé à la regression logistique :\n",
    "\n",
    "$$\\nabla f(\\boldsymbol{\\beta})=\\frac{1}{n}X^T(\\sigma(X\\boldsymbol{\\beta})-\\boldsymbol{y})= \\frac{1}{n}X^T(\\hat{\\boldsymbol{y}}-\\boldsymbol{y})$$\n",
    "\n",
    "\n",
    "On peut montrer que la hessienne peut s'exprimer comme :\n",
    "\n",
    "$$\\boldsymbol{H} = \\frac{1}{n}\\sum_{i=0}^n \\boldsymbol{x_i}\\big(\\sigma(\\boldsymbol{x_i}^T\\boldsymbol{\\beta})(1-\\sigma(\\boldsymbol{x_i}^T\\boldsymbol{\\beta}))\\big)\\boldsymbol{x_i}^T = \\frac{1}{n} X^TWX$$\n",
    "\n",
    "\n",
    "Où l'on note $W_t$ la matrice diagonale dont le $i$-eme terme sur la diagonale vaut $\\sigma(\\boldsymbol{x_i}^T\\boldsymbol{\\beta})(1-\\sigma(\\boldsymbol{x_i}^T\\boldsymbol{\\beta}) = \\hat{y_i}(1-\\hat{y_i})$. On a donc une expression pour l'itération:\n",
    "\n",
    "$$  \\boldsymbol{\\beta_{t+1}} = \\boldsymbol{\\beta_t} - [X^TW_tX]^{-1}X^T(\\hat{\\boldsymbol{y}}-\\boldsymbol{y})$$\n",
    "\n",
    "**Remarque:** On trouve une expression très analogue à celle des équations normales de la regression linéaire si ce n'est qu'on doit appliquer cette opération de manière itérative (en pratique peut d'itérations suffisent comme c'est une méthode d'ordre 2). C'est d'ailleurs pour cette raison que l'on utilise l'expression Iterative Reweighted Least Square pour cette méthode d'optimisation dans le cadre de la regression logistique, car cela revient quasiment à la même chose en remplaçant la cible y par l'erreur de prediction et en ajoutant une matrice de poids W. Cette matrice va clairement jouer sur la singularité/le conditionnement de la matrice à inverser. Le problème qu'on avait précédemment pour la regression linéaire sur le conditionnement dépendait uniquement du fait que différents exemples pouvait être trop \"corrélés\", ici la matrice W peut venir soit améliorer le conditionnement de $X^TX$ ou bien l'empirer. D'un coté les le termes $\\hat{y_i}(1 - y_i)$ font converger, mais comme ils aparaissent aussi dans $W_t$ qui est en inverse dans l'expression, si des points commencent à être bien prédit, ils peuvent provoquer l'explosion de certains coefficients de la solution du fait de la singularité de $[X^TW_tX]$. Une technique de régularisation (à la ridge) peut donc vite être nécessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Question:**</span> Proposez une méthode $\\texttt{hessian}$ dans l'objet $\\texttt{CrossEntropy}$ permettant de calculer la hessienne et, à l'instar de l'objet $\\texttt{GradientDescent}$ qui vous est adressé en bas, construisez un objet $\\texttt{Newton}$ qui implémente la méthode IRWLS vu dans cette section. Testez votre code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "class CrossEntropyNewton(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.idx = np.array([i for i in range(self.X.shape[0])])\n",
    "        self._pos = 0\n",
    "        \n",
    "    def _format_ndarray(arr):\n",
    "        arr = np.array(arr) if type(arr) is not np.ndarray else arr\n",
    "        return arr.reshape((arr.shape[0], 1)) if len(arr.shape) == 1 else arr\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = (1+np.exp(-np.dot(X, self.beta)))**(-1)\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def val(self, beta):\n",
    "        beta = CrossEntropy._format_ndarray(beta)\n",
    "        p = sigmoid(np.dot(X, beta))\n",
    "        log_p = -np.concatenate([np.log(1-p), np.log(p)], axis=1)[np.arange(len(self.X)), y]\n",
    "        return log_p.sum()/len(self.X)\n",
    "    \n",
    "    \n",
    "    def grad(self, beta):\n",
    "        X, y = self.X, self.y\n",
    "        y = CrossEntropy._format_ndarray(y)\n",
    "\n",
    "        beta = CrossEntropy._format_ndarray(beta)\n",
    "\n",
    "        grad = np.dot(X.T, sigmoid(np.dot(X, beta))   - y)\n",
    "        return grad\n",
    "    \n",
    "    def hessian(self, beta):\n",
    "        X, y = self.X, self.y\n",
    "        y = CrossEntropy._format_ndarray(y)\n",
    "        beta = CrossEntropy._format_ndarray(beta)\n",
    "        \n",
    "        predictions = sigmoid(np.dot(X, beta))\n",
    "        W = np.diag(predictions[:, 0]*(1-predictions[:, 0]))\n",
    "        XWX = np.dot(np.dot(X.T, W), X)\n",
    "        return XWX\n",
    "    \n",
    "X, y = perfect_data_sampler(1000, real_beta)\n",
    "\n",
    "\n",
    "loss = CrossEntropyNewton(X, y)\n",
    "beta = np.random.uniform(-4, 4, size=3).reshape((3, 1))\n",
    "print('Hessian:\\n', loss.hessian(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = perfect_data_sampler(100, real_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Newton(object):\n",
    "    init = np.random.uniform(-4, 4, size=3).reshape((3, 1))\n",
    "    def __init__(self, X, y, loss=CrossEntropyNewton):\n",
    "        self.loss = loss(X, y)\n",
    "        \n",
    "    def optimize(self, nb_iterations=10, beta=init):\n",
    "        param_trace = [beta.T[0]]\n",
    "        loss_trace = [self.loss.val(beta)]\n",
    "        for i in range(nb_iterations):\n",
    "            beta = beta - np.dot(np.linalg.pinv(self.loss.hessian(beta)), self.loss.grad(beta))\n",
    "            param_trace.append(beta.T[0])\n",
    "            loss_trace.append(self.loss.val(beta))\n",
    "            \n",
    "        return param_trace, loss_trace\n",
    "\n",
    "\n",
    "init = np.zeros((3, 1))\n",
    "    \n",
    "gd = GradientDescent(X, y)\n",
    "newton = Newton(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gd = []\n",
    "loss_newton = []\n",
    "it = 50\n",
    "params, loss_gd = gd.optimize(nb_iterations=it, learning_rate=2., beta=init)\n",
    "params, loss_newton = newton.optimize(nb_iterations=it, beta=init)\n",
    "plt.figure()\n",
    "plt.title(\"Évolution de la loss en fonction du nombre d'itérations\")\n",
    "plt.plot([i+1 for i in range(len(loss_gd))], loss_gd, label='GD')\n",
    "plt.plot([i+1 for i in range(len(loss_gd))], loss_newton, label='Newton')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut jouer avec le learning rate pour se rendre compte de l'efficacité de la méthode \"Newton\". Un learning rate trop fort pour la descente de gradient la rendra instable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP 2 - Logistic regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
