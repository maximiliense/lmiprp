
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Machine learning et mal√©diction de la dimension &#8212; Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Les arbres de r√©gression et de classification" href="2_regression_and_classification_trees.html" />
    <link rel="prev" title="Le Machine Learning, c‚Äôest quoi ?" href="0_propos_liminaire.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Machine Learning
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../0_requisite/rappels_python.html">
   Rappels de Python et Numpy
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="0_propos_liminaire.html">
   Le
   <em>
    Machine Learning
   </em>
   , c‚Äôest quoi ?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     <em>
      Machine learning
     </em>
     et mal√©diction de la dimension
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="2_regression_and_classification_trees.html">
     Les arbres de r√©gression et de classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../2_linear_regression/0_propos_liminaire.html">
   La
   <em>
    r√©gression
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_linear_regression/1_linear_regression.html">
     La r√©gression lin√©aire ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_linear_regression/2_optimization.html">
     L‚Äôoptimisation ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_linear_regression/3_interpolation.html">
     Interpolation ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_linear_regression/4_algo_proximal_lasso.html">
     Sous-diff√©rentiel et le cas du Lasso ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../3_logistic_regression/0_propos_liminaire.html">
   La
   <em>
    classification
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_logistic_regression/1_logistic_regression.html">
     La R√©gression Logistique ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_logistic_regression/2_fonctions_proxy.html">
     Les fonctions proxy ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_logistic_regression/3_bayes_classifier.html">
     Le classifieur de Bayes ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_logistic_regression/4_VC_theory.html">
     La th√©orie de Vapnik et Chervonenkis ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è (üíÜ‚Äç‚ôÇÔ∏è)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../4_max_margin/0_propos_liminaire.html">
   Les mod√®les
   <em>
    max-margin
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_max_margin/1_max_margin.html">
     Les mod√®les max-margin ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../5_ensembles/0_propos_liminaire.html">
   Les m√©thodes
   <em>
    ensemblistes
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_ensembles/1_ensembles.html">
     Les m√©thodes ensemblistes ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../6_autodiff/0_propos_liminaire.html">
   La diff√©rentiation automatique
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_autodiff/1_autodiff.html">
     La diff√©rentiation automatique et un d√©but de
     <em>
      deep learning
     </em>
     ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_autodiff/2_filters_representation.html">
     Filtres et espace de repr√©sentation des r√©seaux de neurones ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../7_regularization/0_propos_liminaire.html">
   La r√©gularisation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_regularization/1_regularization_deep.html">
     R√©gularisation en deep learning ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_regularization/2_unsupervised_representation_learning.html">
     Unsupervised representation learning ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_regularization/3_multitask.html">
     L‚Äôapprentissage multi-t√¢ches ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_regularization/4_adversarial.html">
     Les attaques adversaires ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_regularization/5_ridge.html">
     Une analyse de la r√©gularisation Ridge ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../content.html">
   Content in Jupyter Book
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../markdown.html">
     Markdown Files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks.html">
     Content with notebooks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/1_what_is_ml/1_introduction_ml.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/maximiliense/lmiprp"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/maximiliense/lmiprp/issues/new?title=Issue%20on%20page%20%2F1_what_is_ml/1_introduction_ml.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/maximiliense/lmiprp/master?urlpath=tree/1_what_is_ml/1_introduction_ml.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#i-introduction">
   I. Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-l-apprentissage-supervise">
     A. L‚Äôapprentissage supervis√©
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-l-apprentissage-non-supervise">
     B. L‚Äôapprentissage non-supervis√©
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ii-on-casse-une-idee-preconcue-as">
   II. On casse une id√©e pr√©con√ßue (AS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iii-une-autre-premiere-approche-logique-le-knn-as">
   III. Une autre premi√®re approche logique : le KNN (AS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iv-les-arbres-de-decision-ou-classification-and-regression-tree-cart-as">
   IV. Les arbres de d√©cision ou Classification and regression Tree (CART) (AS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#v-les-forets-aleatoires-ou-random-forest-rf-as">
   V. Les for√™ts al√©atoires ou Random Forest (RF) (AS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vi-choix-des-hyperparametres-as">
   VI. Choix des hyperparam√®tres (AS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vii-l-algorithme-des-k-moyennes-ans">
   VII. L‚Äôalgorithme des K-Moyennes (ANS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#viii-la-malediction-de-la-dimension">
   VIII. La mal√©diction de la dimension
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#en-details">
     En d√©tails
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="machine-learning-et-malediction-de-la-dimension">
<h1><em>Machine learning</em> et mal√©diction de la dimension<a class="headerlink" href="#machine-learning-et-malediction-de-la-dimension" title="Permalink to this headline">¬∂</a></h1>
<p>Quelques liens pour plus de d√©tails :</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/maximiliense/lmpirp/blob/main/Notes/Overfitting.pdf">Overfitting</a></p></li>
<li><p><a class="reference external" href="https://github.com/maximiliense/lmpirp/blob/main/Notes/KNN.pdf">KNN</a></p></li>
</ul>
<p><strong>Objectif :</strong> Cette s√©quence a pour objectif d‚Äôintroduire les bases du <em>machine learning</em> illustr√©es via quelques algorithmes particuliers. Il s‚Äôagit de sensibiliser √† l‚Äôid√©e de classification, r√©gression, supervis√© ou non supervis√©, √† la notion de sur-apprentissage ainsi qu‚Äô√† la mal√©diction de la dimension.</p>
<p>Des approfondissements et d‚Äôautres mod√®les seront pr√©sent√©s au travers des diff√©rentes s√©quences qui composent ce cours.</p>
<div class="section" id="i-introduction">
<h2>I. Introduction<a class="headerlink" href="#i-introduction" title="Permalink to this headline">¬∂</a></h2>
<p>Imaginons que nous souhaitions construire une application qui prendrait en entr√©e une image de chien ou de chat et doive pr√©dire laquelle des deux esp√®ces est repr√©sent√©e. Imaginons encore une application qui prendrait en entr√©e un mail qu‚Äôelle classifierait comme SPAM ou NONSPAM. Supposons qu‚Äôil existe deux cat√©gories de clients qu‚Äôon ne connait pas <em>a priori</em> et que l‚Äôentreprise souhaite pr√©dire pour chacun des clients sa cat√©gorie. On peut vouloir pr√©dire la temp√©rature qu‚Äôil fera demain √† partir de donn√©es relev√©es aujourd‚Äôhui.</p>
<p>Une constante est partag√©e par l‚Äôensemble de ces sc√©narios. Il y a tout d‚Äôabord une donn√©e d‚Äôentr√©e plus ou moins complexe et structur√©e. On notera <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> l‚Äôespace auquel elle appartient. Ensuite, √† partir de cette donn√©e, l‚Äôobjectif est de faire une pr√©diction. Notons <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> l‚Äôespace auquel appartient cette pr√©diction. On appelle √ßa aussi nos labels ou nos variables √† expliquer. Notre objectif, en tant que <em>machine learner</em> est de construire une fonction <span class="math notranslate nohighlight">\(h:\mathcal{X}\mapsto\mathcal{Y}\)</span> qui aura de <em>bonnes performances</em> ‚Äúen production‚Äù, c‚Äôest-√†-dire sur des donn√©es nouvelles que nous n‚Äôavons jamais vu (i.e. on ne veut pas pr√©dire la m√©t√©o d‚Äôhier √† partir d‚Äôavant hier, mais bien de demain √† partir d‚Äôaujourd‚Äôhui).</p>
<p>Deux types d‚Äôapprentissage sont g√©n√©ralement oppos√©s : l‚Äôapprentissage supervis√© (AS) et non-supervis√© (ANS).</p>
<div class="section" id="a-l-apprentissage-supervise">
<h3>A. L‚Äôapprentissage supervis√©<a class="headerlink" href="#a-l-apprentissage-supervise" title="Permalink to this headline">¬∂</a></h3>
<p>L‚Äôapprentissage supervis√© part du principe que (1) nos labels (i.e. l‚Äôespace <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>) est bien d√©fini et (2) que nous avons acc√®s √† des donn√©es associant des √©l√©ments de <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> √† leur label <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>.</p>
<p>On parlera de probl√®me de r√©gression si par exemple <span class="math notranslate nohighlight">\(\mathcal{Y}\subseteq\mathbb{R}\)</span> ou de probl√®me de classification si <span class="math notranslate nohighlight">\(\mathcal{Y}=\{1, \ldots, C\}\)</span> o√π l‚Äôordre n‚Äôest pas important. Par exemple, pr√©dire la temp√©rature est un probl√®me de r√©gression alors que pr√©dire si la photo repr√©sente un chien ou un chat est un probl√®me de classification.</p>
<p>A fortiori, toutes les observations dans <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> ne sont pas n√©cessairement √©quiprobables. Certains clients ont peut-√™tre, par exemple, un profil plus commun que d‚Äôautres. Afin de pouvoir d√©finir plus rigoureusement ce qu‚Äôon entend pas <em>bonnes performances</em>, notons <span class="math notranslate nohighlight">\(X\in\mathcal{X}\)</span> une variable al√©atoire qui d√©crit nos donn√©es observ√©es et <span class="math notranslate nohighlight">\(Y\in\mathcal{Y}\)</span> la variable al√©atoire associ√©e √† nos labels. Assez na√Øvement, notons <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> la loi de notre couple <span class="math notranslate nohighlight">\(X,Y\)</span> :</p>
<div class="math notranslate nohighlight">
\[X, Y\sim \mathbb{P}.\]</div>
<p>Notons <span class="math notranslate nohighlight">\(r:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}^+\)</span> une mesure d‚Äôerreur, un risque √©l√©mentaire. On a par exemple, dans le cas d‚Äôun probl√®me de r√©gression, l‚Äôerreur quadratique :</p>
<div class="math notranslate nohighlight">
\[r(\hat{y}, y)=(\hat{y}-y)^2,\]</div>
<p>o√π <span class="math notranslate nohighlight">\(\hat{y}\)</span> est la pr√©diction que ferait notre mod√®le. Ou encore, dans le cas de la classification cette fois-ci l‚Äôerreur <span class="math notranslate nohighlight">\(0.1\)</span> :</p>
<div class="math notranslate nohighlight">
\[r(\hat{y}, y)=\textbf{1}\{\hat{y}\neq y\},\]</div>
<p>qui vaut <span class="math notranslate nohighlight">\(1\)</span> si la pr√©diction est mauvaise ou <span class="math notranslate nohighlight">\(0\)</span> sinon.</p>
<p>Notre objectif est tout naturellement de trouver une application <span class="math notranslate nohighlight">\(h:\mathcal{X}\mapsto\mathcal{Y}\)</span> telle que <span class="math notranslate nohighlight">\(R(h)=\mathbb{E}\big[r(h(X), Y)\big]\)</span> est petit. On veut un bon mod√®le sur de nouvelles donn√©es. L‚Äôid√©e va √™tre de collecter des donn√©es repr√©sentatives (dans le sens iid) et de construire notre mod√®le avec ces derni√®res. Notons :</p>
<div class="math notranslate nohighlight">
\[S_n=\{(X_i, Y_i)\}_{i\neq n}\]</div>
<p>un jeu de donn√©es de taille <span class="math notranslate nohighlight">\(n\)</span>.</p>
</div>
<div class="section" id="b-l-apprentissage-non-supervise">
<h3>B. L‚Äôapprentissage non-supervis√©<a class="headerlink" href="#b-l-apprentissage-non-supervise" title="Permalink to this headline">¬∂</a></h3>
<p>Ici, c‚Äôest l‚Äôinverse. Nous avons acc√®s √† l‚Äôespace des observations <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> duquel on peut collecter des donn√©es (toujours selon la loi de la variable al√©atoire <span class="math notranslate nohighlight">\(X\)</span>). On sait qu‚Äôil existe un espace <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> cible mais (1) il n‚Äôest pas n√©cessairement connu et (2) nous ne connaissons pas d‚Äôexemple de liens entre exemples d‚Äôapprentissage et cibles associ√©es.</p>
<p>Par exemple, si <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> repr√©sente des donn√©es clients, on peut savoir (se douter) qu‚Äôil existe des groupes de clients qui se ressemblent mais ne pas les conna√Ætre et ne pas savoir combien il y en a. Il s‚Äôagit ici d‚Äôune t√¢che de <em>clustering</em> o√π on cherche √† regroupe des donn√©es entre-elles toujours de mani√®re √† ce que le regroupement g√©n√©ralise √† de nouvelles donn√©es.</p>
<p>On peut chercher √† transformer nos donn√©es dans <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> dans un espace qu‚Äôon notera cette fois-ci <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> o√π ces derni√®res auront de meilleures propri√©t√©. On note cet ‚Äúespace de repr√©sentation‚Äù <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> et non <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> car il s‚Äôagit souvent d‚Äôune √©tape interm√©diaire avant une t√¢che supervis√© o√π on chercherait √† pr√©dire un label dans <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. C‚Äôest ce qu‚Äôon appelle l‚Äôapprentissage de repr√©sentation. Ainsi, si <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> est l‚Äôensemble des photos de chiens et de chats, <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> est l‚Äôensemble de ces derni√®res o√π on a mis ‚Äúd‚Äôun c√¥t√©‚Äù les photos de chiens et de ‚Äúl‚Äôautres‚Äù celles de chats. Il devient simple de construire une t√¢che supervis√©e permettant de pr√©dire le bon label ‚Äúchien/chat‚Äù.</p>
</div>
</div>
<div class="section" id="ii-on-casse-une-idee-preconcue-as">
<h2>II. On casse une id√©e pr√©con√ßue (AS)<a class="headerlink" href="#ii-on-casse-une-idee-preconcue-as" title="Permalink to this headline">¬∂</a></h2>
<p>Soit <span class="math notranslate nohighlight">\(S=\{(x_i, y_i)\}_{i\leq n}\)</span> un jeu de donn√©es repr√©sentatif de taille <span class="math notranslate nohighlight">\(n\)</span>. Un mod√®le tr√®s performant sur ces donn√©es est-il performant sur des donn√©es nouvelles ?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">metrics</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<p>Chargeons et affichons notre jeu de donn√©es. Ce dernier consiste en des chiffres √©crits √† la main. L‚Äôobjectif va √™tre de faire un mod√®le qui permet de pr√©dire ces derniers.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray_r</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Training: </span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_9_0.png" src="../_images/1_introduction_ml_9_0.png" />
</div>
</div>
<p>Construisons notre premier mod√®le.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Memorize</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">memorized</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">memorized</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">memorized</span><span class="p">:</span>
                <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># flatten the images</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split data into 50% train and 50% test subsets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Les donn√©es de test nous permettront de tester notre mod√®le sur des donn√©es qu‚Äôil n‚Äôa pas utilis√© pour se construire.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Memorize</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>On commence par tester les performances de notre mod√®le sur notre jeu d‚Äôapprentissage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Classification report for classifier Memorize on train:</span><span class="se">\n</span><span class="s1">&#39;</span>
      <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification report for classifier Memorize on train:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        90
           1       1.00      1.00      1.00        91
           2       1.00      1.00      1.00        91
           3       1.00      1.00      1.00        92
           4       1.00      1.00      1.00        89
           5       1.00      1.00      1.00        91
           6       1.00      1.00      1.00        90
           7       1.00      1.00      1.00        90
           8       1.00      1.00      1.00        86
           9       1.00      1.00      1.00        88

    accuracy                           1.00       898
   macro avg       1.00      1.00      1.00       898
weighted avg       1.00      1.00      1.00       898
</pre></div>
</div>
</div>
</div>
<p>Notre mod√®le est parfait ! Aucune erreur. On ne peut pas faire mieux ! Et du c√¥t√© du test ?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Classification report for classifier Memorize on test:</span><span class="se">\n</span><span class="s1">&#39;</span>
      <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification report for classifier Memorize on test:
              precision    recall  f1-score   support

           0       0.10      0.09      0.10        88
           1       0.09      0.11      0.10        91
           2       0.04      0.05      0.04        86
           3       0.11      0.11      0.11        91
           4       0.09      0.08      0.08        92
           5       0.12      0.12      0.12        91
           6       0.04      0.04      0.04        91
           7       0.09      0.09      0.09        89
           8       0.15      0.16      0.15        88
           9       0.18      0.15      0.16        92

    accuracy                           0.10       899
   macro avg       0.10      0.10      0.10       899
weighted avg       0.10      0.10      0.10       899
</pre></div>
</div>
</div>
</div>
<p>C‚Äôest ridiculement mauvais : on se trompe une fois sur dix, soit exactement ce qu‚Äôon attendrait d‚Äôune r√©ponse al√©atoire.</p>
<p>Oui mais on a fait expr√®s de construire le mod√®le de cette mani√®re ! En r√©alit√©, il existe une infinit√© fonction, param√©triques ou non, qu‚Äôon peut rendre aussi bonne qu‚Äôon veut sur nos donn√©es mais qui seraient particuli√®rement mauvaises sur de nouvelles donn√©es (cela inclut les mod√®les usuels et c‚Äôest pour cela qu‚Äôon a besoin d‚Äôexperts !)‚Ä¶ Toute la difficult√© du <em>machine learner</em> va √™tre de contr√¥ler cela.</p>
</div>
<div class="section" id="iii-une-autre-premiere-approche-logique-le-knn-as">
<h2>III. Une autre premi√®re approche logique : le KNN (AS)<a class="headerlink" href="#iii-une-autre-premiere-approche-logique-le-knn-as" title="Permalink to this headline">¬∂</a></h2>
<p>Intuitivement, on a envie de dire que nos donn√©es ne sont pas compl√®tement d√©structur√©es. Deux clients tr√®s similaires ach√®teront tr√®s probablement des produits tr√®s similaires. Un trois ressemble plus √† un trois qu‚Äô√† un cinq et un cinq ressemble plus √† un cinq qu‚Äô√† un trois. Finalement, on g√©n√©ralise un petit peu l‚Äôexemple pr√©c√©dent. Au lieu de r√©pondre al√©atoirement si je ne connais pas la donn√©e, je cherche l‚Äôexemple le plus proche et je pr√©dis le m√™me label ! Plus rigoureusement, notre mod√®le de pr√©diction fonctionne comme suit :</p>
<div class="math notranslate nohighlight">
\[\hat{y}_\text{new}=y\text{ avec }(x, y)=\text{argmin}_{(x, y)\in S}\lVert x-x_{\text{new}}\rVert_2.\]</div>
<p>On peut imaginer que si plusieurs points sont √©quidistants, la r√©ponse se fait al√©atoirement entre les labels possibles.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Utilisez l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{KNeighborsClassifier}\)</span> avec le param√®tre <span class="math notranslate nohighlight">\(\texttt{n}\_\texttt{neighbors=1}\)</span> et entra√Ænez le sur <span class="math notranslate nohighlight">\(\texttt{X}\_\texttt{train}\)</span>.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####### Complete this part ######## or die ####################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1">###############################################################</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KNeighborsClassifier(n_neighbors=1)
</pre></div>
</div>
</div>
</div>
<p>On teste maintenant sur le jeu de train pour avoir une id√©e des performances de notre mod√®le sur ce dernier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Classification report for classifier </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1"> on train:</span><span class="se">\n</span><span class="s1">&#39;</span>
      <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification report for classifier KNeighborsClassifier(n_neighbors=1) on train:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        90
           1       1.00      1.00      1.00        91
           2       1.00      1.00      1.00        91
           3       1.00      1.00      1.00        92
           4       1.00      1.00      1.00        89
           5       1.00      1.00      1.00        91
           6       1.00      1.00      1.00        90
           7       1.00      1.00      1.00        90
           8       1.00      1.00      1.00        86
           9       1.00      1.00      1.00        88

    accuracy                           1.00       898
   macro avg       1.00      1.00      1.00       898
weighted avg       1.00      1.00      1.00       898
</pre></div>
</div>
</div>
</div>
<p>On est toujours aussi bon sur le jeu d‚Äôapprentissage ! Cependant, c‚Äôest attendu car l‚Äôimage qui ressemble le plus √† une autre est l‚Äôimage elle-m√™me. Pr√©disons maintenant sur le test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Classification report for classifier </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1"> on test:</span><span class="se">\n</span><span class="s1">&#39;</span>
      <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification report for classifier KNeighborsClassifier(n_neighbors=1) on test:
              precision    recall  f1-score   support

           0       0.99      0.99      0.99        88
           1       0.96      0.97      0.96        91
           2       0.99      0.97      0.98        86
           3       0.91      0.92      0.92        91
           4       0.99      0.95      0.97        92
           5       0.96      0.98      0.97        91
           6       0.99      1.00      0.99        91
           7       0.99      0.99      0.99        89
           8       0.94      0.92      0.93        88
           9       0.91      0.93      0.92        92

    accuracy                           0.96       899
   macro avg       0.96      0.96      0.96       899
weighted avg       0.96      0.96      0.96       899
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">figure_</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_35_0.png" src="../_images/1_introduction_ml_35_0.png" />
</div>
</div>
<p>Is Machine learning solved ? Minute papillon ! Ce mod√®le est tr√®s sensible au bruit ! Supposons qu‚Äôune de nos donn√©es soient bruit√©es (e.g. un 3 qui ressemble √† un 8). Si une nouvelle donn√©e repr√©sentant un <span class="math notranslate nohighlight">\(8\)</span> se retrouve √† c√¥t√© de cette anomalie, elle sera mal pr√©dite. Nous pouvons adresser cette limite de la mani√®re suivante : au lieu de regarder le point le plus proche, on regarde les <span class="math notranslate nohighlight">\(k\)</span> points les plus proches et on fait un vote √† la majorit√©. Plus formellement la pr√©diction est faite comme suit :</p>
<div class="math notranslate nohighlight">
\[\hat{y}_\text{new}=\text{majority$\_$voting}(\texttt{KNN}.\texttt{labels})\text{ o√π }\texttt{KNN}=\text{argmin}_{S^\prime\subset S,\ |S^\prime|=K}\sum_i \lVert x_i- x_{\text{new}}\rVert.\]</div>
<p>Dans le cas o√π on chercherait √† faire une r√©gression, on remplace le vote √† la majorit√© par une moyenne.</p>
<p>R√©cup√©rons le jeu de donn√©es <span class="math notranslate nohighlight">\(\texttt{iris}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="c1"># d√©commentez la ligne suivante pour obtenir des informations</span>
<span class="c1"># sur le dataset iris.</span>
<span class="c1"># print(iris.DESCR)</span>
</pre></div>
</div>
</div>
</div>
<p>De la m√™me mani√®re que pr√©c√©demment, on construit notre jeu d‚Äôapprentissage pour construire notre mod√®le et notre jeu de test pour en tester les performances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Utilisez l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{KNeighborsClassifier}\)</span> avec le param√®tre <span class="math notranslate nohighlight">\(\texttt{n}\_\texttt{neighbors=1}\)</span> et entra√Ænez le sur <span class="math notranslate nohighlight">\(\texttt{X}\_\texttt{train}\)</span>. Faites une pr√©diction sur <span class="math notranslate nohighlight">\(\texttt{predicted=X}\_\texttt{test}\)</span>.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####### Complete this part ######## or die ####################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1">###############################################################</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">figure_</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_42_0.png" src="../_images/1_introduction_ml_42_0.png" />
</div>
</div>
<p>Les performances sont d√©j√† tr√®s bonnes ! Mais il est possible de gagner un tout petit peu de performances en consid√©rant plus de voisins :</p>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Utilisez l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{KNeighborsClassifier}\)</span> avec le param√®tre <span class="math notranslate nohighlight">\(\texttt{n}\_\texttt{neighbors=10}\)</span> et entra√Ænez le sur <span class="math notranslate nohighlight">\(\texttt{X}\_\texttt{train}\)</span>. Faites une pr√©diction sur <span class="math notranslate nohighlight">\(\texttt{predicted=X}\_\texttt{test}\)</span>.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####### Complete this part ######## or die ####################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1">###############################################################</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">figure_</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_46_0.png" src="../_images/1_introduction_ml_46_0.png" />
</div>
</div>
</div>
<div class="section" id="iv-les-arbres-de-decision-ou-classification-and-regression-tree-cart-as">
<h2>IV. Les arbres de d√©cision ou Classification and regression Tree (CART) (AS)<a class="headerlink" href="#iv-les-arbres-de-decision-ou-classification-and-regression-tree-cart-as" title="Permalink to this headline">¬∂</a></h2>
<p>De la m√™me mani√®re que pour l‚Äôalgorithme KNN, on supposera ici que nos donn√©es admettent une certaine structure et que des points proches poss√®dent probablement le m√™me label ou une prediction proche dans le cas de la r√©gression. Ici, √† la diff√©rence du KNN, la notion de voisinage se construit au travers d‚Äôhyperrectangles parall√®les aux axes. Afin de bien comprendre le fonctionnement, supposons que notre arbre de d√©cision soit d√©j√† construit. Prenons une nouvelle donn√©es <span class="math notranslate nohighlight">\(x_{\text{new}}=[3, 5]^T\)</span> et partons de la racine de notre arbre. Cette racine poss√®de deux branches sortantes. Le choix de la branche se fait √† partir d‚Äôun seuil (param√®tre associ√© au noeud racine) et d‚Äôune coordonn√©e de notre <span class="math notranslate nohighlight">\(x\)</span>. Dans notre exemple imaginons que le seuil soit <span class="math notranslate nohighlight">\(7\)</span> et que la coordonn√©e √† regarder soit <span class="math notranslate nohighlight">\(x_{\text{new}}^{(1)}=5\)</span>. C‚Äôest clairement inf√©rieur √† <span class="math notranslate nohighlight">\(7\)</span> et nous partons donc la branche de gauche de notre arbre. Nous somme sur un nouveau noeud associ√© √† un nouveau seuil et une nouvelle coordonn√©e de notre donn√©e. On r√©p√®te cette op√©ration jusqu‚Äô√† ce qu‚Äôon arrive aux feuilles de notre arbre. Chaque feuille regroupe les donn√©es du jeu d‚Äôapprentissage qui y aboutisse lorsqu‚Äôon les classe. Le choix du label se fait par un vote √† la majorit√© sur ces donn√©es ou en moyennant. L‚Äôimage suivante illustre cette id√©e :</p>
<p><img alt="Decision tree" src="https://miro.medium.com/max/360/1*XMId5sJqPtm8-RIwVVz2tg.png" /></p>
<p>Le choix de la r√®gle de d√©cision √† chaque noeud peut √™tre adapter afin d‚Äôobtenir des r√©gions √† la g√©om√©trie variable. La construction d‚Äôun arbre se fait en partant de la racine vers les feuilles et en choisissant int√©rativement les variables explicatives qui ont le plus d‚Äôeffet sur notre pr√©diction (via diverses crit√®res).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Utilisez l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{DecisionTreeClassifier}\)</span> avec le param√®tre <span class="math notranslate nohighlight">\(\texttt{n}\_\texttt{max}\_\texttt{depth=10}\)</span> et entra√Ænez le sur <span class="math notranslate nohighlight">\(\texttt{X}\_\texttt{train}\)</span>. Faites une pr√©diction sur <span class="math notranslate nohighlight">\(\texttt{predicted=X}\_\texttt{test}\)</span>.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####### Complete this part ######## or die ####################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1">###############################################################</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">figure_</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_52_0.png" src="../_images/1_introduction_ml_52_0.png" />
</div>
</div>
</div>
<div class="section" id="v-les-forets-aleatoires-ou-random-forest-rf-as">
<h2>V. Les for√™ts al√©atoires ou Random Forest (RF) (AS)<a class="headerlink" href="#v-les-forets-aleatoires-ou-random-forest-rf-as" title="Permalink to this headline">¬∂</a></h2>
<p>Les arbres de d√©cision peuvent √™tre sujets au surapprentissage. Une mani√®re de compenser le probl√®me est d‚Äôen construire plusieurs o√π chaque arbre est construit en ne voyant qu‚Äôune partie des donn√©es. Enfin leurs pr√©dictions sont aggr√©g√©es. Ces approches sont g√©n√©ralement beaucoup plus performantes que les arbres simples. Malheureusement, autant avec un arbre simple on pouvait essayer de comprendre la pr√©diction, autant ici, cela devient difficile.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Utilisez l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{RandomForestClassifier}\)</span> et entra√Ænez le sur <span class="math notranslate nohighlight">\(\texttt{X}\_\texttt{train}\)</span>. Faites une pr√©diction sur <span class="math notranslate nohighlight">\(\texttt{predicted=X}\_\texttt{test}\)</span>.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####### Complete this part ######## or die ####################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1">###############################################################</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">figure_</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_58_0.png" src="../_images/1_introduction_ml_58_0.png" />
</div>
</div>
</div>
<div class="section" id="vi-choix-des-hyperparametres-as">
<h2>VI. Choix des hyperparam√®tres (AS)<a class="headerlink" href="#vi-choix-des-hyperparametres-as" title="Permalink to this headline">¬∂</a></h2>
<p>Nous avons du, pour les mod√®les pr√©c√©dents, choisir diff√©rents param√®tres qui affectaient les performances de notre mod√®le. Nous les avons choisi en regardant les performances de notre mod√®le sur le jeu de test. Cependant, les bonnes performances √©taient peut-√™tre un coup de chance !</p>
<p>Il existe deux strat√©gies d‚Äô√©valuation sans biais de la qualit√© de notre mod√®le :</p>
<ul class="simple">
<li><p>La validation non crois√©e o√π une partie de notre jeu de donn√©e est cach√©e pendant l‚Äôapprentissage puis utilis√©e afin d‚Äô√©valuer les performances du mod√®le. Il s‚Äôagit du d√©coupage train/test. Cette strat√©gie est un estimateur sans biais de la qualit√© de notre mod√®le mais poss√®de une variance plus forte que la validation crois√©e. Elle peut-√™tre particuli√®rement utile lorsque le coup d‚Äôapprentissage d‚Äôun mod√®le est tr√®s √©lev√© (e.g. <em>deep learning</em>)</p></li>
<li><p>La validation crois√©e o√π notre jeu de donn√©es est divis√© en <em>k</em> parties (on parle aussi de <em>k-fold</em>). √âvidemment, <span class="math notranslate nohighlight">\(k\in\{2, ..., n\}\)</span> o√π <span class="math notranslate nohighlight">\(n\)</span> est la taille du jeu de donn√©es. Chacune des parties jouera successivement le r√¥le de jeu de test pendant que les <span class="math notranslate nohighlight">\(k-1\)</span> autres parties serviront √† calculer notre mod√®le. Le r√©sultat de cette proc√©dure est un vecteur de <span class="math notranslate nohighlight">\(k\)</span> scores dont on peut calculer la moyenne, la variance, etc.</p></li>
</ul>
<p>On peut illustrer la m√©thode des <em>k-folds</em> via l‚Äôexemple suivant :</p>
<p>\begin{align}
\text{Appartient au train set: } \color{red}{\boxed{}}&amp;\text{ et appartient au test set: }\color{green}{\boxed{}}
\end{align}
\begin{align}
\text{Step 1: }\color{green}{\boxed{}}\color{red}{\boxed{}}&amp;\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}
\end{align}
\begin{align}
\text{Step 2: }\color{red}{\boxed{}}\color{green}{\boxed{}}&amp;\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}
\end{align}
\begin{align}
\text{Step 3: }\color{red}{\boxed{}}\color{red}{\boxed{}}&amp;\color{green}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}
\end{align}
\begin{align}
\text{Step 4: }\color{red}{\boxed{}}\color{red}{\boxed{}}&amp;\color{red}{\boxed{}}\color{green}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}
\end{align}
\begin{align}
\text{Step 5: }\color{red}{\boxed{}}\color{red}{\boxed{}}&amp;\color{red}{\boxed{}}\color{red}{\boxed{}}\color{green}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}
\end{align}
\begin{align}
\text{Step 6: }\color{red}{\boxed{}}\color{red}{\boxed{}}&amp;\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{green}{\boxed{}}\color{red}{\boxed{}}
\end{align}
\begin{align}
\text{Step 7: }\color{red}{\boxed{}}\color{red}{\boxed{}}&amp;\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{red}{\boxed{}}\color{green}{\boxed{}}
\end{align}</p>
<p>La m√©thode <span class="math notranslate nohighlight">\(\texttt{cross_val_score}\)</span> de <span class="math notranslate nohighlight">\(\texttt{sklearn}\)</span> permet de r√©aliser cette proc√©dure. On pourra renseigner le param√®tre <span class="math notranslate nohighlight">\(\texttt{cv}\)</span> qui indique le nombre <span class="math notranslate nohighlight">\(k\)</span> et le param√®tre <span class="math notranslate nohighlight">\(\texttt{scoring}\)</span> qui donne la m√©trique que l‚Äôon souhaite calculer.</p>
<p>Si on cherche √† trouver une valeur d‚Äôun param√®tre, l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{GridSearchCV}\)</span> applique une validation crois√©e en cherchant diff√©rentes valeurs d‚Äôun param√®tres.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Utilisez l‚Äôobjet <span class="math notranslate nohighlight">\(\texttt{GridSearchCV}\)</span> pour faire une recherche par grille sur le mod√®le <span class="math notranslate nohighlight">\(\texttt{RandomForestClassifier}\)</span> et entra√Ænez le sur <span class="math notranslate nohighlight">\(\texttt{X}\_\texttt{train}\)</span>.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####### Complete this part ######## or die ####################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(),</span> <span class="n">params</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1">###############################################################</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(estimator=RandomForestClassifier(),
             param_grid={&#39;max_depth&#39;: [2, 3, 4, 5, 10, None]})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">figure_</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_65_0.png" src="../_images/1_introduction_ml_65_0.png" />
</div>
</div>
<p>Notre RandomForest de base √©tait d√©j√† tr√®s bon !</p>
</div>
<div class="section" id="vii-l-algorithme-des-k-moyennes-ans">
<h2>VII. L‚Äôalgorithme des K-Moyennes (ANS)<a class="headerlink" href="#vii-l-algorithme-des-k-moyennes-ans" title="Permalink to this headline">¬∂</a></h2>
<p>Il s‚Äôagit ici d‚Äôun algorithme non supervis√©. Imaginons que nous ayons un collect√© un jeu de donn√©es <span class="math notranslate nohighlight">\(S_n=\{(X_i)\}_{i\leq n}\)</span>. On sait qu‚Äôil existe des groupes dans nos donn√©es. Supposons m√™me qu‚Äôon s√¢che qu‚Äôil existe <span class="math notranslate nohighlight">\(K\)</span> groupes. L‚Äôid√©e de l‚Äôalgorithme des K-Moyennes va √™tre de d√©tecter ces <span class="math notranslate nohighlight">\(K\)</span> groupes en trouvant une solution au probl√®me d‚Äôoptimisation suivant :</p>
<div class="math notranslate nohighlight">
\[\text{KMeans}=\text{argmin}_{m_1, \ldots, m_K\in\mathcal{X}, c_1,\ldots,c_n\in\{1,\ldots,K\}}\sum_{i=1}^K\sum_{j=1}^n\textbf{1}\{c_1=i\}\lVert m_i-x_j\rVert_2=\text{argmin}_{m_1, \ldots, m_K\in\mathcal{X}, c_1,\ldots,c_n\in\{1,\ldots,K\}}\sum_{j=1}^n\lVert x_j-m_{c_j}\rVert_2.\]</div>
<p>Dit autrement, chaque groupe est repr√©sent√©e par une coordonn√©e <span class="math notranslate nohighlight">\(c_i\)</span> (qui s‚Äôav√®re √™tre la moyenne des √©l√©ments du groupe) et chaque √©l√©ment de notre jeu de donn√©es n‚Äôest associ√© qu‚Äô√† un seul groupe. L‚Äôobjectif va √™tre que leur distance quadratique au centre de leur groupe doit √™tre minimale !</p>
<p>Consid√©rons le jeu de donn√©es suivant.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">sample_data</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]])</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">15</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">means</span>
    <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="n">n</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">n</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
    
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sample_data</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">def</span> <span class="nf">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">means</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Nos donn√©es et leur label inconnu&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">means</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">s</span><span class="o">=</span><span class="mi">55</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_70_0.png" src="../_images/1_introduction_ml_70_0.png" />
</div>
</div>
<p>Le probl√®me de K-Means est NP-Difficile. Pour cela, nous utilisons en pratique un heuristique appel√© ‚Äúalgorithme de LLoyd‚Äù qui fonctionnde la mani√®re suivante :</p>
<ol class="simple">
<li><p>On initialise les k moyennes</p></li>
<li><p>On assigne tous nos points √† leur moyenne la plus proche</p></li>
<li><p>On met √† jour les moyennes avec les nouveaux points</p></li>
<li><p>Si le d√©placement des moyennes est significatif, on reprend √† l‚Äô√©tape 2</p></li>
</ol>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Le probl√®me est NP-Difficile et un algorithme permettant de le r√©soudre est l‚Äôalgorithme de LLoyd. Impl√©mentez le.</strong></p>
<hr class="docutils" />
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">KMeans</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1">####### Complete this part ######## or die ####################</span>
        <span class="c1"># K means initialization</span>
        <span class="n">X_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">X_</span><span class="p">)</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">X_</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">]</span>
        
        <span class="n">variation</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        
        <span class="n">assignment</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))]</span>
        
        <span class="n">path</span> <span class="o">=</span> <span class="p">[</span><span class="n">means</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
        
        <span class="k">while</span> <span class="n">variation</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="c1"># Step 1</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
                <span class="n">closest</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">closest_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">means</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                    <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">dist</span>  <span class="o">&lt;</span> <span class="n">closest_dist</span><span class="p">:</span>
                        <span class="n">closest_dist</span> <span class="o">=</span> <span class="n">dist</span>
                        <span class="n">closest</span> <span class="o">=</span> <span class="n">k</span>

                <span class="n">assignment</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">closest</span>

            <span class="c1"># Step 2</span>
            <span class="n">kmeans</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span> <span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
                <span class="n">kmeans</span><span class="p">[</span><span class="n">assignment</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            <span class="n">variation</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>

                <span class="n">new_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kmeans</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">new_mean</span><span class="o">-</span><span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">variation</span><span class="p">:</span>
                    <span class="n">variation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">new_mean</span><span class="o">-</span><span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_mean</span>
            <span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1">###############################################################</span>
        <span class="k">return</span> <span class="n">assignment</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">path</span>
            

<span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_73_0.png" src="../_images/1_introduction_ml_73_0.png" />
</div>
</div>
<p>On se rend compte qu‚Äôon arrive √† retrouver les 3 groupes automatiquement (Les couleurs sont celles calcul√©es par notre mod√®le des K-Moyennes) !</p>
</div>
<div class="section" id="viii-la-malediction-de-la-dimension">
<h2>VIII. La mal√©diction de la dimension<a class="headerlink" href="#viii-la-malediction-de-la-dimension" title="Permalink to this headline">¬∂</a></h2>
<p>Nous avons pu observer des sc√©narios o√π l‚Äôerreur sur notre jeu de donn√©es d‚Äôapprentissage √©tait <span class="math notranslate nohighlight">\(0\)</span> alors que notre mod√®le n‚Äô√©tait pas si bon que cela sur notre jeu de test. Cet √©cart peut m√™me devenir catastrophique ! De mani√®re plus rigoureuse, le gap de g√©n√©ralisation de notre estimateur <span class="math notranslate nohighlight">\(\hat{h}\)</span> est la quantit√© suivante :</p>
<p>\begin{equation}
\text{gap}(\hat{h})=|Re(\hat{h})-R(\hat{h})|.
\end{equation}</p>
<p>O√π <span class="math notranslate nohighlight">\(Re\)</span> fait r√©f√©rence √† notre risque empirique, c‚Äôest-√†-dire l‚Äôerreur sur le jeu d‚Äôapprentissage et <span class="math notranslate nohighlight">\(R\)</span> √† l‚Äôerreur en esp√©rance.</p>
<p>Il est possible d‚Äôavoir une id√©e de <span class="math notranslate nohighlight">\(R(\hat{h})\)</span> en passant par un jeu de test ou par une autre strat√©gie d‚Äô√©valuation via un jeu de test par exemple, comme nous avons pu le voir.</p>
<p>Deux facteurs principaux sont admis comme entrant en jeu dans <span class="math notranslate nohighlight">\(\text{gap}(\hat{h})\)</span> :</p>
<ul class="simple">
<li><p>la taille de l‚Äôensemble <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> qui est g√©n√©ralement li√©e au nombre de param√®tres de notre mod√®le,</p></li>
<li><p>la taille du jeu de donn√©es <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p></li>
</ul>
<p>Plus <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> est grand, plus on s‚Äôattend √† voir l‚Äôerreur augmenter. L‚Äôeffet de double descente montre qu‚Äôavec un choix r√©fl√©chi de param√©trisation, cette tendance n‚Äôest pas n√©cessairement monotone. De la m√™me mani√®re, augmenter la taille du jeu de donn√©es <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> permet de r√©duire l‚Äôerreur de g√©n√©ralisation.</p>
<p>La taille de <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> est intrins√®quement li√©e au nombre de param√®tres qui lui-m√™me d√©pend tr√®s souvent de la dimension <span class="math notranslate nohighlight">\(d\)</span> de nos donn√©es.</p>
<p>Nous allons ici nous rendre compte que les mod√®les qui regardent le voisinage de nos donn√©es souffre d‚Äôune grosse limite li√©e √† ce qu‚Äôon appelle <em>la mal√©diction de la dimension</em>.</p>
<div class="section" id="en-details">
<h3>En d√©tails<a class="headerlink" href="#en-details" title="Permalink to this headline">¬∂</a></h3>
<p>La mal√©diction de la dimension fait r√©f√©rence aux r√©sultats contre-intuitifs qui apparaissent lorsque la dimension augmente. Une premi√®re mani√®re de l‚Äôobserver est possible gr√¢ce au KNN. Ce dernier classe un nouvel √©l√©ment en fonction de ses voisins dans le jeu d‚Äôapprentissage. Nous allons en particulier √©tudier l‚Äô√©volution du risque de g√©n√©ralisation en fonction de la dimension. Plus pr√©cis√©ment, les donn√©es synth√©tiques sont construites de la mani√®re suivante :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">sample_data</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">y</span><span class="o">*</span><span class="n">X</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">X</span> <span class="c1"># positive have mean mu and negative, -mu</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="o">-</span><span class="n">k</span><span class="p">))</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">noise</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<p>Dit autrement, <span class="math notranslate nohighlight">\(k\)</span> dimensions contiennent le signal int√©ressant pour notre t√¢che et <span class="math notranslate nohighlight">\(d\)</span> dimensions ne servent √† rien. Nous observons ci-dessous ce qui se passe lorsqu‚Äôon rajouter des dimensions de bruits (i.e. qui ne servent √† rien). C‚Äôest typiquement ce pourrait se passer avec des images. Une photo de chien ne contient pas que des pixels descriptifs du concept de chien.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">redo</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">max_dim</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">first_dim</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">first_dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">,</span> <span class="n">steps</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">redo</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sample_data</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
        <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sample_data</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
        <span class="n">c</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)))</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">c</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)))</span><span class="o">/</span><span class="n">redo</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># configuration generale de matplotlib</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">12.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">first_dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">,</span> <span class="n">steps</span><span class="p">)),</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Evolution de l</span><span class="se">\&#39;</span><span class="s1">erreur en fonction de la dimension du probleme&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_82_0.png" src="../_images/1_introduction_ml_82_0.png" />
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice 1 :</strong></span> <strong>Quelle est le risque de g√©n√©ralisation pour l‚Äôerreur 0/1 (1 si la classe est mal pr√©dite, 0 sinon) d‚Äôun classifieur al√©atoire ?</strong></p>
<p><span style="color:green"><strong>R√©ponse :</strong></span></p>
<p><span style="color:blue"><strong>Exercice 2 :</strong></span> <strong>Expliquez pourquoi l‚Äôerreur de g√©n√©ralisation diminue lorsqu‚Äôon rajoute des dimensions sans signal.</strong></p>
<p><span style="color:green"><strong>R√©ponse :</strong></span></p>
<hr class="docutils" />
<p>De mani√®re similaire, affichons ci-dessous l‚Äô√©volution des distances entre nos points en fonction de la dimension du probl√®me.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">sample_data</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sample_data</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">redo</span> <span class="o">=</span> <span class="mi">50</span>
<span class="k">def</span> <span class="nf">experiment_</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="n">min_</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">max_</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">mean_</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">redo</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">sample_data</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">min_</span> <span class="o">+=</span> <span class="n">vec</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">/</span><span class="n">redo</span>
        <span class="n">max_</span> <span class="o">+=</span> <span class="n">vec</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">/</span><span class="n">redo</span>
        <span class="n">mean_</span> <span class="o">+=</span> <span class="n">vec</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">/</span><span class="n">redo</span>
    <span class="k">return</span> <span class="n">min_</span><span class="p">,</span> <span class="n">max_</span><span class="p">,</span> <span class="n">mean_</span>
<span class="n">idx</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">idx</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">d</span><span class="p">])</span>
    <span class="n">val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experiment_</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">):</span>
    <span class="n">idx</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">d</span><span class="p">])</span>
    <span class="n">val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experiment_</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">arr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">arr</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Min&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">arr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">arr</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Max&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">arr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">arr</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Moy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Evolution des distances en fonction de la dimension du probleme&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1_introduction_ml_87_0.png" src="../_images/1_introduction_ml_87_0.png" />
</div>
</div>
<hr class="docutils" />
<p><span style="color:blue"><strong>Exercice :</strong></span> <strong>Quelle ph√©nom√®ne math√©matique pouvons nous invoquer afin d‚Äôexpliquer ce ph√©nom√®ne ?</strong></p>
<p><span style="color:green"><strong>R√©ponse :</strong></span></p>
<hr class="docutils" />
<p>Soit <span class="math notranslate nohighlight">\(x_\text{new}\)</span> une nouvelle donn√©e. Une petite perturbation du point de notre jeu d‚Äôapprentissage le plus diff√©rent de <span class="math notranslate nohighlight">\(x_\text{new}\)</span> peut le transformer en le point le plus proche est inversement‚Ä¶ C‚Äôest une grosse limite des mod√®les pr√©c√©dents. Il faut soit r√©fl√©chir √† r√©duire la dimension, soit injecter de la connaissance dans nos mod√®les, etc.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./1_what_is_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="0_propos_liminaire.html" title="previous page">Le <em>Machine Learning</em>, c‚Äôest quoi ?</a>
    <a class='right-next' id="next-link" href="2_regression_and_classification_trees.html" title="next page">Les arbres de r√©gression et de classification</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The LMIPR team<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>