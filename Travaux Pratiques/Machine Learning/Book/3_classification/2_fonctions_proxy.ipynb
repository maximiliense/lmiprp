{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Les fonctions de perte (loss function) \u2615\ufe0f\u2615\ufe0f\u2615\ufe0f"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Objectifs de la s\u00e9quence</span>** ", "\n", "* Comprendre&nbsp;:\n", "    * pourquoi on ne minimise pas en g\u00e9n\u00e9ral le nombre d'erreurs,\n", "    * les caract\u00e9ristiques des fonctions (*loss*) qu'on minimise en pratique.\n", "* \u00catre capable de&nbsp;:\n", "    * proposer une *loss*,\n", "    * et la minimiser.\n", "    \n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Situons-nous dans le cadre d'un probl\u00e8me de classification supervis\u00e9 et notons $\\mathcal{X}\\subseteq\\mathbb{R}^d$ et $\\mathcal{Y}=\\{0, 1\\}$ ou $\\mathcal{Y}=\\{-1,+1\\}$ selon le contexte et afin de simplifier les notations. Notons \u00e9galement $X,Y\\in\\mathcal{X}\\times\\mathcal{Y}$ deux variables al\u00e9atoires telles que $\\mu$ est la mesure de $X$ et $\\eta(x)=\\mathbb{P}(Y=1|X=x)$. La connaissance de $\\mu$ et de $\\eta$ nous donne toutes les informations propres au processus g\u00e9n\u00e9rateur de notre probl\u00e8me. Nous pouvons d'ailleurs construire la mesure jointe. Soit $A\\subseteq \\mathcal{X}\\times\\mathcal{Y}$, nous avons:\n", "\n", "$$\\mathbb{P}(X, Y \\in A)=\\int_{A\\cap \\mathcal{X}\\times \\{1\\}}\\eta(x)d\\mu+\\int_{A\\cap \\mathcal{X}\\times \\{0\\}}(1-\\eta(x))d\\mu.$$\n", "\n", "Notre objectif est de trouver une application $h:\\mathcal{X}\\mapsto\\mathcal{Y}$ tel qu'un risque est minimis\u00e9. *A priori* ce que nous souhaitons faire est de minimiser le nombre d'erreurs. Pour cela, nous d\u00e9finissons le risque dit $0/1$:\n", "\n", "$$L(h)=\\mathbb{P}(h(X)\\neq Y)=\\mathbb{E}\\big[1\\{X\\neq Y\\}\\big].$$\n", "\n", "Nous ne connaissons malheureusement ni $\\mu$ ni $\\eta$ et pour cela, nous devons estimer le risque $L$ sur un jeu de donn\u00e9es:\n", "\n", "$$S_n=\\{(X_i, Y_i)\\}_{i\\leq n}\\sim \\mathbb{P}^n,$$\n", "\n", "qu'on supposera repr\u00e9sentatif du probl\u00e8me dans le sens o\u00f9 les couples $(X, Y)$ sont iid. \u00c0 partir de l\u00e0, nous pouvons estimer notre risque empirique:\n", "\n", "$$L_n(h)=\\frac{1}{n}\\sum_i 1\\{h(X_i)\\neq Y_i\\}.$$\n", "\n", "Il s'agit tout simplement de la moyenne des erreurs.\n", "\n", "Notre objectif, en tant que *machine learner* est de minimiser cette erreur. Bien s\u00fbr (#nofreelunchtheorem), nous ne pouvons pas consid\u00e9rer toutes les fonctions de $\\mathcal{X}$ dans $\\mathcal{Y}$. Soit $\\mathcal{H}$ la classe de fonctions que nous souhaitons consid\u00e9rer. Le probl\u00e8me \u00e0 r\u00e9soudre est:\n", "\n", "$$h_n=\\text{argmin}_{h\\in\\mathcal{H}}L_n(h).$$\n", "\n", "C'est ce qu'on appelle le minimiseur du risque empirique. Remarquez que ce n'est pas exactement ce qu'on minimise en pratique. Nous allons voir pourquoi."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## I. Une premi\u00e8re minimisation du risque empirique"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Construction du jeu de donn\u00e9es"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def h_star(x):\n", "    y = np.zeros(x.shape[0])\n", "    y[x[:,1]>x[:,0]] = 1\n", "    y[x[:,1]<=x[:,0]] = -1\n", "    return y\n", "\n", "def construct_dataset(n):\n", "    X = np.random.uniform(-1, 1, (n, 2))\n", "    return X, h_star(X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = construct_dataset(50)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Affichage du dataset "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "plt.figure(figsize=(10, 8))\n", "plt.scatter(X[:, 0], X[:, 1], c=y)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Notre classe de fonctions lin\u00e9aires $\\mathcal{H}$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consid\u00e9rons le cas tr\u00e8s simple des mod\u00e8les lin\u00e9aires. Ici, notre ensemble de fonctions $\\mathcal{H}$ est l'ensemble de cardinal infini dont les fronti\u00e8res de d\u00e9cision sont les droites dans le plan&nbsp;:\n", "\n", "$$\\mathcal{H}=\\{x\\mapsto\\text{sign}(\\langle \\omega, x\\rangle+b):\\ \\omega\\in\\mathbb{R}^2,\\ b\\in\\mathbb{R}\\},$$\n", "\n", "o\u00f9&nbsp;:\n", "\n", "$$\\text{sign}(x)=\\begin{cases}+1\\text{ si }x\\geq 0\\\\-1\\text{ sinon.}\\end{cases}$$\n", "\n", "o\u00f9, nous avons suppos\u00e9 que $\\mathcal{Y}=\\{-1, 1\\}$ afin de simplifier les notations. Notre probl\u00e8me de minimisation devient donc&nbsp;:\n", "\n", "$$(\\omega, b)=\\text{argmin}_{\\omega, b\\in \\mathbb{R}^2\\times\\mathbb{R}}\\frac{1}{n}\\sum_i \\mathbf{1}\\{\\text{sign}(\\langle \\omega, x_i\\rangle+b)\\neq y_i\\}.$$\n", "\n", "Notez que nous avons la formulation \u00e9quivalente suivante&nbsp;:\n", "\n", "$$(\\omega, b)=\\text{argmin}_{\\omega, b\\in \\mathbb{R}^2\\times\\mathbb{R}}\\frac{1}{n}\\sum_i \\mathbf{1}\\{ y_i(\\langle \\omega, x_i\\rangle+b)< 0\\}.$$\n", "\n", "Comment faire cela ? La fonction \u00e0 optimiser est constante par morceau et les optimiseurs \u00e0 base d'information du premier ordre (i.e. d\u00e9riv\u00e9e, gradient) ne peuvent pas nous aider. Une strat\u00e9gie est de constater que dans le plan, une droite n'a besoin que de deux points pour se positionner. \u00c0 partir de deux points $x_1$ et $x_2$, il est possible d'obtenir une valeur de $\\omega$ et de $b$ en r\u00e9solvant le syst\u00e8me d'\u00e9quations suivant&nbsp;:\n", "\n", "$$\\begin{cases}\\langle\\omega, x_1\\rangle + b=0\\\\\\langle\\omega, x_2\\rangle +b=0.\\end{cases}$$\n", "\n", "Il y a \u00e9videmment une infinit\u00e9 de solutions (deux \u00e9quations et trois inconnues). On peut r\u00e9soudre ce probl\u00e8me en contraignant la norme de $\\omega$ \u00e0 valoir $1$.\n", "\n", "Il suffit maintenant de tester toutes les valeurs possibles de $\\omega$ et de $b$ s'appuyant sur des points de notre jeu de donn\u00e9es et de prendre celle qui fait le moins d'erreurs&nbsp;!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Impl\u00e9mentez notre mod\u00e8le de classification $h$ (i.e. la fonction qui fait une pr\u00e9diction quant \u00e0 la classe).**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def h(x, omega, b):\n", "    ####### Complete this part ######## or die ####################\n", "    ...\n", "    ...\n", "    ...\n", "    ###############################################################\n", "    return predictions\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Impl\u00e9mentez une methode qui prend en param\u00e8tre deux points et retourne un vecteur $\\omega$ qui d\u00e9crit l'orientation de l'hyperplan et le biais $b$.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def parameterize(x_1, x_2):\n", "    ####### Complete this part ######## or die ####################\n", "    ...\n", "    ...\n", "    ...\n", "    ...\n", "    ###############################################################\n", "    return omega, b\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Impl\u00e9mentez une m\u00e9thode qui calcule le risque empirique.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def empirical_risk(X, y, omega, b):\n", "    ####### Complete this part ######## or die ####################\n", "    risk = ...\n", "    ###############################################################\n", "    return risk\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Impl\u00e9mentez une m\u00e9thode qui calcule le minimiseur du risque empirique.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def fit_empirical_risk(X, y):\n", "    ####### Complete this part ######## or die ####################\n", "    ...\n", "    ...\n", "    ...\n", "    ...\n", "    ...\n", "    ...\n", "    ...\n", "    ###############################################################\n", "    return best_omega, best_b, best_risk\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Testons le code pr\u00e9c\u00e9dent."]}, {"cell_type": "code", "metadata": {}, "source": ["omega, b, _ = fit_empirical_risk(X, y)\n", "print('Obtained empirical risk:', _)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Affichons maintenant le s\u00e9parateur ainsi calcul\u00e9."]}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(10, 8))\n", "plt.scatter(X[:, 0], X[:, 1], c=y)\n", "\n", "x_ = np.linspace(-1, 1, 101)\n", "y_ = (-b-omega[0]*x_)/omega[1]\n", "plt.plot(x_, y_)\n", "plt.xlim(-1, 1)\n", "plt.ylim(-1, 1)\n", "plt.title('Our data and our model')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Malheureusement, tester toutes les combinaisons a un co\u00fbt qui nous emp\u00eache de consid\u00e9rer des jeux de donn\u00e9es trop grands et en trop grande dimension. Il y a en effet dans $\\mathbb{R}^d$ $n!/(d!(n-d)!)$ combinaisons possibles \u00e0 tester. Dans le plan, cela nous donne :\n", "\n", "$$\\frac{n!}{2(n-2)!}=0.5n(n-1)\\approx 0.5 n^2$$"]}, {"cell_type": "code", "metadata": {}, "source": ["import time\n", "\n", "fit_duration = []\n", "dataset_sizes = list(range(10, 291, 20))\n", "for n in dataset_sizes:\n", "    X, y = construct_dataset(n)\n", "    start = time.time()\n", "    omega, b, _ = fit_empirical_risk(X, y)\n", "    fit_duration.append(time.time()-start)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(10, 8))\n", "plt.plot(dataset_sizes, fit_duration, label='Fit time')\n", "\n", "scale = fit_duration[-1]/(dataset_sizes[-1]**2)\n", "\n", "theoretical_fit_duration = np.power(np.array(dataset_sizes), 2)*scale\n", "\n", "plt.plot(dataset_sizes, theoretical_fit_duration, label='Estimated fit time')\n", "\n", "plt.title('Fit duration')\n", "plt.ylabel('Time (s)')\n", "plt.xlabel('Dataset size')\n", "plt.legend()\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["print('Avec un jeu de donn\u00e9es de taille 150000 dans le plan (petite dim),'\\\n", "      'le temps du fit estim\u00e9 est d\\'environ', int(np.round(scale * 150000**2/60/24)), 'jours')\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["On peut r\u00e9soudre ce probl\u00e8me avec notamment deux visions diff\u00e9rentes&nbsp;:\n", "    \n", "1. On estime la loi conditionnelle $\\hat{\\eta}\\approx\\eta$ et on utilise une *plug-in* rule (la m\u00eame r\u00e8gle que pour le classifieur de Bayes)&nbsp;:\n", "\n", "$$\\hat{g}(x)=\\begin{cases}1\\text{ si }\\hat{\\eta}(x)\\geq 0.5\\\\0\\text{ sinon.}\\end{cases}$$\n", "\n", "2. On optimise un autre \"risque\" qu'on appelle un $\\phi$-risk et qui nous garantit que le r\u00e9sultat ne sera pas trop mauvais par rapport au vrai risque.\n", "\n", "La s\u00e9quence de cours sur la r\u00e9gression logistique montre un r\u00e9sultat de convergence pour le premier cas. Cette s\u00e9quence aborde le deuxi\u00e8me point."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## II. Construction du $\\phi$-risk"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00c0 la place de chercher \u00e0 optimiser notre erreur 0/1, l'id\u00e9e va \u00eatre de trouver une fonction avec des propri\u00e9t\u00e9s math\u00e9matiques int\u00e9ressantes et pouvant nous offrir certaines garanties du point de vue de la classification. Consid\u00e9rons ici les labels $\\mathcal{Y}=\\{-1, 1\\}$ et supposons que notre classe de fonctions ait la forme suivante&nbsp;:\n", "\n", "$$\\mathcal{H}=\\{h:x\\mapsto \\text{sign}(g(x)),\\ g:\\mathcal{X}\\rightarrow\\mathbb{R}\\}$$\n", "\n", "Il s'agit de la composition entre une fonction de score $g$ et de la fonction&nbsp;:\n", "\n", "$$\\text{sign}(x)=\\begin{cases}+1\\text{ si }x\\geq 0\\\\-1\\text{ sinon.}\\end{cases}$$\n", "\n", "Un classifieur $h\\in\\mathcal{H}$ est donc une fonction de $\\mathcal{X}\\rightarrow \\{-1,+1\\}$. Un $\\phi$-risk est un risque \"facile\" \u00e0 minimiser et qui garantit d'\u00eatre un \"bon choix\" du point de vue de l'erreur 0/1.\n", "\n", "**<span style='color:blue'> D\u00e9finition ($\\phi$-risk)</span>** ", "\n", "Un $\\phi$-risk est d\u00e9fini comme&nbsp;:\n", "\n", "$$L^\\phi(g)=\\mathbb{E}\\big[\\phi(Yg(X))\\big],$$\n", "\n", "avec les propri\u00e9t\u00e9s suivantes&nbsp;:\n", "\n", "1. **Majoration du risque 0/1** : $\\phi(z)\\geq \\mathbf{1}\\{z<0\\}$,\n", "2. **Convexit\u00e9** : La fonction $\\phi:\\mathbb{R}\\rightarrow\\mathbb{R}^+$ est convexe,\n", "3. **Calibr\u00e9e pour la classification** : La fonction $\\phi$ est d\u00e9rivable en $0$ et $\\phi^\\prime(0)<0$.\n", "\n", "\n\n ----", "\n", "Nous allons bien entendu d\u00e9tailler l'int\u00e9r\u00eat de ces propri\u00e9t\u00e9s. Le risque empirique associ\u00e9 devient alors :\n", "\n", "$$L_n^\\phi(g)=\\frac{1}{n}\\sum_i \\phi(Y_ig(X_i)).$$\n", "\n", "Comme nous l'avons vu dans la d\u00e9finition, avec la fonction $\\phi$ suivante :\n", "\n", "$$\\phi(z)=\\mathbf{1}\\{z< 0\\},$$\n", "\n", "on retombe sur notre erreur $0/1$. En effet, on compte $1$ si le signe de $Yg(X)$ est n\u00e9gatif, \u00e0 savoir, si notre score ne correspond pas au label et $0$ sinon. D'autres choix de $\\phi$-risks sont les suivants (il y en a beaucoup d'autres) :\n", "\n", "*  **Hinge loss** : $\\phi(z)=\\text{max}(0, 1-z)$, ici  on p\u00e9nalise tous les $z$ tant qu'ils sont inf\u00e9rieur \u00e0 $1$. Cette loss est notamment utilis\u00e9e par le SVM qui cherche \u00e0 obtenir une marge,\n", "*  **Smoothed hinge loss** : $\\phi(z)=\\beta^{-1}\\text{log}\\big(1+e^{\\beta(1-z)}\\big)$, o\u00f9 $\\beta>0$ est un param\u00e8tre. On retrouve la hinge loss comme limite lorsque $\\beta\\rightarrow\\infty$,\n", "* **Logistic loss** : $\\phi(z)=\\text{log}(1+e^{-z})$, c'est la loss utilis\u00e9e lorsqu'on fait une r\u00e9gression logistique ou de la classification binaire en *deep learning*. En effet, on a :\n", "\n", "$$\\text{log}(1+e^{-yg(x)})=-\\text{log}\\Big(\\frac{1}{1+e^{-yg(x)}}\\Big)=-\\big(\\mathbf{1}\\{y=1\\}\\text{log}(\\sigma(g(x)))+\\mathbf{1}\\{y=-1\\}\\text{log}(1-\\sigma(g(x)))\\big),$$\n", "\n", "o\u00f9 $\\sigma(z)=(1+e^{-z})^{-1}$ est la fonction sigmo\u00efd. C'est la composition de notre fonction de score $g$ avec une sigmo\u00efd avec une log-entropie n\u00e9gative (i.e. on veut maximiser la vraisemblance du mod\u00e8le $\\sigma(g(x))$. Si $g$ est un mod\u00e8le lin\u00e9aire, alors on retombe sur la r\u00e9gression logistique.\n", "\n", "Visualisons ces quelques $\\phi$-risk."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def zero_one_loss(x):\n", "    return (x<0).astype(int)\n", "\n", "def hinge_loss(x):\n", "    v = 1-x\n", "    return v * (v>0).astype(int) + np.zeros(x.shape) * (v<=0).astype(int)\n", "\n", "def logistic_loss(x):\n", "    return np.log(1+np.exp(-x))\n", "\n", "def soft_hinge_loos(x, beta=3):\n", "    return logistic_loss(beta*(x-1))/beta"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "x = np.linspace(-2, 2, 201)\n", "plt.figure(figsize=(10, 8))\n", "\n", "plt.plot(x, zero_one_loss(x), label='0/1 loss')\n", "plt.plot(x, hinge_loss(x), label='Hinge loss')\n", "plt.plot(x, soft_hinge_loos(x), label='Soft Hinge loss')\n", "plt.plot(x, logistic_loss(x), label='Logistic loss')\n", "plt.ylim(0, 3)\n", "plt.legend()\n", "plt.title(r'$\\phi$-risks')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## III. Les propri\u00e9t\u00e9s d'un $\\phi$-risk"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### A. Majoration du risque 0/1\n", "\n", "La d\u00e9finition d'un $\\phi$-risk indiquait que ce dernier devait majorer l'erreur 0/1. En r\u00e9alit\u00e9 nous pouvons all\u00e9ger cette contrainte et dire qu'un $\\phi$-risk doit majorer le risque 0/1 a un facteur proportionnel pr\u00e8s. Ainsi le risque logistique ne majore pas l'erreur 0/1 car $\\log(1+e^0)<1$. Cependant, nous avons bien&nbsp;:\n", "\n", "$$\\frac{1}{\\log 2}\\phi(z)\\geq \\mathbf{1}\\{z<0\\}.$$\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "\n", "**Intuitivement, supposons que l'on minimise l'un des $\\phi$-risk sur notre probl\u00e8me de *machine learning* et qu'on obtienne $0$ erreur \u00e0 la fin. Que pouvons nous dire quant au risque $0/1$ ?**\n", "\n", "\n\n ----", "\n", "\n", "De mani\u00e8re plus g\u00e9n\u00e9rale, notre objectif reste de minimiser la quantit\u00e9 d'erreurs de classifications. Notons $g^\\star$ le classifieur de Bayes et $h_n$ le minimiseur du $\\phi$-risk empirique sur un jeu de donn\u00e9es de taille $n$. Nous pouvons majorer le risque 0/1 de la mani\u00e8re suivante&nbsp;:\n", "\n", "$$L^{\\text{0/1}}(h_n)\\leq \\underbrace{L^\\text{0/1}(g^\\star)}_{\\text{Bayes risk}}+(\\underbrace{\\inf_{h\\in\\mathcal{H}}L^\\text{0/1}(h)-L^\\text{0/1}(g^\\star)}_{\\text{Approximation error}})+(\\underbrace{L^\\phi(h_n)-\\inf_{h\\in\\mathcal{H}}L^\\phi(h)}_{\\text{Estimation error}})+(\\underbrace{\\inf_{h\\in\\mathcal{H}}L^\\phi(h)-\\inf_{h\\in\\mathcal{H}}L^\\text{0/1}(h)}_{\\text{Optimization error}})$$\n", "\n", "On supposera que $L^\\phi$ aura \u00e9t\u00e9 recalibr\u00e9e de mani\u00e8re \u00e0 bien majorer le risque $L^{0/1}$.\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "\n", "D\u00e9crivez chacune des erreurs.\n", "\n", "\n\n ----", "\n", "**<span style='color:blue'> Exercice</span>** ", "\n", "D\u00e9montrez l'in\u00e9galit\u00e9.\n", "\n", "\n\n ----", "\n", "\n", "\n", "### B. Convexit\u00e9\n", "\n", "La convexit\u00e9 garantit un certain nombre de propri\u00e9t\u00e9s dont la plus int\u00e9ressante, peut-\u00eatre, est que si nous trouvons un minimiseur local de notre loss, alors celui-ci est \u00e9galement un minimiseur global. C'est donc une propri\u00e9t\u00e9 id\u00e9ale pour la minimisation.\n", "\n", "### C. Calibr\u00e9 pour la classification\n", "\n", "La derni\u00e8re propri\u00e9t\u00e9 que nous avons \u00e9voqu\u00e9e est d'\u00eatre calibr\u00e9 pour la classification. Nous avons indiqu\u00e9 que cela \u00e9tait \u00e9quivalent \u00e0 avoir $\\phi$ d\u00e9rivable en $0$ et $\\phi^\\prime(0)<0$.\n", "\n", "Rappellons la notation $\\eta(x)=\\mathbb{P}(Y=1|X=x)$ indique la **vraie** probabilit\u00e9 conditionnelle d'obtenir le label $1$ sachant qu'on a observ\u00e9 la donn\u00e9e $x$. Nous avons donc la probabilit\u00e9 du label $-1$ avec $1-\\eta(x)$. La fonction $\\eta$ n'est bien s\u00fbr pas connue. Cependant, nous avons&nbsp;:\n", "\n", "$$\\mathbb{E}\\Big[\\phi(Yg(x))|X=x\\Big]=\\eta(x)\\phi(g(x))+(1-\\eta(x))\\phi(-g(x))=:C_\\eta(g(x)).$$\n", "\n", "C'est tout simplement l'esp\u00e9rance de notre $\\phi$-risk lorsqu'on a observ\u00e9 la donn\u00e9e $x$.\n", "\n", "Rappelons-nous que la fonction $g$ retourne un score positif si on pr\u00e9dit le label $y=1$ et un score n\u00e9gatif si on pr\u00e9dit le label $y=-1$. Ainsi, si $\\eta(x)>0.5$, alors, on veut pr\u00e9dire le label $1$ et on veut que $g(x)>0$. \u00c0 l'inverse, si $\\eta(x)<0.5$, alors on veut pr\u00e9dire le label $-1$ et on veut $g(x)<0$. Plus formellement, nous pouvons d\u00e9finir cela comme suit.\n", "\n", "**<span style='color:blue'> D\u00e9finition (*loss* calibr\u00e9e pour la classification)</span>** ", "\n", "Un $\\phi$-risk est calibr\u00e9 pour la classification si et seulement si&nbsp;:\n", "\n", "$$\\eta>0.5\\Leftrightarrow\\text{argmin}_{z}C_\\eta(z)\\subset\\mathbb{R}^{\\star+},$$\n", "\n", "$$\\eta<0.5\\Leftrightarrow\\text{argmin}_{z}C_\\eta(z)\\subset\\mathbb{R}^{\\star-}.$$\n", "\n", "\n\n ----", "\n", "Les minimiseurs de notre *loss* (du point de vu du score), doivent avoir le m\u00eame signe que $\\eta-0.5$. Cela a bien entendu un effet sur la forme que peut prendre $\\phi$ et en particulier celui que nous illustrons par la proposition suivante.\n", "\n", "**<span style='color:blue'> Proposition</span>** ", "\n", "$\\phi$ est d\u00e9rivable en $0$ et $\\phi^\\prime(0)<0$ si et seulement si $\\phi$ est calibr\u00e9e pour la classification.\n", "\n", "\n\n ----", "\n", "**<span style='color:orange'> Preuve</span>** ", "\n", "Notons $\\phi_+$, $\\phi_-$, $(C_\\eta)_+$ et $(C_\\eta)_-$ les d\u00e9riv\u00e9es \u00e0 gauche et \u00e0 droite. Nous avons alors, pour que les in\u00e9galit\u00e9s soient satisfaites, $(C_\\eta)_+^\\prime(0)<0\\Leftrightarrow \\eta>0.5$ et $(C_\\eta)_-^\\prime(0)>0\\Leftrightarrow \\eta<0.5$ puisque $C_\\eta$ est convexe en tant que combinaison convexe de fonctions convexes. Pour se convaincre des \u00e9quivalences pr\u00e9c\u00e9dentes, supposons $\\eta>0.5$, alors le minimum de $C_\\eta(z)$ doit \u00eatre atteint avec $z>0$. Si $(C_\\eta)_+^\\prime(0)<0$, alors le minimum est \"\u00e0 droite\" de 0 et r\u00e9pond au besoin. \n", "\n", "$(\\Leftarrow)$ Supposons que les deux in\u00e9galit\u00e9s soient satisfaites.\n", "\n", "Nous voulons montrer (1) que $\\phi$ est d\u00e9rivable en $0$ et (2) que $\\phi^\\prime(0)<0$.\n", "\n", "On a (attention \u00e0 la d\u00e9riv\u00e9e) :\n", "\n", "$$\\lim_{\\eta\\rightarrow 0.5^+}(C_\\eta)_+^\\prime(0)=\\lim_{\\eta\\rightarrow 0.5^+}\\eta\\phi_+^\\prime(0)-(1-\\eta)\\phi_-^\\prime(0)=0.5\\big(\\phi_+^\\prime(0)-\\phi_-^\\prime(0)\\big)\\leq 0.$$\n", "\n", "La derni\u00e8re in\u00e9galit\u00e9 est v\u00e9rifi\u00e9e par hypoth\u00e8se sur $C_\\eta$. Cela nous donne donc $\\phi_-^\\prime(0)\\geq\\phi_+^\\prime(0)$. Par hypoth\u00e8se, $\\phi$ est convexe et on a toujours $\\phi_-^\\prime(0)\\leq\\phi_+^\\prime(0)$. On a donc $\\phi_+^\\prime(0)=\\phi_-^\\prime(0)$ et $\\phi$ est d\u00e9rivable en $0$. C'est le premier point. \n", "\n", "Nous avons ensuite :\n", "\n", "$$C_\\eta^\\prime(0)=\\eta\\phi^\\prime(0)-(1-\\eta)\\phi^\\prime(0)=(2\\eta-1)\\phi^\\prime(0).$$\n", "\n", "Si $\\eta>0.5$, alors $2\\eta-1>0$ et $C_\\eta^\\prime(0)<0$. On a alors $\\phi^\\prime(0)<0$. On obtient le m\u00eame r\u00e9sultat si $\\eta<0.5$ !\n", "\n", "$(\\Rightarrow)$ Supposons que $\\phi$ est d\u00e9rivable en $0$ et que $\\phi^\\prime(0)<0$. On obtient alors :\n", "\n", "$$C_\\eta^\\prime(0)=(2\\eta-1)\\phi^\\prime(0)$$\n", "\n", "dont le signe est n\u00e9gatif si $\\eta>0.5$ et positif si $\\eta<0.5$. **$\\boxed{}$**\n", "\n", "\n\n ----", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### D. Construction\n", "\n", "Maintenant que nous avons vu et d\u00e9crit les propri\u00e9t\u00e9s d'un $\\phi$-risk calibr\u00e9 pour la classification, nous pouvons laisser notre imagination \u00e0 en cr\u00e9er de nouveaux.\n", "\n", "**<span style='color:blue'> Exercice (cr\u00e9er une *loss*)</span>** ", "\n", "Nous avons vu les propri\u00e9t\u00e9s qu'un $\\phi$-risk devait respecter pour \u00eatre \"classification calibrated\". Inventez une nouvelle fonction de perte (i.e. *loss*).\n", "\n", "\n\n ----", "\n", "**<span style='color:green'> Indice</span>** ", "\n", "Utilisez des fonctions simples, connues, convexes, etc..\n", "\n", "\n\n ----", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## IV. *Logistic loss* et r\u00e9gression logistique"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La *logistic loss* est $\\phi(z)=\\text{log}(1+e^{-z})$. Consid\u00e9rons un jeu de donn\u00e9es $S_n$, notre objectif pratique est de minimiser le $\\phi$-risk empirique :\n", "\n", "$$L_n^\\phi(g)=\\frac{1}{n}\\sum_i\\phi(y_ig(x_i))=\\frac{1}{n}\\sum_i\\text{log}(1+e^{-y_ig(x_i)})$$\n", "\n", "Reprenons le cas d'un mod\u00e8le lin\u00e9aire. Cela nous permettra de comparer les co\u00fbts calculatoires avec le vrai risque empirique. Nous avons donc&nbsp;:\n", "\n", "$$\\mathcal{H}=\\{x\\mapsto \\text{sign}(g(x)):\\ g(x)=\\langle \\omega, x\\rangle +b,\\ \\omega\\in\\mathbb{R}^d,\\ b\\in\\mathbb{R}\\}$$\n", "\n", "L'optimisation du $\\phi$-risk se fera bien s\u00fbr \u00e0 partir de la fonction $g(x)$ et non de $\\text{sign}(g(x))$.\n", "\n", "Avant de pouvoir optimiser, il faut calculer le gradient de notre $\\phi$-risk empirique. La premi\u00e8re \u00e9tape est de calculer la d\u00e9riv\u00e9e de la fonction $\\phi(yz)$ par rapport \u00e0 $z$&nbsp;:\n", "\n", "$$\\phi^\\prime(yz)=-\\frac{ye^{-yz}}{1+e^{-yz}}=-\\frac{y}{1+e^{yz}}.$$\n", "\n", "Observons notamment qu'on a&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "\\phi^\\prime((+1)z)&=\\frac{1}{1+e^{-z}}-1=\\sigma(z)-y^{0/1}\\\\\n", "\\phi^\\prime((-1)z)&=\\frac{1}{1+e^{-z}}-0=\\sigma(z)-y^{0/1}\n", "\\end{aligned}$$\n", "\n", "o\u00f9 $y^{0/1}$ repr\u00e9sente le label $0$ ou $1$ plut\u00f4t que $-1$ et $+1$ et $\\sigma(\\cdot)$ est la fonction sigmo\u00efd. Par simplicit\u00e9 de notation consid\u00e9rons les vecteur $x_i=[1, x_1, \\ldots, x_d]^T$ afin d'\u00e9viter la notation avec le biais $b$.\n", "\n", "Du c\u00f4t\u00e9 du mod\u00e8le lin\u00e9aire, nous retrouvons naturellement&nbsp;:\n", "\n", "$$\\nabla_\\omega g(x)=x.$$\n", "\n", "Ainsi, en combinant le tout, nous obtenons&nbsp;:\n", "\n", "$$\\nabla_\\omega \\phi(y_ig(x_i))=x_i\\left(\\frac{1}{1+e^{-\\langle \\omega, x_i\\rangle}}-y_i^{0/1}\\right),$$\n", "\n", "On retrouve le gradient que nous avons calcul\u00e9 lors de la pr\u00e9c\u00e9dente s\u00e9quence (i.e. sur la r\u00e9gression logistique) o\u00f9 on avait&nbsp;: \n", "\n", "$$\\nabla_\\omega L_n(\\omega)=\\frac{1}{n}X^T(\\sigma(X\\boldsymbol{\\omega})-\\boldsymbol{y}^{0/1})$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CrossEntropy(object):\n", "    def __init__(self, X, y):\n", "        self.X = np.insert(CrossEntropy._format_ndarray(X), 0, 1, axis=1)\n", "        self.y = (y>0).astype(int)\n", "        self.idx = np.array([i for i in range(self.X.shape[0])])\n", "        self._pos = 0\n", "        \n", "    def _format_ndarray(arr):\n", "        arr = np.array(arr) if type(arr) is not np.ndarray else arr\n", "        return arr.reshape((arr.shape[0], 1)) if len(arr.shape) == 1 else arr\n", "    \n", "    def predict(self, X):\n", "        y_pred = (1+np.exp(-np.dot(X, self.beta)))**(-1)\n", "\n", "        return y_pred\n", "    \n", "    def _sigmoid(X, beta):\n", "        z = np.dot(X, beta)\n", "        z_max = z.max()\n", "        # numerical stability trick\n", "        return np.exp(z-z_max)/(np.exp(z-z_max)+np.exp(-z_max))\n", "    \n", "    def val(self, beta):\n", "        beta = CrossEntropy._format_ndarray(beta)\n", "        p = CrossEntropy._sigmoid(self.X, beta)\n", "        log_p = -np.concatenate([np.log(1-p), np.log(p)], axis=1)[np.arange(len(self.X)), self.y]\n", "        return log_p.sum()/len(self.X)\n", "    \n", "    def grad(self, beta):\n", "        y = CrossEntropy._format_ndarray(self.y)\n", "        beta = CrossEntropy._format_ndarray(beta)\n", "        grad = np.dot(self.X.T, CrossEntropy._sigmoid(self.X, beta)   - y)\n", "        return grad/len(X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GradientDescent(object):\n", "    init = np.random.uniform(-4, 4, size=3).reshape((3, 1))\n", "    def __init__(self, X, y, loss=CrossEntropy):\n", "        self.loss = loss(X, y)\n", "        \n", "    def optimize(self, learning_rate = 1., nb_iterations=10, beta=init):\n", "        param_trace = [beta.T[0]]\n", "        loss_trace = [self.loss.val(beta)]\n", "        for i in range(nb_iterations):\n", "            beta = beta - learning_rate * self.loss.grad(beta)\n", "            param_trace.append(beta.T[0])\n", "            loss_trace.append(self.loss.val(beta))\n", "            \n", "        return param_trace, loss_trace\n", "\n", "X, y = construct_dataset(200)\n", "gd = GradientDescent(X, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params, _ = gd.optimize(nb_iterations=1000)\n", "plt.figure(figsize=(10, 8))\n", "plt.plot(_)\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 8))\n", "plt.scatter(X[:, 0], X[:, 1], c=y)\n", "omega = params[-1][1:3]\n", "b = params[-1][0]\n", "x_ = np.linspace(-1, 1, 101)\n", "y_ = (-b-omega[0]*x_)/omega[1]\n", "plt.plot(x_, y_)\n", "plt.xlim(-1, 1)\n", "plt.ylim(-1, 1)\n", "plt.title('Our data and our model')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00c9tudions l'\u00e9volution du temps de calcul et comparons le au minimiseur du risque empirique."]}, {"cell_type": "code", "metadata": {}, "source": ["import time\n", "\n", "fit_duration_erm = []\n", "fit_duration_phi_risk = []\n", "dataset_sizes = list(range(10, 291, 20))\n", "for n in dataset_sizes:\n", "    X, y = construct_dataset(n)\n", "    start = time.time()\n", "    omega, b, _ = fit_empirical_risk(X, y)\n", "    fit_duration_erm.append(time.time()-start)\n", "    \n", "    gd = GradientDescent(X, y)\n", "    start = time.time()\n", "    params, _ = gd.optimize(nb_iterations=1000)\n", "    fit_duration_phi_risk.append(time.time()-start)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(10, 8))\n", "plt.plot(dataset_sizes, fit_duration_erm, label='ERM fit time')\n", "\n", "scale = fit_duration_erm[-1]/(dataset_sizes[-1]**2)\n", "\n", "theoretical_fit_duration = np.power(np.array(dataset_sizes), 2)*scale\n", "\n", "plt.plot(dataset_sizes, theoretical_fit_duration, label='Estimated ERM fit time')\n", "\n", "plt.plot(dataset_sizes, fit_duration_phi_risk, label='$\\phi$-risk fit time')\n", "\n", "plt.title('Fit duration')\n", "plt.ylabel('Time (s)')\n", "plt.xlabel('Dataset size')\n", "plt.legend()\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Question</span>** ", "\n", "**Qu'en conclure ? Dans quel cas le minimiseur du risque empirique a-t-il toujours du sens ?**\n", "\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## V. Optimiser votre *loss*\n", "\n", "**<span style='color:blue'> Exercice (Optimisez votre *loss*)</span>** ", "\n", "Dans un exercice pr\u00e9c\u00e9dent vous avez cr\u00e9\u00e9 votre propre *loss*. Utilisez votre *loss* sur le jeu de donn\u00e9es pr\u00e9c\u00e9dent avec un mod\u00e8le lin\u00e9aire&nbsp;:\n", "\n", "$$\\mathcal{H}=\\{x\\rightarrow\\text{sign}(g(x)):\\ g(x)=\\langle\\omega, x\\rangle +b,\\ \\omega\\in\\mathbb{R}^d,b\\in\\mathbb{R}\\}.$$\n", "\n", "o\u00f9&nbsp;:\n", "\n", "$$\\text{sign}(x)=\\begin{cases}+1\\text{ si }x\\geq 0\\\\-1\\text{ sinon.}\\end{cases}$$\n", "\n", "\n\n ----", "\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# pensez a ajouter une colonne de 1 si vous voulez un biais\n", "X_prime =  np.insert(X, 0, 1, axis=1)\n", "...\n", "beta = ...\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(10, 8))\n", "plt.scatter(X[:, 0], X[:, 1], c=y)\n", "omega = beta[1:3]\n", "b = beta[0]\n", "x_ = np.linspace(-1, 1, 101)\n", "y_ = (-b-omega[0]*x_)/omega[1]\n", "plt.plot(x_, y_)\n", "plt.xlim(-1, 1)\n", "plt.ylim(-1, 1)\n", "plt.title('Our data and our model')\n", "plt.show()\n"], "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 4}