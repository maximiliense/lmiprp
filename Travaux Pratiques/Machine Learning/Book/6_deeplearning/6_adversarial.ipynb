{"cells": [{"cell_type": "markdown", "id": "worse-failing", "metadata": {}, "source": ["# Les attaques adversaires \u2615\ufe0f\n", "\n", "**<span style='color:blue'> Objectifs de la s\u00e9quence</span>** ", "\n", "* \u00catre sensibilis\u00e9&nbsp;:\n", "    * aux attaques adversaires,\n", "    * \u00e0 leur lien au sur-apprentissage et \u00e0 la r\u00e9gularisation.\n", "* \u00catre capable&nbsp;:\n", "    * d'impl\u00e9menter une attaque adversaire avec $\\texttt{pytorch}$,\n", "    * de produire un apprentissage robuste aux attaques adversaires.\n", "\n", "\n\n ----"]}, {"cell_type": "markdown", "id": "selected-cleveland", "metadata": {}, "source": ["## I. Introduction, qu'est-ce qu'une attaque adversaire ?"]}, {"cell_type": "markdown", "id": "grave-nickname", "metadata": {}, "source": ["Reprenons le probl\u00e8me introduit pr\u00e9c\u00e9demment. Soit $\\mathcal{X}\\subseteq\\mathbb{R}^d$ notre espace d'entr\u00e9e et $\\mathcal{Y}=\\{1, \\ldots, C\\}$ notre espace de sortie o\u00f9 $C\\in\\mathbb{N}$ est le nombre de classes de notre probl\u00e8me de classification. Consid\u00e9rons une famille param\u00e9trique de fonctions :\n", "\n", "$$\\mathcal{H}=\\{h_\\theta:\\ \\theta\\in\\mathbb{R}^p\\},$$\n", "\n", "o\u00f9 $p\\in\\mathbb{N}$ est le nombre de param\u00e8tres. Notons $S_n$ notre jeu de donn\u00e9es d'apprentissage compos\u00e9 de $n$ exemples, $T_m$ notre jeu de test et $\\ell$ la <em>loss</em> pour une unique pr\u00e9diction. Notons aussi $\\text{Acc}(h_\\theta, S)$ le pourcentage de bonnes pr\u00e9dictions (i.e. <em>accuracy</em>) faites par $h_\\theta$ sur l'ensemble de donn\u00e9es $S$. L'objectif classique en *machine learning* est de trouver la param\u00e9trisation qui nous permet de minimiser notre <em>loss</em> sur le jeu de donn\u00e9es d'apprentissage&nbsp;:\n", "\n", "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\ell(h_\\theta(x_i), y_i)=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\mathcal{L}(h_\\theta, S_n).$$\n", "\n", "Cette minimisation n'est cependant pas un crit\u00e8re ultime et on souhaite que la fonction ainsi obtenue se comporte bien sur de nouvelles donn\u00e9es jamais observ\u00e9es. Une mani\u00e8re d'estimer ces performances consiste \u00e0 tester notre fonction sur un jeu de test : \n", "\n", "$$\\text{Acc}(h_{\\theta^\\star}, T_m).$$ \n", "\n", "Et malheureusement, la param\u00e9trisation qui minimise notre <em>loss</em> n'est pas toujours performante sur de nouvelles donn\u00e9es, comme nous avons pu le voir. Pour cela, diverses techniques allant de la r\u00e9duction du nombre de param\u00e8tres aux techniques de r\u00e9gularitation $\\ell_1$ ou $\\ell_2$ en passant par le <em>dropout</em>, etc. sont possibles.\n", "\n", "Cependant, imaginons que notre jeu de test $T_m$ au lieu d'\u00eatre un tirage al\u00e9atoire repr\u00e9sentatif de la distribution de nos donn\u00e9es soit choisi par un adversaire dont l'objectif est de mettre en \u00e9chec notre mod\u00e8le d'une mani\u00e8re telle qu'un \u00eatre humain n'y verrait aucune diff\u00e9rence. Est-il possible de faire croire \u00e0 un mod\u00e8le que la photo d'un STOP est en r\u00e9alit\u00e9 une limitation de vitesse \u00e0 130km/h sans qu'un \u00eatre humain ne voit la diff\u00e9rence. C'est l\u00e0 l'objectif des attaques adversaires.\n", "\n", "<img SRC=\"https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemons_result.jpeg\" style='width:700px' align=\"center\" >\n", "\n", "Nous commencerons l'\u00e9tude de ces questions en utilisant un mod\u00e8le de l'\u00e9tat de l'art d\u00e9j\u00e0 pr\u00e9-entra\u00een\u00e9 sur la base de donn\u00e9es ImagetNet. L'objectif sera dans un premier temps de construire ces attaques adversaires puis, dans un second temps, de construire une proc\u00e9dure d'apprentissage robuste aux attaques adversaires."]}, {"cell_type": "markdown", "id": "understanding-shuttle", "metadata": {}, "source": ["## II. Imports et construction du mod\u00e8le"]}, {"cell_type": "code", "execution_count": null, "id": "absolute-affairs", "metadata": {}, "outputs": [], "source": ["from torchvision import models, transforms, datasets\n", "from torch.nn.functional import softmax\n", "from torch.nn import CrossEntropyLoss, Linear, BatchNorm1d, ReLU, Sequential, Module\n", "from torch.utils.data import Dataset as TorchDataset, DataLoader\n", "from torch import optim, zeros_like, LongTensor\n", "import torch\n", "from PIL import Image\n", "import matplotlib.pyplot as plt\n", "\n", "plt.style.use('ggplot')\n", "\n", "import matplotlib.patches as patches\n", "import ast, json\n", "import numpy as np"]}, {"cell_type": "markdown", "id": "frozen-identity", "metadata": {}, "source": ["Le mod\u00e8le utilis\u00e9 est $\\texttt{resnet50}$."]}, {"cell_type": "code", "execution_count": null, "id": "abstract-johnson", "metadata": {}, "outputs": [], "source": ["resnet = models.resnet50(pretrained=True)"]}, {"cell_type": "code", "execution_count": null, "id": "sporting-parish", "metadata": {}, "outputs": [], "source": ["resnet.eval()\n", "\n", "# https://pytorch.org/vision/stable/models.html\n", "\n", "normalize = transforms.Normalize(\n", "    mean=[0.485, 0.456, 0.406],\n", "    std=[0.229, 0.224, 0.225]\n", ")\n", "\n", "preprocessing_no_normalize = transforms.Compose([\n", "    transforms.Resize(256),\n", "    transforms.CenterCrop(224),\n", "    transforms.ToTensor()\n", "])"]}, {"cell_type": "markdown", "id": "answering-australian", "metadata": {}, "source": ["Notre r\u00e9seau de neurones fait ses pr\u00e9dictions au travers d'un vecteur de dimension 1000 o\u00f9 chaque dimension est la probabilit\u00e9 (ou un score) associ\u00e9e \u00e0 la classe de m\u00eame indice. Afin de pouvoir associer un nom \u00e0 chacune de ces classes, nous construisons le dictionnaire ci-dessous $\\texttt{classes}\\_\\texttt{to}\\_\\texttt{labels}$.\n", "\n", "Le fichier est t\u00e9l\u00e9chargeable \u00e0 l'adresse suivante : \n", "[imagenet.json](https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/imagenet.json)."]}, {"cell_type": "code", "execution_count": null, "id": "7e9c3879", "metadata": {}, "outputs": [], "source": ["# python 3\n", "import urllib.request\n", "\n", "urllib.request.urlretrieve(\n", "    \"https://raw.githubusercontent.com/maximiliense/lmiprp/main/\"\\\n", "    \"Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/imagenet.json\", \n", "    \"imagenet.json\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "blind-veteran", "metadata": {}, "outputs": [], "source": ["with open('imagenet.json', 'r') as f:\n", "    classes_to_labels = {int(k):v for k, v in json.load(f).items()}"]}, {"cell_type": "markdown", "id": "impossible-headquarters", "metadata": {}, "source": ["## III. La donn\u00e9e \u00e0 attaquer"]}, {"cell_type": "markdown", "id": "c4e5d01e", "metadata": {}, "source": ["L'image est t\u00e9l\u00e9chargeable \u00e0 l'adresse suivante : \n", "[lemon.jpeg](https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemon.jpeg)."]}, {"cell_type": "code", "execution_count": null, "id": "a2d4e45d", "metadata": {}, "outputs": [], "source": ["# python 3\n", "\n", "import urllib.request\n", "urllib.request.urlretrieve(\n", "    \"https://raw.githubusercontent.com/maximiliense/lmiprp/main/\"\\\n", "    \"Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemon.jpeg\", \n", "    \"lemon.jpeg\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "deadly-julian", "metadata": {}, "outputs": [], "source": ["image = Image.open('lemon.jpeg')\n", "tensor = preprocessing_no_normalize(image)\n", "\n", "plt.figure(figsize=(8, 8))\n", "plt.imshow(tensor.numpy().transpose(1, 2, 0))\n", "plt.axis('off')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "sublime-helen", "metadata": {}, "source": ["$\\texttt{Pytorch}$ prend en entr\u00e9e des donn\u00e9es dont la premi\u00e8re dimension repr\u00e9sente celle du batch. S'il n'y a qu'une donn\u00e9e alors cette premi\u00e8re dimension doit toujours exister et vaut $1$."]}, {"cell_type": "code", "execution_count": null, "id": "continuous-finger", "metadata": {}, "outputs": [], "source": ["batch = normalize(tensor)[None, :, :, :] # we create a batch\n", "\n", "print('[batch size, channels, width, height]:', batch.size())"]}, {"cell_type": "code", "execution_count": null, "id": "colored-click", "metadata": {}, "outputs": [], "source": ["prediction = resnet(batch)"]}, {"cell_type": "code", "execution_count": null, "id": "clean-broadway", "metadata": {}, "outputs": [], "source": ["# dim=1 indique qu'on pr\u00e9dit image par image \n", "# rappelez-vous que dim=0 correspond \u00e0 la dimension du batch\n", "true_index = prediction.max(dim=1)[1].item()\n", "probability = softmax(prediction, dim=1).max(dim=1)[0][0].item()\n", "true_label = classes_to_labels[true_index]"]}, {"cell_type": "code", "execution_count": null, "id": "special-membership", "metadata": {}, "outputs": [], "source": ["print(true_label, ':', probability)"]}, {"cell_type": "markdown", "id": "combined-auditor", "metadata": {}, "source": ["On observe que notre mod\u00e8le pr\u00e9dit le bon label avec une tr\u00e8s bonne probabilit\u00e9 !"]}, {"cell_type": "markdown", "id": "several-sugar", "metadata": {}, "source": ["## IV. Une premi\u00e8re attaque"]}, {"cell_type": "markdown", "id": "quiet-mississippi", "metadata": {}, "source": ["### Quelques rappels d'optimisation"]}, {"cell_type": "markdown", "id": "retained-casino", "metadata": {}, "source": ["Revenons \u00e0 l'apprentissage de notre r\u00e9seau de neurones. Notre objectif est de trouver une solution \u00e0 la minimisation suivante : \n", "\n", "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\ell(h_\\theta(x_i), y_i)=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\mathcal{L}(h_\\theta, S_n).$$\n", "\n", "Pour cela, nous exploitons le fait que $\\mathcal{L}(h_\\theta, S_n)$ est diff\u00e9rentiable presque partout en tant que fonction de $\\theta$ et cela afin d'utiliser l'algorithme de descente de gradient. Ce dernier r\u00e9alise des pas successifs afin de se rapprocher toujours plus du minimum de notre fonction (ou du moins d'un minimum local). Chacun des pas se construit de la mani\u00e8re suivante :\n", "\n", "$$\\theta^{(t+1)}=\\theta^{(t)}-\\eta \\nabla_\\theta\\mathcal{L}(h_{\\theta^{(t)}}, S_n)$$\n", "\n", "La valeur du gradient $\\nabla_\\theta\\mathcal{L}(h_{\\theta^{(t)}}, S_n)$ est elle obtenue au travers de l'algorithme de <em>backpropagration</em>. Le param\u00e8tre $\\eta>0$ est ce qu'on appelle le pas d'apprentissage ou <em>learning rate</em> et permet de controler la stabilit\u00e9 de l'optimisation mais a aussi un effet de r\u00e9gularisation."]}, {"cell_type": "markdown", "id": "rotary-atmosphere", "metadata": {}, "source": ["### Construction d'une attaque adversaire"]}, {"cell_type": "markdown", "id": "second-missile", "metadata": {}, "source": ["L'id\u00e9e d'une attaque adversaire est de s'appuyer sur le m\u00eame raisonnement mais dans l'espace des donn\u00e9es $\\mathbb{R}^d$. Soit une donn\u00e9e et son label $(x, y)$. Notre objectif est ainsi de trouver une perturbation $\\delta\\in\\mathbb{R}^d$ telle que la nouvelle donn\u00e9e $x+\\delta$ ne soit plus associ\u00e9e au label $y$. Rappelons que notre loss $\\ell$ est une mesure des performances de notre r\u00e9seau de neurones pour la donn\u00e9e $(x, y)$. Ainsi, $\\ell(h_\\theta(x), y)$ est d'autant plus faible que notre mod\u00e8le est bon et d'autant plus forte que notre mod\u00e8le est mauvais. Nous allons omettre l'indice $\\theta$ de notre mod\u00e8le puisqu'on le consid\u00e8re maintenant comme une constante.\n", "\n", "L'objectif d'une attaque adversaire est donc de trouver un bruit $\\delta\\in\\mathbb{R}^d$ de telle mani\u00e8re \u00e0 ce que $\\ell(h_\\theta(x+\\delta), y)$ ait la plus grande valeur possible. Ainsi, on peut reformuler l'attaque adversaire via le probl\u00e8me de minimisation suivant :\n", "\n", "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathbb{R}^d}-\\ell(h_{\\theta}(x+\\delta), y).$$\n", "\n", "Observez qu'on minimise bien l'oppos\u00e9 de notre <em>loss</em> puisqu'on est en r\u00e9alit\u00e9 int\u00e9ress\u00e9 par une maximisation."]}, {"cell_type": "markdown", "id": "greek-flight", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "Compl\u00e9tez l'algorithme suivant permettant de construire notre attaque adversaire.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "execution_count": null, "id": "4c1f42c4", "metadata": {}, "outputs": [], "source": ["# we initialize delta with 0\n", "delta = zeros_like(tensor, requires_grad=True)"]}, {"cell_type": "code", "id": "c1fc2ea3", "metadata": {}, "source": ["\n", "# we construct our optimizer and loss\n", "optimizer = optim.SGD([delta], lr=2e-1)\n", "criterion = CrossEntropyLoss()\n", "\n", "# we construct the target\n", "target = LongTensor([true_index])\n", "\n", "for iteration in range(60):\n", "    ############### COMPLETE HERE ###############\n", "    ...\n", "    ...\n", "    ...\n", "\n", "    if iteration % 5 == 0:\n", "        print('\\r[%d] loss: %.3f' % (iteration, loss.item()), end=\"\")\n", "    \n", "    ...\n", "    #############################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "b6d93544", "metadata": {}, "source": ["batch = normalize(tensor + delta)[None, :, :, :]\n", "logit = resnet(batch)\n", "\n", "print('\\rTrue class probability:', softmax(logit, dim=1)[0, true_index].item())\n", "\n", "new_index = logit.max(dim=1)[1].item()\n", "new_label = classes_to_labels[new_index]\n", "\n", "print('New class:', new_label)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "equivalent-marker", "metadata": {}, "source": ["Excellent, nous avons r\u00e9ussi \u00e0 transformer notre image $x$ via un bruit $\\delta$ de mani\u00e8re \u00e0 pi\u00e9ger notre mod\u00e8le ! On observe de plus que la probabilit\u00e9 de la bonne classe est maintenant ridiculement faible et se retrouve tr\u00e8s probablement parmi les classes les moins probables. Observons le r\u00e9sultat de notre attaque adversaire."]}, {"cell_type": "code", "id": "56314916", "metadata": {}, "source": ["plt.figure(figsize=(18,18))\n", "plt.subplot(131)\n", "plt.title('Notre image transform\u00e9e $x+\\delta$')\n", "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(132)\n", "plt.title('Le bruit $\\delta$')\n", "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(133)\n", "plt.title('Le bruit $\\delta$ amplifi\u00e9')\n", "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "textile-portal", "metadata": {}, "source": ["Oups ! Notre image ne ressemble plus \u00e0 rien. Le bruit ajout\u00e9 est clairement visible. On pourrait m\u00eame, si nous ne savions pas qu'il s'agit de citrons, douter et penser qu'il s'agit r\u00e9ellement d'oranges..."]}, {"cell_type": "markdown", "id": "seeing-special", "metadata": {}, "source": ["## V. Un deuxi\u00e8me essai"]}, {"cell_type": "markdown", "id": "southeast-pastor", "metadata": {}, "source": ["La strat\u00e9gie va \u00eatre de contraindre les d\u00e9formations \u00e0 rester \u00e0 l'int\u00e9rieur d'une boule dont nous pourrons contr\u00f4ler le rayon et le fixer \u00e0 de petites valeurs :\n", "\n", "$$\\mathcal{B}_\\epsilon=\\{x\\in\\mathbb{R}^d:\\ \\lVert x\\rVert\\leq \\epsilon\\}$$\n", "\n", "Consid\u00e9rons le cas simple de la norme $\\ell_\\infty$ :\n", "\n", "$$\\lVert x\\rVert_\\infty=\\text{max}_i|x_i|.$$\n", "\n", "Contraindre un vecteur \u00e0 rester au sein d'une boule de rayon $\\epsilon$ revient pour la norme $\\ell_\\infty$ \u00e0 tronquer chaque coordonn\u00e9e de mani\u00e8re \u00e0 ce que sa valeur absolue ne d\u00e9passe pas $\\epsilon$.\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "\n", "Compl\u00e9tez l'algorithme suivant permettant de construire notre attaque adversaire en contraignant le vecteur $\\delta$ \u00e0 rester dans une boule de rayon $\\epsilon$. Utilisez la m\u00e9thode $\\texttt{delta.data.clamp}\\_\\texttt{(min, max)}$ qui permet de tronquer la valeur.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "execution_count": null, "id": "288a7abd", "metadata": {}, "outputs": [], "source": ["# we initialize delta with 0\n", "delta = zeros_like(tensor, requires_grad=True)"]}, {"cell_type": "code", "id": "1c7cf4bd", "metadata": {}, "source": ["epsilon = 2./255\n", "\n", "# we construct our optimizer and loss\n", "optimizer = optim.SGD([delta], lr=2e-1)\n", "criterion = CrossEntropyLoss()\n", "\n", "# we construct the target\n", "target = LongTensor([true_index])\n", "\n", "for iteration in range(60):\n", "    ############### COMPLETE HERE ###############\n", "    # we construct the batch\n", "    ...\n", "    ...\n", "\n", "    if iteration % 5 == 0:\n", "        print('\\r[%d] loss: %.3f' % (iteration, loss.item()), end=\"\")\n", "    \n", "    ...\n", "    ...\n", "    #############################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "7d145e60", "metadata": {}, "source": ["batch = normalize(tensor + delta)[None, :, :, :]\n", "logit = resnet(batch)\n", "\n", "print('\\rTrue class probability:', softmax(logit, dim=1)[0, true_index].item())\n", "\n", "new_index = logit.max(dim=1)[1].item()\n", "new_label = classes_to_labels[new_index]\n", "\n", "print('New class:', new_label)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "theoretical-circumstances", "metadata": {}, "source": ["Affichons maintenant l'image ainsi obtenue et le bruit qui lui est associ\u00e9 :"]}, {"cell_type": "code", "id": "a5f7de25", "metadata": {}, "source": ["plt.figure(figsize=(18,18))\n", "plt.subplot(131)\n", "plt.title('Notre image transform\u00e9e $x+\\delta$')\n", "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(132)\n", "plt.title('Le bruit $\\delta$')\n", "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(133)\n", "plt.title('Le bruit $\\delta$ amplifi\u00e9')\n", "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "invisible-leeds", "metadata": {}, "source": ["C'est beaucoup mieux ! Cependant, ce n'est pas en transformant des citrons en oranges que nous arriverons \u00e0 prendre le contr\u00f4le de l'univers ! Ce que nous souhaiterions, c'est tromper le r\u00e9seau de neurones avec une classe qui n'a RIEN \u00c0 VOIR !!"]}, {"cell_type": "markdown", "id": "viral-tennis", "metadata": {}, "source": ["Avant d'aller plus loin, il convient de comprendre un peu mieux pourquoi le r\u00e9seau de neurones a choisi la classe orange \u00e0 la place de citron. En minimisant l'oppos\u00e9 de l'entropie crois\u00e9e afin de trouver notre bruit $\\delta$ nous avons en r\u00e9alit\u00e9 principalement r\u00e9duit l'amplitude des logits (i.e. le vecteur de score associ\u00e9 \u00e0 chaque classe) pour la classe citron... Celle-ci en perdant de l'importance a laiss\u00e9 la place \u00e0 la deuxi\u00e8me classe la plus probable pour cette image : les oranges."]}, {"cell_type": "markdown", "id": "potential-international", "metadata": {}, "source": ["## VI. Une attaque un petit peu plus cibl\u00e9e ?"]}, {"cell_type": "markdown", "id": "aerial-server", "metadata": {}, "source": ["Ce que nous voulons ici, c'est minimiser l'importance d'une classe $A$ tout en augmentant l'importance d'une classe $B$. Le probl\u00e8me qui nous int\u00e9resse est donc :\n", "\n", "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y)+\\ell(h_{\\theta}(x+\\delta), y_{\\text{target}}),$$\n", "\n", "o\u00f9 $y_{\\text{target}}$ est la classe que nous aimerions voir pr\u00e9dite. Choisissons maintenant la classe que nous visons :"]}, {"cell_type": "code", "execution_count": null, "id": "standard-investment", "metadata": {}, "outputs": [], "source": ["target_index = 589\n", "print('Selected target:', classes_to_labels[target_index])"]}, {"cell_type": "markdown", "id": "scheduled-dealing", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "Compl\u00e9tez l'algorithme suivant permettant de construire notre attaque adversaire en contraignant le vecteur $\\delta$ \u00e0 rester dans une boule de rayon $\\epsilon$ et en ciblant une classe objectif.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "execution_count": null, "id": "80b1a1c2", "metadata": {}, "outputs": [], "source": ["# we initialize delta with 0\n", "delta = zeros_like(tensor, requires_grad=True)"]}, {"cell_type": "code", "id": "f237ddc8", "metadata": {}, "source": ["epsilon = 2./255\n", "\n", "# we initialize delta with 0\n", "delta = zeros_like(tensor, requires_grad=True)\n", "\n", "# we construct our optimizer and loss\n", "optimizer = optim.SGD([delta], lr=5e-3)\n", "criterion = CrossEntropyLoss()\n", "\n", "# we construct the targets\n", "true_target = LongTensor([true_index])\n", "target_target = LongTensor([target_index])\n", "\n", "for iteration in range(100):\n", "    ############### COMPLETE HERE ###############\n", "    ...\n", "    ...\n", "    ...\n", "\n", "    if iteration % 5 == 0:\n", "        print('\\r[%d] loss: %.3f' % (iteration, loss.item()), end=\"\")\n", "    \n", "    ...\n", "    ...\n", "    #############################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "2128a00f", "metadata": {}, "source": ["batch = normalize(tensor + delta)[None, :, :, :]\n", "logit = resnet(batch)\n", "\n", "print('\\rTrue class probability:', softmax(logit, dim=1)[0, true_index].item())\n", "\n", "new_index = logit.max(dim=1)[1].item()\n", "new_label = classes_to_labels[new_index]\n", "\n", "print('New class:', new_label)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "regular-gasoline", "metadata": {}, "source": ["Victoire ! Observons maintenant l'image bruit\u00e9e ainsi que le bruit associ\u00e9."]}, {"cell_type": "code", "id": "027b186d", "metadata": {}, "source": ["plt.figure(figsize=(18,18))\n", "plt.subplot(131)\n", "plt.title('Notre image transform\u00e9e $x+\\delta$')\n", "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(132)\n", "plt.title('Le bruit $\\delta$')\n", "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(133)\n", "plt.title('Le bruit $\\delta$ amplifi\u00e9')\n", "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "damaged-gothic", "metadata": {}, "source": ["Nous avons ainsi r\u00e9ussi \u00e0 choisir notre classe objectif et \u00e0 perturber notre r\u00e9seau de neurones avec un bruit invisible \u00e0 l'oeil nu."]}, {"cell_type": "markdown", "id": "unlimited-george", "metadata": {}, "source": ["## VII. La m\u00e9thode \"fast-sign\""]}, {"cell_type": "markdown", "id": "surprising-tracker", "metadata": {}, "source": ["Nous avons pu constater dans l'exemple pr\u00e9c\u00e9dent que la construction d'un exemple adversaire demandait de minimiser une fonction de co\u00fbt (i.e. l'oppos\u00e9 de ce qu'on souhaiterait minimiser en temps normal). Cette minimisation prend un certain temps pour une unique image.\n", "\n", "Il existe une m\u00e9thode alternative, moins performante en terme d'attaque mais plus efficace computationnellement. Il s'agit de la m\u00e9thode \"fast-sign\". Rappelons que l'objectif d'une attaque adversaire est de construire le bruit suivant : \n", "\n", "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y).$$\n", "\n", "L'intuition derri\u00e8re la m\u00e9thode \"fast-sign\" est de supposer que la direction du gradient au cours de la minimisation ne changera pas tr\u00e8s significativement. Ainsi, au lieu de r\u00e9aliser plusieurs petits pas successifs, nous pouvons r\u00e9aliser un grand pas dans la direction du gradient au point de d\u00e9part. Notons que nous souhaitons que notre vecteur de bruit reste dans une boule en norme infini $\\ell_\\infty$. Cela revient \u00e0 dire que pour chaque coordonn\u00e9e positive de notre gradient nous voulons que $\\delta_j=-\\epsilon$ et pour chaque coordonn\u00e9e n\u00e9gative, nous voulons $\\delta_j=\\epsilon$ (nous voulons aller le plus loin possible). Notre bruit devient donc :\n", "\n", "$$\\hat{\\delta}=-\\epsilon\\cdot\\text{sign}(\\nabla_\\delta\\ell(h_{\\theta}(x+\\delta), y)).$$"]}, {"cell_type": "markdown", "id": "suspected-durham", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "\u00c0 vous d'impl\u00e9menter la m\u00e9thode *fast-sign* dans le cas d'une attaque non cibl\u00e9e.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "execution_count": null, "id": "55532dee", "metadata": {}, "outputs": [], "source": ["# we initialize delta with 0\n", "delta = zeros_like(tensor, requires_grad=True)"]}, {"cell_type": "code", "id": "2bf9adb4", "metadata": {}, "source": ["epsilon = 2./255\n", "\n", "# we construct our loss\n", "criterion = CrossEntropyLoss()\n", "\n", "# we construct the target\n", "target = LongTensor([true_index])\n", "\n", "batch = normalize(tensor + delta)[None, :, :, :]\n", "\n", "pred = resnet(batch)\n", "\n", "############### COMPLETE HERE ###############\n", "loss = ...\n", "...\n", "\n", "delta = ...\n", "#############################################\n", "\n", "batch = normalize(tensor + delta)[None, :, :, :]\n", "pred = resnet(batch)\n", "\n", "print('\\rTrue class probability:', softmax(pred, dim=1)[0, true_index].item())\n", "\n", "new_index = pred.max(dim=1)[1].item()\n", "new_label = classes_to_labels[new_index]\n", "\n", "print('New class:', new_label)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "limited-disease", "metadata": {}, "source": ["La performance de l'attaque est grandement r\u00e9duite, mais fonctionne ! Visualisons le r\u00e9sultat :"]}, {"cell_type": "code", "id": "d16c2ec7", "metadata": {}, "source": ["plt.figure(figsize=(18,18))\n", "plt.subplot(131)\n", "plt.title('Notre image transform\u00e9e $x+\\delta$')\n", "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(132)\n", "plt.title('Le bruit $\\delta$')\n", "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(133)\n", "plt.title('Le bruit $\\delta$ amplifi\u00e9')\n", "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "liquid-midwest", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "\u00c0 vous d'impl\u00e9menter la m\u00e9thode *fast-sign* dans le cas d'une attaque cibl\u00e9e.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "execution_count": null, "id": "7e2afa62", "metadata": {}, "outputs": [], "source": ["# we initialize delta with 0\n", "delta = zeros_like(tensor, requires_grad=True)"]}, {"cell_type": "code", "id": "59a7a226", "metadata": {}, "source": ["epsilon = 50./255\n", "\n", "target_index = 589\n", "print('Selected target:', classes_to_labels[target_index])\n", "\n", "# we construct our loss\n", "criterion = CrossEntropyLoss()\n", "\n", "# we construct the target\n", "true_target = LongTensor([true_index])\n", "target_target = LongTensor([target_index])\n", "\n", "batch = normalize(tensor + delta)[None, :, :, :]\n", "\n", "pred = resnet(batch)\n", "\n", "############### COMPLETE HERE ###############\n", "...\n", "...\n", "...\n", "#############################################\n", "\n", "\n", "\n", "batch = normalize(tensor + delta)[None, :, :, :]\n", "pred = resnet(batch)\n", "\n", "print('\\rTrue class probability:', softmax(pred, dim=1)[0, true_index].item())\n", "\n", "new_index = pred.max(dim=1)[1].item()\n", "new_label = classes_to_labels[new_index]\n", "\n", "print('New class:', new_label)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "engaged-difficulty", "metadata": {}, "source": ["Il est probable que cette attaque ait \u00e9chou\u00e9. En effet, nous avons d\u00e9j\u00e0 pu observer que dans le cas non cibl\u00e9, notre attaque avait eu beaucoup moins d'effet. L'effet sur les logits de la bonne classe est encore plus r\u00e9duit lorsque l'attaque devient cibl\u00e9e. Pour que l'attaque fonctionne, nous devons consid\u00e9rer un d\u00e9placement plus significatif qui risque d'\u00eatre visible \u00e0 l'\u00e9cran...\n", "\n", "Testez plusieurs valeurs de $\\epsilon$ et observez le r\u00e9sultat \u00e0 la fois en termes de pr\u00e9diction que visuellement avec le code ci-dessous."]}, {"cell_type": "code", "id": "ad11a461", "metadata": {}, "source": ["plt.figure(figsize=(18,18))\n", "plt.subplot(131)\n", "plt.title('Notre image transform\u00e9e $x+\\delta$')\n", "plt.imshow((tensor + delta).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(132)\n", "plt.title('Le bruit $\\delta$')\n", "plt.imshow((delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.subplot(133)\n", "plt.title('Le bruit $\\delta$ amplifi\u00e9')\n", "plt.imshow((50*delta + 0.5).detach().numpy().transpose(1,2,0))\n", "plt.axis('off')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "wound-participant", "metadata": {}, "source": ["## VIII. Devenir robuste aux attaques adversaires"]}, {"cell_type": "markdown", "id": "demographic-chorus", "metadata": {}, "source": ["### Introduction\n", "Comme indiqu\u00e9 plus haut, l'objectif de notre apprentissage est de trouver la solution :\n", "\n", "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\ell(h_\\theta(x_i), y_i)=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\mathcal{L}(h_\\theta, S_n).$$\n", "\n", "C'est la param\u00e9trisation qui fait le moins d'erreur (au sens de la loss $\\ell$) sur notre jeu de donn\u00e9es d'apprentissage. Si le choix de notre classe de fonctions et de nos hyperparam\u00e8tres est bon, alors cette m\u00eame param\u00e9trisation fonctionnera \u00e9galement sur des donn\u00e9es que nous n'avons pas encore vu. Cependant, cette derni\u00e8re peut \u00eatre tr\u00e8s sensible aux attaques adversaires comme nous avons pu le voir ci-dessus. Une solution consiste \u00e0 ne pas minimiser notre loss sur le jeu d'apprentissage, mais notre loss dans le pire des cas :\n", "\n", "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(h_\\theta(x_i+\\delta), y_i).$$\n", "\n", "Rappelons nous que l'algorithme de descente de gradient a besoin de ce dernier. Il nous faut donc calculer le gradient du maximum. Il se trouve que la solution est assez simple et revient \u00e0 calculer le gradient au point $\\delta^\\star$, solution du maximum :\n", "\n", "$$\\nabla_\\theta \\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(h_\\theta(x_i+\\delta), y_i)=\\nabla_\\theta \\ell(h_\\theta(x_i+\\delta^\\star), y_i).$$"]}, {"cell_type": "markdown", "id": "informational-watch", "metadata": {}, "source": ["### Construction du jeu de donn\u00e9es\n", "Nous utiliserons ici le jeu de donn\u00e9es MNIST restreint aux chiffres 0 et 1."]}, {"cell_type": "code", "execution_count": null, "id": "timely-composite", "metadata": {}, "outputs": [], "source": ["mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n", "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())"]}, {"cell_type": "code", "execution_count": null, "id": "suspected-netscape", "metadata": {}, "outputs": [], "source": ["train_idx = mnist_train.targets <= 1\n", "mnist_train.data = mnist_train.data[train_idx]\n", "mnist_train.targets = mnist_train.targets[train_idx]\n", "\n", "test_idx = mnist_test.targets <= 1\n", "mnist_test.data = mnist_test.data[test_idx]\n", "mnist_test.targets = mnist_test.targets[test_idx]\n", "\n", "train_loader = DataLoader(mnist_train, batch_size = 512, shuffle=True)\n", "test_loader = DataLoader(mnist_test, batch_size = 512, shuffle=False)"]}, {"cell_type": "markdown", "id": "tired-emerald", "metadata": {}, "source": ["Visualisons la t\u00eate de ces donn\u00e9es."]}, {"cell_type": "code", "execution_count": null, "id": "laden-plant", "metadata": {}, "outputs": [], "source": ["iterator = iter(train_loader)\n", "images, labels = next(iterator)\n", "\n", "plt.figure(figsize=(12,12))\n", "for j in range(16):\n", "    plt.subplot(4, 4, j+1)\n", "    plt.title(str(labels[j].numpy()))\n", "    plt.imshow(torch.squeeze(images[j].detach()).numpy())\n", "    plt.axis('off')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "dried-reward", "metadata": {}, "source": ["### Un cas simple : le mod\u00e8le lin\u00e9aire (Rappels)\n", "\n", "La m\u00e9thode \"fast-sign\" permet d'obtenir efficacement un adversaire mais le r\u00e9sultat n'est qu'approximatif. Le cas du mod\u00e8le lin\u00e9aire est int\u00e9ressant car il est possible de trouver analytiquement les solutions de la maximisation (l'adversaire). Comme nous l'avons vu, un mod\u00e8le lin\u00e9aire cherche \u00e0 s\u00e9parer les classes par un ou plusieurs (multi-classes) hyperplans. Supposons que nous soyons dans $\\mathbb{R}^d$, un hyper-plan est d\u00e9crit par un vecteur $\\omega\\in\\mathbb{R}^d$ et un scalaire $b\\in\\mathbb{R}$. Le vecteur $\\omega$ donne l'orientation de l'hyperplan et $b$ sa \"distance\" \u00e0 \"l'origine\". Ainsi, un hyperplan est repr\u00e9sent\u00e9 par l'ensemble des points suivants :\n", "\n", "$$\\{x\\in\\mathbb{R}^d:\\ \\langle \\omega, x\\rangle+b=0\\}.$$\n", "\n", "Au-del\u00e0 des points de l'hyperplan, la quantit\u00e9 $\\langle \\omega, x,\\rangle+b$ est positive si on est d'un c\u00f4t\u00e9 de l'hyperplan et n\u00e9gative de l'autre. Consid\u00e9rons le cas binaire et notons nos classes $\\mathcal{Y}=\\{-1,+1\\}$. On souhaiterait que le c\u00f4t\u00e9 n\u00e9gatif de l'hyperplan soit associ\u00e9 aux donn\u00e9es dont le label est -1 et de la m\u00eame mani\u00e8re que le c\u00f4t\u00e9 positif soit associ\u00e9 aux donn\u00e9es dont le label est +1.\n", "\n", "Soit la fonction $\\text{sign}(z)$ qui retourne $+1$ si $z>0$ et $-1$ si $z\\leq 0$. Le classifieur associ\u00e9 \u00e0 notre hyperplan se construit donc de la mani\u00e8re suivante : \n", "\n", "$$h_\\theta(x)=\\text{sign}(\\langle \\omega, x\\rangle + b),\\ \\theta=\\{\\omega\\in\\mathbb{R}^d,b\\in\\mathbb{R}\\}.$$\n", "\n", "Par simplicit\u00e9 de notation nous ommettrons \u00e0 partir de maintenant le biais $b$. Notons $g(x)=\\langle \\omega, x\\rangle$. Il s'agit d'une fonction qui donne le score de classification. On remarque que la fonction $g$ pr\u00e9dit le bon label si $g(x)$ a le m\u00eame signe que $y$. Dit autrement, nos pr\u00e9dictions sont correctes si $g(x)y>0$.\n", "\n", "Intuitivement, nous aimerions minimiser la loss 0/1 :\n", "\n", "$$\\ell_{0/1}(z)=1\\{z\\leq 0\\}.$$\n", "\n", "Cette loss retourne $1$ si $z$ est n\u00e9gatif et $0$ sinon. Appliqu\u00e9 \u00e0 notre mod\u00e8le, cela donn\u00e9e $\\ell(g(x)y)$ qui vaut $1$ si $g(x)$ n'a pas le m\u00eame signe que $y$. C'est exactement ce qu'on veut. Cependant, cette loss n'est pas diff\u00e9rentiable en $0$ et son gradient vaut $0$ partout ailleurs. Cela nous complique la t\u00e2che lorsqu'on cherche \u00e0 optimiser notre mod\u00e8le. Utilisons donc une loss poss\u00e9dant de meilleures propri\u00e9t\u00e9s math\u00e9matiques ainsi que certaines garanties pour la classification. Il s'agit de la fonction de perte logistique :\n", "\n", "$$\\ell(z)=\\text{log}(1+e^{-z}).$$\n", "\n", "On remarque que si $z$ est tr\u00e8s grand ($g$ et $y$ sont de m\u00eame signe et le score pr\u00e9dit est grand) alors la fonction est tr\u00e8s proche de $0$. Si $z$ est tr\u00e8s petit ($g$ et $y$ sont de signe diff\u00e9rent et le score pr\u00e9dit est grand) alors la fonction diverge vers $+\\infty$. Il s'agit en r\u00e9alit\u00e9 exactement de l'entropie crois\u00e9e compos\u00e9e avec la sigmoid que nous avons d\u00e9j\u00e0 vu !\n", "\n", "Finalement, le probl\u00e8me \u00e0 r\u00e9soudre dans le cadre d'un classifieur lin\u00e9aire est le suivant :\n", "\n", "$$\\theta^\\star=\\text{argmin}_{\\theta=\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i \\ell(y\\langle \\omega, x\\rangle).$$\n", " "]}, {"cell_type": "markdown", "id": "radical-ottawa", "metadata": {}, "source": ["### Construction du mod\u00e8le"]}, {"cell_type": "code", "execution_count": null, "id": "characteristic-amateur", "metadata": {}, "outputs": [], "source": ["class LinearClassifier(Module):\n", "    def __init__(self, dim_input=784):\n", "        super(LinearClassifier, self).__init__()\n", "        self.weights = Linear(dim_input, 1)\n", "        self.dim_input = dim_input\n", "        \n", "    def forward(self, x):\n", "        # we flatten the image into a vector\n", "        x = x.view(x.size()[0], self.dim_input)\n", "        # we apply our linear model\n", "        return self.weights(x)"]}, {"cell_type": "markdown", "id": "respected-hazard", "metadata": {}, "source": ["### Construction de la loss"]}, {"cell_type": "markdown", "id": "digital-level", "metadata": {}, "source": ["La logistic loss n'est rien d'autre que la sigmoid compos\u00e9e avec l'entropie crois\u00e9e."]}, {"cell_type": "code", "execution_count": null, "id": "dental-proof", "metadata": {}, "outputs": [], "source": ["class LogisticLoss(Module):\n", "    def __init__(self):\n", "        super(LogisticLoss, self).__init__()\n", "        \n", "    def forward(self, y_hat, y):\n", "        # we flatten the image into a vector\n", "        y_hat = torch.squeeze(y_hat)\n", "        batch_size = y_hat.size()[0]\n", "        y = 2*y-1  # on met les labels entre -1 (anciennement 0) et 1\n", "        z = y*y_hat\n", "        return torch.sum(torch.log(1+torch.exp(-z))) / batch_size"]}, {"cell_type": "markdown", "id": "existing-battlefield", "metadata": {}, "source": ["### Entra\u00eenement"]}, {"cell_type": "markdown", "id": "aerial-hampshire", "metadata": {}, "source": ["Notez qu'il s'agit encore et toujours ici de l'entra\u00eenement classique o\u00f9 nous ne tenons pas compte des attaques adversaires."]}, {"cell_type": "code", "execution_count": null, "id": "aggregate-behalf", "metadata": {}, "outputs": [], "source": ["# TODO D\u00e9commenter les prints de loss, etc.\n", "def train_and_plot(lr=0.005, epochs=50, logs=10, criterion=LogisticLoss()):\n", "    model = LinearClassifier()\n", "    # model.cuda()\n", "    \n", "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n", "    \n", "    loss_history = []\n", "    running_loss = 0.0\n", "    for e in range(epochs):\n", "        for idx, data in enumerate(train_loader):\n", "            inputs, labels = data\n", "            # labels = labels.cuda()\n", "            optimizer.zero_grad()\n", "            outputs = model(inputs)\n", "            \n", "            loss = criterion(outputs, labels)\n", "            running_loss += loss.item()\n", "            if idx % logs == logs - 1:  # print every 2000 mini-batches\n", "                print('\\r[%d, %5d] loss: %.3f' % (e + 1, idx + 1, running_loss / logs), end=\"\")\n", "                loss_history.append(running_loss / logs)\n", "                running_loss = 0.0\n", "\n", "            loss.backward() # on calcule le gradient\n", "            optimizer.step() # on fait un pas d'optimisation\n", "    print('\\r************* Training done! *************')\n", "    plt.figure(figsize=(14, 8))\n", "    plt.plot(loss_history)\n", "    plt.title('Loss')\n", "    plt.show()\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "id": "practical-expression", "metadata": {}, "outputs": [], "source": ["model = train_and_plot(lr=0.001, epochs=60, logs=1)"]}, {"cell_type": "markdown", "id": "played-depth", "metadata": {}, "source": ["### Test des performances"]}, {"cell_type": "code", "execution_count": null, "id": "afraid-butler", "metadata": {}, "outputs": [], "source": ["def test(model):\n", "    model.eval()  # on passe le modele en mode evaluation\n", "    correct = 0\n", "    total = 0\n", "    with torch.no_grad():\n", "        for data in test_loader:\n", "            images, labels = data\n", "            #images = images.cuda()\n", "            #labels = labels.cuda()\n", "            outputs = model(images)\n", "            predicted = torch.squeeze((outputs > 0).float())\n", "        \n", "            total += labels.size(0)\n", "            correct += (predicted == labels).sum().item()\n", "            \n", "    model.train()  # on remet le modele en mode apprentissage\n", "    print('Accuracy du modele sur le jeu de test: %d %%' % (100 * correct / total))"]}, {"cell_type": "code", "execution_count": null, "id": "finite-edinburgh", "metadata": {}, "outputs": [], "source": ["test(model)"]}, {"cell_type": "markdown", "id": "eleven-express", "metadata": {}, "source": ["### Construction d'une attaque adversaire dans le cas du mod\u00e8le lin\u00e9aire"]}, {"cell_type": "markdown", "id": "unnecessary-candidate", "metadata": {}, "source": ["\n", "En reprenant le probl\u00e8me de l'apprentissage robuste aux attaques adversaires tel que d\u00e9fini ci-dessus, notre loss n'est plus directement $\\ell$. En effet, comme indiqu\u00e9, nous devons non pas \u00e9valuer $\\ell$ en $x$ mais dans un voisinage de $x$ tel que le score de notre mod\u00e8le y est le plus mauvais possible. La *loss* dans le pire des cas est d\u00e9crite par l'\u00e9quation suivante :\n", "\n", "$$\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(y\\langle\\omega, x+\\delta\\rangle)=\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\text{log}(1+e^{-y\\langle\\omega, x+\\delta\\rangle}).$$\n", "\n", "Avant d'aller plus loin, observons notre fonction de perte logistique."]}, {"cell_type": "code", "execution_count": null, "id": "peaceful-draft", "metadata": {}, "outputs": [], "source": ["z=np.linspace(-5, 5, 101)\n", "y=np.log(1+np.exp(-z))\n", "\n", "plt.figure(figsize=(14, 10))\n", "plt.plot(z, y)\n", "plt.title('La fonction de perte logistique')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "proper-permit", "metadata": {}, "source": ["Celle-ci semble monotone et d\u00e9croissante (et convexe). Pour nous en convaincre, calculons la d\u00e9riv\u00e9e :\n", "\n", "$$\\ell^\\prime(z)=-\\frac{1}{e^z+1}<0,$$\n", "\n", "qui est bien toujours n\u00e9gative confirmant \u00e0 la fois la monotonie et la d\u00e9croissance. Pour le fun, constatons que notre fonction est bien \u00e9galement convexe :\n", "\n", "$$\\ell^{\\prime\\prime}(z)=\\frac{e^z}{(e^z+1)^2}>0.$$\n", "\n", "La fonction de perte logistique est donc m\u00eame strictement convexe.\n", "\n", "---"]}, {"cell_type": "markdown", "id": "respected-mozambique", "metadata": {}, "source": ["En constatant ainsi que la fonction de perte logistique est monotone ET d\u00e9croissante et en exploitant la lin\u00e9arit\u00e9 du produit scalaire, on obtient donc :\n", "\n", "$$\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(y\\langle\\omega, x+\\delta\\rangle)=\\ell(\\text{min}y\\langle\\omega, x+\\delta\\rangle)=\\ell(y\\langle\\omega, x\\rangle+\\text{min}y\\langle \\omega, \\delta\\rangle).$$"]}, {"cell_type": "markdown", "id": "hollywood-batman", "metadata": {}, "source": ["Il nous reste donc \u00e0 chercher la solution du probl\u00e8me de minimisation $\\text{min}_{\\delta\\in\\mathcal{B}_\\epsilon}y\\langle \\omega, \\delta\\rangle$\n", "qui, heureusement pour nous, est convexe avec un domaine de d\u00e9finition compact. Il y a donc un minimum local qui est le minimum global. La norme $\\ell_\\infty$ nous permet de consid\u00e9rer chaque dimension s\u00e9par\u00e9ment (le probl\u00e8me est s\u00e9parable). Nous voulons donc calculer :\n", "\n", "$$\\text{min}_{|\\delta_j|\\leq \\epsilon}y\\langle \\omega_j, \\delta_j\\rangle.$$\n", "\n", "Si $\\omega_j=0$, toutes les solutions se valent. Si $\\omega_j\\neq 0$ et $y=-1$, alors le minimum est atteint lorsque $\\delta_j=\\epsilon\\cdot\\text{sign}(\\omega_j)$. Enfin, si $y=1$, alors le minimum est atteint lorsque $\\delta_j=-\\epsilon\\cdot\\text{sign}(\\omega_j)$. De mani\u00e8re g\u00e9n\u00e9rale, nous avons :\n", "\n", "$$\\delta^\\star=-y \\epsilon\\cdot\\text{sign}(\\omega)$$\n", "\n", "Nous avons ainsi : \n", "\n", "$$\\text{min}_{\\delta\\in\\mathcal{B}_\\epsilon}y\\langle \\omega, \\delta\\rangle=y\\langle\\omega, -y \\epsilon\\cdot\\text{sign}(\\omega)\\rangle=-y^2\\epsilon\\langle \\omega, \\text{sign}(\\omega)\\rangle=-\\epsilon\\lVert\\omega\\rVert_1.$$\n", "\n", "Un apprentissage robuste aux attaques adversaires minimise donc la loss :\n", "\n", "$$\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\text{log}(1+e^{-y\\langle\\omega, x\\rangle+\\epsilon\\lVert\\omega\\rVert_1})=\\ell(y\\langle\\omega, x\\rangle-\\epsilon\\lVert\\omega\\rVert_1)$$\n", "\n", "On retombe quasiment sur un probl\u00e8me d'optimisation avec une p\u00e9nalit\u00e9 $\\ell_1$. On cherche le vecteur $\\omega$ qui maximise les bonnes pr\u00e9dictions mais qui en m\u00eame temps poss\u00e8de une norme $\\ell_1$ faible."]}, {"cell_type": "markdown", "id": "concrete-conspiracy", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "En vous appuyant sur les \"r\u00e9sultats th\u00e9oriques\" pr\u00e9c\u00e9dent, proposez un code permettant de g\u00e9n\u00e9rer un bruit adversaire.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "id": "967a1aa5", "metadata": {}, "source": ["def generate_adversarial_noise(image_and_label, model, epsilon=0.5):\n", "    imagesize = (1, 28, 28)\n", "    image, label = image_and_label\n", "    label = -1 if label==0 else label\n", "    ############### COMPLETE HERE ###############\n", "    noise = ...\n", "    #############################################\n", "    \n", "    return noise\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "93eb3097", "metadata": {}, "source": ["def plot_images_and_noise(image, noise):\n", "    plt.figure(figsize=(18,18))\n", "    plt.subplot(131)\n", "    plt.title('Notre image $x$')\n", "    plt.imshow(torch.squeeze(image.detach()).numpy())\n", "    plt.axis('off')\n", "    plt.subplot(132)\n", "    plt.title('Notre image transform\u00e9e $x + \\delta^\\star$')\n", "    plt.imshow(torch.squeeze((image+noise).detach()).numpy())\n", "    plt.axis('off')\n", "    plt.subplot(133)\n", "    plt.title('Notre bruit $\\delta^\\star$')\n", "    plt.imshow(torch.squeeze(noise.detach()))\n", "    plt.axis('off')\n", "    plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "e40312da", "metadata": {}, "source": ["iterator = iter(train_loader)\n", "\n", "images, labels = next(iterator)\n", "noise = generate_adversarial_noise((images[0], labels[0]), model)\n", "\n", "plot_images_and_noise(images[0], noise)\n", "\n", "prediction = 0 if model(images[0])[0, 0] < 0 else 1\n", "print('Pr\u00e9diction:', prediction)\n", "prediction = 0 if model(images[0]+noise)[0, 0] < 0 else 1\n", "print('Pr\u00e9diction avec du bruit:', prediction)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "direct-sound", "metadata": {}, "source": ["### Apprentissage robuste aux attaques adversaires"]}, {"cell_type": "markdown", "id": "impressed-classification", "metadata": {}, "source": ["Un apprentissage robuste aux exemples adversaires cherche tout simplement \u00e0 minimiser le pire des sc\u00e9narios&nbsp;:\n", "\n", "$$\\omega^\\star=\\text{argmin}_{\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i\\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(y_i\\langle\\omega, x_i +\\delta\\rangle)=\\text{argmin}_{\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i\\ell(y_i\\langle\\omega, x_i\\rangle-\\epsilon\\lVert\\omega\\rVert_1).$$"]}, {"cell_type": "markdown", "id": "gorgeous-meeting", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "En vous appuyant sur les \"r\u00e9sultats th\u00e9oriques\" pr\u00e9c\u00e9dent, proposez un code permettant de construire une loss robuste aux attaques adversaires.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "id": "8a3a10a9", "metadata": {}, "source": ["class RobustLogisticLoss(Module):\n", "    def __init__(self, weights, epsilon=0.5):\n", "        super(RobustLogisticLoss, self).__init__()\n", "        self.epsilon = epsilon\n", "        self.weights = weights\n", "        \n", "    def forward(self, y_hat, y):\n", "        # we flatten the image into a vector\n", "        y_hat = torch.squeeze(y_hat)\n", "        batch_size = y_hat.size()[0]\n", "        y[y == 0] = -1\n", "        ############### COMPLETE HERE ###############\n", "        z = ......\n", "        #############################################\n", "        \n", "        return torch.sum(torch.log(1+torch.exp(-z))) / batch_size\n", "    \n", "model = train_and_plot(lr=0.001, epochs=60, logs=1, criterion=RobustLogisticLoss(model.weights.weight))\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "d0f9767c", "metadata": {}, "source": ["\n", "iterator = iter(train_loader)\n", "\n", "images, labels = next(iterator)\n", "noise = generate_adversarial_noise((images[0], labels[0]), model)\n", "\n", "plot_images_and_noise(images[0], noise)\n", "\n", "prediction = 0 if model(images[0])[0, 0] < 0 else 1\n", "\n", "print('Pr\u00e9diction:', prediction)\n", "prediction = 0 if model(images[0]+noise)[0, 0] < 0 else 1\n", "print('Pr\u00e9diction avec du bruit:', prediction)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "viral-scale", "metadata": {}, "source": ["Il se trouve que les mod\u00e8les lin\u00e9aires sont d\u00e9j\u00e0 beaucoup plus robustes aux attaques adversaires que les r\u00e9seaux de neurones. Malheureusement, les choses sont plus compliqu\u00e9es pour ces derni\u00e8res puisque il n'y a d\u00e9j\u00e0 pas de solution analytique..."]}, {"cell_type": "markdown", "id": "advanced-divide", "metadata": {}, "source": ["## En r\u00e9sum\u00e9"]}, {"cell_type": "markdown", "id": "emerging-ideal", "metadata": {}, "source": ["*  Nous avons vu comment formaliser la notion d'attaque adversaire via un probl\u00e8me d'optimisation sous contrainte :\n", "\n", "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y),$$\n", "\n", "*  Nous avons vu une mani\u00e8re de cibler l'attaque afin de \"forcer\" notre mod\u00e8le \u00e0 pr\u00e9dire une classe particuli\u00e8re :\n", "\n", "$$\\delta^\\star=\\text{argmin}_{\\delta\\in\\mathcal{B}_\\epsilon}-\\ell(h_{\\theta}(x+\\delta), y)+\\ell(h_{\\theta}(x+\\delta), y_{\\text{target}}),$$\n", "\n", "*  Nous avons contourn\u00e9 le processus d'optimisation via une heuristique, la m\u00e9thode *fast-sign* :\n", "\n", "$$\\hat{\\delta}=-\\epsilon\\cdot\\text{sign}(\\nabla_\\delta\\ell(h_{\\theta}(x+\\delta), y)),$$\n", "\n", "*  Nous avons \u00e9galement formalis\u00e9 le probl\u00e8me d'apprentissage robuste aux attaques : \n", "\n", "$$\\theta^\\star=\\text{argmin}_{\\theta\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_i \\text{max}_{\\delta\\in\\mathcal{B}_\\epsilon}\\ell(h_\\theta(x_i+\\delta), y_i),$$\n", "\n", "*  Et avons r\u00e9solu la maximisation dans le cadre d'un classifieur lin\u00e9aire :\n", "\n", "$$\\omega^\\star=\\text{argmin}_{\\omega\\in\\mathbb{R}^d}\\frac{1}{n}\\sum_i\\ell(y_i\\langle\\omega, x_i\\rangle-\\epsilon\\lVert\\omega\\rVert_1).$$"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 5}