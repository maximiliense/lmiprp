
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Les attaques adversaires â˜•ï¸ &#8212; Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lâ€™apprentissage non-supervisÃ©" href="../7_unsupervised/0_propos_liminaire.html" />
    <link rel="prev" title="Transfer learning et apprentissage multi-tÃ¢ches â˜•ï¸â˜•ï¸" href="5_transfer_multitask.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-72WWYCKNK6"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-72WWYCKNK6');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../0_requisite/rappels_python.html">
   Rappels de Python et Numpy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../1_what_is_ml/0_propos_liminaire.html">
   <em>
    Machine Learning
   </em>
   , initiation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_what_is_ml/1_introduction_ml.html">
     <em>
      Machine learning
     </em>
     et malÃ©diction de la dimension
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_what_is_ml/2_regression_and_classification_trees.html">
     Les arbres de rÃ©gression et de classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../2_regression/0_propos_liminaire.html">
   La
   <em>
    rÃ©gression
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_regression/1_linear_regression.html">
     La rÃ©gression linÃ©aire â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_regression/2_optimization.html">
     Lâ€™optimisation â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_regression/3_interpolation.html">
     Interpolation â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_regression/4_algo_proximal_lasso.html">
     Sous-diffÃ©rentiel et le cas du Lasso â˜•ï¸â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_regression/5_least_square_qr.html">
     Les moindres carrÃ©s via une dÃ©composition QR (et plus)â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_regression/6_ridge.html">
     Une analyse de la rÃ©gularisation Ridge â˜•ï¸â˜•ï¸â˜•ï¸
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../3_classification/0_propos_liminaire.html">
   La
   <em>
    classification
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/1_logistic_regression.html">
     La rÃ©gression logistique â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/2_fonctions_proxy.html">
     Les fonctions de perte (loss function) â˜•ï¸â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/3_bayes_classifier.html">
     Le classifieur de Bayes â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/4_VC_theory.html">
     Un modÃ¨le formel de lâ€™apprentissage â˜•ï¸â˜•ï¸â˜•ï¸â˜•ï¸ (ğŸ’†â€â™‚ï¸)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../4_kernel_methods/0_propos_liminaire.html">
   Les mÃ©thodes Ã  noyaux
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_kernel_methods/1_svm.html">
     Le SVM ou lâ€™hypothÃ¨se max-margin â˜•ï¸â˜•ï¸
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../5_ensembles/0_propos_liminaire.html">
   Les mÃ©thodes
   <em>
    ensemblistes
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_ensembles/1_ensembles.html">
     MÃ©thodes ensemblistes â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_ensembles/2_bayesian_linear_regression.html">
     Bayesian linear regression â˜•ï¸â˜•ï¸â˜•ï¸â˜•ï¸
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="0_propos_liminaire.html">
   <em>
    deep learning
   </em>
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="1_autodiff.html">
     La diffÃ©rentiation automatique et un dÃ©but de
     <em>
      deep learning
     </em>
     â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="2_filters_representation.html">
     Filtres et espace de reprÃ©sentation des rÃ©seaux de neurones â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3_probabilities_calibration.html">
     Calibration des probabilitÃ©s et quelques notions â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="4_regularization_deep.html">
     RÃ©gularisation en
     <em>
      deep learning
     </em>
     â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5_transfer_multitask.html">
     <em>
      Transfer learning
     </em>
     et apprentissage multi-tÃ¢ches â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Les attaques adversaires â˜•ï¸
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../7_unsupervised/0_propos_liminaire.html">
   Lâ€™apprentissage non-supervisÃ©
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_unsupervised/1_principal_component_analysis.html">
     Lâ€™Analyse en Composantes Principales â˜•ï¸â˜•ï¸â˜•ï¸
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_unsupervised/2_em_gaussin_mixture_model.html">
     ModÃ¨le de MÃ©lange Gaussien et algorithme
     <em>
      Expectation-Maximization
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../8_set_prediction/0_propos_liminaire.html">
   PrÃ©diction dâ€™ensembles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_set_prediction/1_well_defined.html">
     Jeu dâ€™apprentissage
     <em>
      set-valued
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_set_prediction/2_ill_defined.html">
     Jeu dâ€™apprentissage uniquement multi-classes â˜•ï¸
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../biblio.html">
   Bibliographie
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/6_deeplearning/6_adversarial.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/maximiliense/lmiprp"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/maximiliense/lmiprp/issues/new?title=Issue%20on%20page%20%2F6_deeplearning/6_adversarial.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/maximiliense/lmiprp/blob/master/Travaux Pratiques/Machine Learning/Book/6_deeplearning/6_adversarial.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#i-introduction-qu-est-ce-qu-une-attaque-adversaire">
   I. Introduction, quâ€™est-ce quâ€™une attaque adversaire ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ii-imports-et-construction-du-modele">
   II. Imports et construction du modÃ¨le
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iii-la-donnee-a-attaquer">
   III. La donnÃ©e Ã  attaquer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iv-une-premiere-attaque">
   IV. Une premiÃ¨re attaque
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quelques-rappels-d-optimisation">
     Quelques rappels dâ€™optimisation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#construction-d-une-attaque-adversaire">
     Construction dâ€™une attaque adversaire
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#v-un-deuxieme-essai">
   V. Un deuxiÃ¨me essai
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vi-une-attaque-un-petit-peu-plus-ciblee">
   VI. Une attaque un petit peu plus ciblÃ©e ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vii-la-methode-fast-sign">
   VII. La mÃ©thode â€œfast-signâ€
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#viii-devenir-robuste-aux-attaques-adversaires">
   VIII. Devenir robuste aux attaques adversaires
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introduction">
     Introduction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#construction-du-jeu-de-donnees">
     Construction du jeu de donnÃ©es
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#un-cas-simple-le-modele-lineaire-rappels">
     Un cas simple : le modÃ¨le linÃ©aire (Rappels)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#construction-du-modele">
     Construction du modÃ¨le
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#construction-de-la-loss">
     Construction de la loss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entrainement">
     EntraÃ®nement
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-des-performances">
     Test des performances
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#construction-d-une-attaque-adversaire-dans-le-cas-du-modele-lineaire">
     Construction dâ€™une attaque adversaire dans le cas du modÃ¨le linÃ©aire
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#apprentissage-robuste-aux-attaques-adversaires">
     Apprentissage robuste aux attaques adversaires
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#en-resume">
   En rÃ©sumÃ©
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="les-attaques-adversaires">
<h1>Les attaques adversaires â˜•ï¸<a class="headerlink" href="#les-attaques-adversaires" title="Permalink to this headline">Â¶</a></h1>
<div class="admonition-objectifs-de-la-sequence admonition">
<p class="admonition-title">Objectifs de la sÃ©quence</p>
<ul class="simple">
<li><p>ÃŠtre sensibilisÃ©Â :</p>
<ul>
<li><p>aux attaques adversaires,</p></li>
<li><p>Ã  leur lien au sur-apprentissage et Ã  la rÃ©gularisation.</p></li>
</ul>
</li>
<li><p>ÃŠtre capableÂ :</p>
<ul>
<li><p>dâ€™implÃ©menter une attaque adversaire avec <span class="math notranslate nohighlight">\(\texttt{pytorch}\)</span>,</p></li>
<li><p>de produire un apprentissage robuste aux attaques adversaires.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="i-introduction-qu-est-ce-qu-une-attaque-adversaire">
<h2>I. Introduction, quâ€™est-ce quâ€™une attaque adversaire ?<a class="headerlink" href="#i-introduction-qu-est-ce-qu-une-attaque-adversaire" title="Permalink to this headline">Â¶</a></h2>
<p>Reprenons le problÃ¨me introduit prÃ©cÃ©demment. Soit <span class="math notranslate nohighlight">\(\mathcal{X}\subseteq\mathbb{R}^d\)</span> notre espace dâ€™entrÃ©e et <span class="math notranslate nohighlight">\(\mathcal{Y}=\{1, \ldots, C\}\)</span> notre espace de sortie oÃ¹ <span class="math notranslate nohighlight">\(C\in\mathbb{N}\)</span> est le nombre de classes de notre problÃ¨me de classification. ConsidÃ©rons une famille paramÃ©trique de fonctions :</p>
<div class="math notranslate nohighlight">
\[\mathcal{H}=\{h_\theta:\ \theta\in\mathbb{R}^p\},\]</div>
<p>oÃ¹ <span class="math notranslate nohighlight">\(p\in\mathbb{N}\)</span> est le nombre de paramÃ¨tres. Notons <span class="math notranslate nohighlight">\(S_n\)</span> notre jeu de donnÃ©es dâ€™apprentissage composÃ© de <span class="math notranslate nohighlight">\(n\)</span> exemples, <span class="math notranslate nohighlight">\(T_m\)</span> notre jeu de test et <span class="math notranslate nohighlight">\(\ell\)</span> la <em>loss</em> pour une unique prÃ©diction. Notons aussi <span class="math notranslate nohighlight">\(\text{Acc}(h_\theta, S)\)</span> le pourcentage de bonnes prÃ©dictions (i.e. <em>accuracy</em>) faites par <span class="math notranslate nohighlight">\(h_\theta\)</span> sur lâ€™ensemble de donnÃ©es <span class="math notranslate nohighlight">\(S\)</span>. Lâ€™objectif classique en <em>machine learning</em> est de trouver la paramÃ©trisation qui nous permet de minimiser notre <em>loss</em> sur le jeu de donnÃ©es dâ€™apprentissageÂ :</p>
<div class="math notranslate nohighlight">
\[\theta^\star=\text{argmin}_{\theta\in\mathbb{R}^p}\frac{1}{n}\sum_i \ell(h_\theta(x_i), y_i)=\text{argmin}_{\theta\in\mathbb{R}^p}\mathcal{L}(h_\theta, S_n).\]</div>
<p>Cette minimisation nâ€™est cependant pas un critÃ¨re ultime et on souhaite que la fonction ainsi obtenue se comporte bien sur de nouvelles donnÃ©es jamais observÃ©es. Une maniÃ¨re dâ€™estimer ces performances consiste Ã  tester notre fonction sur un jeu de test :</p>
<div class="math notranslate nohighlight">
\[\text{Acc}(h_{\theta^\star}, T_m).\]</div>
<p>Et malheureusement, la paramÃ©trisation qui minimise notre <em>loss</em> nâ€™est pas toujours performante sur de nouvelles donnÃ©es, comme nous avons pu le voir. Pour cela, diverses techniques allant de la rÃ©duction du nombre de paramÃ¨tres aux techniques de rÃ©gularitation <span class="math notranslate nohighlight">\(\ell_1\)</span> ou <span class="math notranslate nohighlight">\(\ell_2\)</span> en passant par le <em>dropout</em>, etc. sont possibles.</p>
<p>Cependant, imaginons que notre jeu de test <span class="math notranslate nohighlight">\(T_m\)</span> au lieu dâ€™Ãªtre un tirage alÃ©atoire reprÃ©sentatif de la distribution de nos donnÃ©es soit choisi par un adversaire dont lâ€™objectif est de mettre en Ã©chec notre modÃ¨le dâ€™une maniÃ¨re telle quâ€™un Ãªtre humain nâ€™y verrait aucune diffÃ©rence. Est-il possible de faire croire Ã  un modÃ¨le que la photo dâ€™un STOP est en rÃ©alitÃ© une limitation de vitesse Ã  130km/h sans quâ€™un Ãªtre humain ne voit la diffÃ©rence. Câ€™est lÃ  lâ€™objectif des attaques adversaires.</p>
<img SRC="https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemons_result.jpeg" style='width:700px' align="center" >
<p>Nous commencerons lâ€™Ã©tude de ces questions en utilisant un modÃ¨le de lâ€™Ã©tat de lâ€™art dÃ©jÃ  prÃ©-entraÃ®nÃ© sur la base de donnÃ©es ImagetNet. Lâ€™objectif sera dans un premier temps de construire ces attaques adversaires puis, dans un second temps, de construire une procÃ©dure dâ€™apprentissage robuste aux attaques adversaires.</p>
</div>
<div class="section" id="ii-imports-et-construction-du-modele">
<h2>II. Imports et construction du modÃ¨le<a class="headerlink" href="#ii-imports-et-construction-du-modele" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torch.nn.functional</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span> <span class="k">as</span> <span class="n">TorchDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span><span class="p">,</span> <span class="n">zeros_like</span><span class="p">,</span> <span class="n">LongTensor</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>
<span class="kn">import</span> <span class="nn">ast</span><span class="o">,</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<p>Le modÃ¨le utilisÃ© est <span class="math notranslate nohighlight">\(\texttt{resnet50}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># https://pytorch.org/vision/stable/models.html</span>

<span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
    <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">preprocessing_no_normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Notre rÃ©seau de neurones fait ses prÃ©dictions au travers dâ€™un vecteur de dimension 1000 oÃ¹ chaque dimension est la probabilitÃ© (ou un score) associÃ©e Ã  la classe de mÃªme indice. Afin de pouvoir associer un nom Ã  chacune de ces classes, nous construisons le dictionnaire ci-dessous <span class="math notranslate nohighlight">\(\texttt{classes}\_\texttt{to}\_\texttt{labels}\)</span>.</p>
<p>Le fichier est tÃ©lÃ©chargeable Ã  lâ€™adresse suivante :
<a class="reference external" href="https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/imagenet.json">imagenet.json</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># python 3</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>

<span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span>
    <span class="s2">&quot;https://raw.githubusercontent.com/maximiliense/lmiprp/main/&quot;</span>\
    <span class="s2">&quot;Travaux%20Pratiques/Machine</span><span class="si">%20Le</span><span class="s2">arning/Introduction/data/Adversarial/imagenet.json&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;imagenet.json&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;imagenet.json&#39;, &lt;http.client.HTTPMessage at 0x105785070&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;imagenet.json&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">classes_to_labels</span> <span class="o">=</span> <span class="p">{</span><span class="nb">int</span><span class="p">(</span><span class="n">k</span><span class="p">):</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="iii-la-donnee-a-attaquer">
<h2>III. La donnÃ©e Ã  attaquer<a class="headerlink" href="#iii-la-donnee-a-attaquer" title="Permalink to this headline">Â¶</a></h2>
<p>Lâ€™image est tÃ©lÃ©chargeable Ã  lâ€™adresse suivante :
<a class="reference external" href="https://raw.githubusercontent.com/maximiliense/lmiprp/main/Travaux%20Pratiques/Machine%20Learning/Introduction/data/Adversarial/lemon.jpeg">lemon.jpeg</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># python 3</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span>
    <span class="s2">&quot;https://raw.githubusercontent.com/maximiliense/lmiprp/main/&quot;</span>\
    <span class="s2">&quot;Travaux%20Pratiques/Machine</span><span class="si">%20Le</span><span class="s2">arning/Introduction/data/Adversarial/lemon.jpeg&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;lemon.jpeg&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;lemon.jpeg&#39;, &lt;http.client.HTTPMessage at 0x10d11dc40&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;lemon.jpeg&#39;</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">preprocessing_no_normalize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6_adversarial_14_0.png" src="../_images/6_adversarial_14_0.png" />
</div>
</div>
<p><span class="math notranslate nohighlight">\(\texttt{Pytorch}\)</span> prend en entrÃ©e des donnÃ©es dont la premiÃ¨re dimension reprÃ©sente celle du batch. Sâ€™il nâ€™y a quâ€™une donnÃ©e alors cette premiÃ¨re dimension doit toujours exister et vaut <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="c1"># we create a batch</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[batch size, channels, width, height]:&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[batch size, channels, width, height]: torch.Size([1, 3, 224, 224])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/maximilienservajean/.miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dim=1 indique qu&#39;on prÃ©dit image par image </span>
<span class="c1"># rappelez-vous que dim=0 correspond Ã  la dimension du batch</span>
<span class="n">true_index</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">probability</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">true_label</span> <span class="o">=</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">true_index</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">true_label</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">probability</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lemon : 0.9656189680099487
</pre></div>
</div>
</div>
</div>
<p>On observe que notre modÃ¨le prÃ©dit le bon label avec une trÃ¨s bonne probabilitÃ© !</p>
</div>
<div class="section" id="iv-une-premiere-attaque">
<h2>IV. Une premiÃ¨re attaque<a class="headerlink" href="#iv-une-premiere-attaque" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="quelques-rappels-d-optimisation">
<h3>Quelques rappels dâ€™optimisation<a class="headerlink" href="#quelques-rappels-d-optimisation" title="Permalink to this headline">Â¶</a></h3>
<p>Revenons Ã  lâ€™apprentissage de notre rÃ©seau de neurones. Notre objectif est de trouver une solution Ã  la minimisation suivante :</p>
<div class="math notranslate nohighlight">
\[\theta^\star=\text{argmin}_{\theta\in\mathbb{R}^p}\frac{1}{n}\sum_i \ell(h_\theta(x_i), y_i)=\text{argmin}_{\theta\in\mathbb{R}^p}\mathcal{L}(h_\theta, S_n).\]</div>
<p>Pour cela, nous exploitons le fait que <span class="math notranslate nohighlight">\(\mathcal{L}(h_\theta, S_n)\)</span> est diffÃ©rentiable presque partout en tant que fonction de <span class="math notranslate nohighlight">\(\theta\)</span> et cela afin dâ€™utiliser lâ€™algorithme de descente de gradient. Ce dernier rÃ©alise des pas successifs afin de se rapprocher toujours plus du minimum de notre fonction (ou du moins dâ€™un minimum local). Chacun des pas se construit de la maniÃ¨re suivante :</p>
<div class="math notranslate nohighlight">
\[\theta^{(t+1)}=\theta^{(t)}-\eta \nabla_\theta\mathcal{L}(h_{\theta^{(t)}}, S_n)\]</div>
<p>La valeur du gradient <span class="math notranslate nohighlight">\(\nabla_\theta\mathcal{L}(h_{\theta^{(t)}}, S_n)\)</span> est elle obtenue au travers de lâ€™algorithme de <em>backpropagration</em>. Le paramÃ¨tre <span class="math notranslate nohighlight">\(\eta&gt;0\)</span> est ce quâ€™on appelle le pas dâ€™apprentissage ou <em>learning rate</em> et permet de controler la stabilitÃ© de lâ€™optimisation mais a aussi un effet de rÃ©gularisation.</p>
</div>
<div class="section" id="construction-d-une-attaque-adversaire">
<h3>Construction dâ€™une attaque adversaire<a class="headerlink" href="#construction-d-une-attaque-adversaire" title="Permalink to this headline">Â¶</a></h3>
<p>Lâ€™idÃ©e dâ€™une attaque adversaire est de sâ€™appuyer sur le mÃªme raisonnement mais dans lâ€™espace des donnÃ©es <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>. Soit une donnÃ©e et son label <span class="math notranslate nohighlight">\((x, y)\)</span>. Notre objectif est ainsi de trouver une perturbation <span class="math notranslate nohighlight">\(\delta\in\mathbb{R}^d\)</span> telle que la nouvelle donnÃ©e <span class="math notranslate nohighlight">\(x+\delta\)</span> ne soit plus associÃ©e au label <span class="math notranslate nohighlight">\(y\)</span>. Rappelons que notre loss <span class="math notranslate nohighlight">\(\ell\)</span> est une mesure des performances de notre rÃ©seau de neurones pour la donnÃ©e <span class="math notranslate nohighlight">\((x, y)\)</span>. Ainsi, <span class="math notranslate nohighlight">\(\ell(h_\theta(x), y)\)</span> est dâ€™autant plus faible que notre modÃ¨le est bon et dâ€™autant plus forte que notre modÃ¨le est mauvais. Nous allons omettre lâ€™indice <span class="math notranslate nohighlight">\(\theta\)</span> de notre modÃ¨le puisquâ€™on le considÃ¨re maintenant comme une constante.</p>
<p>Lâ€™objectif dâ€™une attaque adversaire est donc de trouver un bruit <span class="math notranslate nohighlight">\(\delta\in\mathbb{R}^d\)</span> de telle maniÃ¨re Ã  ce que <span class="math notranslate nohighlight">\(\ell(h_\theta(x+\delta), y)\)</span> ait la plus grande valeur possible. Ainsi, on peut reformuler lâ€™attaque adversaire via le problÃ¨me de minimisation suivant :</p>
<div class="math notranslate nohighlight">
\[\delta^\star=\text{argmin}_{\delta\in\mathbb{R}^d}-\ell(h_{\theta}(x+\delta), y).\]</div>
<p>Observez quâ€™on minimise bien lâ€™opposÃ© de notre <em>loss</em> puisquâ€™on est en rÃ©alitÃ© intÃ©ressÃ© par une maximisation.</p>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>ComplÃ©tez lâ€™algorithme suivant permettant de construire notre attaque adversaire.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we initialize delta with 0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># we construct our optimizer and loss</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">delta</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-1</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># we construct the target</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">true_index</span><span class="p">])</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">60</span><span class="p">):</span>
    <span class="c1">############### COMPLETE HERE ###############</span>
    <span class="o">...</span>
    <span class="o">...</span>
    <span class="o">...</span>

    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">[</span><span class="si">%d</span><span class="s1">] loss: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="o">...</span>
    <span class="c1">#############################################</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="n">logit</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">True class probability:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">new_index</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">new_label</span> <span class="o">=</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">new_index</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;New class:&#39;</span><span class="p">,</span> <span class="n">new_label</span><span class="p">)</span>
</pre></div>
</div>
<p>Excellent, nous avons rÃ©ussi Ã  transformer notre image <span class="math notranslate nohighlight">\(x\)</span> via un bruit <span class="math notranslate nohighlight">\(\delta\)</span> de maniÃ¨re Ã  piÃ©ger notre modÃ¨le ! On observe de plus que la probabilitÃ© de la bonne classe est maintenant ridiculement faible et se retrouve trÃ¨s probablement parmi les classes les moins probables. Observons le rÃ©sultat de notre attaque adversaire.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image transformÃ©e $x+\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$ amplifiÃ©&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="mi">50</span><span class="o">*</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Oups ! Notre image ne ressemble plus Ã  rien. Le bruit ajoutÃ© est clairement visible. On pourrait mÃªme, si nous ne savions pas quâ€™il sâ€™agit de citrons, douter et penser quâ€™il sâ€™agit rÃ©ellement dâ€™orangesâ€¦</p>
</div>
</div>
<div class="section" id="v-un-deuxieme-essai">
<h2>V. Un deuxiÃ¨me essai<a class="headerlink" href="#v-un-deuxieme-essai" title="Permalink to this headline">Â¶</a></h2>
<p>La stratÃ©gie va Ãªtre de contraindre les dÃ©formations Ã  rester Ã  lâ€™intÃ©rieur dâ€™une boule dont nous pourrons contrÃ´ler le rayon et le fixer Ã  de petites valeurs :</p>
<div class="math notranslate nohighlight">
\[\mathcal{B}_\epsilon=\{x\in\mathbb{R}^d:\ \lVert x\rVert\leq \epsilon\}\]</div>
<p>ConsidÃ©rons le cas simple de la norme <span class="math notranslate nohighlight">\(\ell_\infty\)</span> :</p>
<div class="math notranslate nohighlight">
\[\lVert x\rVert_\infty=\text{max}_i|x_i|.\]</div>
<p>Contraindre un vecteur Ã  rester au sein dâ€™une boule de rayon <span class="math notranslate nohighlight">\(\epsilon\)</span> revient pour la norme <span class="math notranslate nohighlight">\(\ell_\infty\)</span> Ã  tronquer chaque coordonnÃ©e de maniÃ¨re Ã  ce que sa valeur absolue ne dÃ©passe pas <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>ComplÃ©tez lâ€™algorithme suivant permettant de construire notre attaque adversaire en contraignant le vecteur <span class="math notranslate nohighlight">\(\delta\)</span> Ã  rester dans une boule de rayon <span class="math notranslate nohighlight">\(\epsilon\)</span>. Utilisez la mÃ©thode <span class="math notranslate nohighlight">\(\texttt{delta.data.clamp}\_\texttt{(min, max)}\)</span> qui permet de tronquer la valeur.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we initialize delta with 0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">2.</span><span class="o">/</span><span class="mi">255</span>

<span class="c1"># we construct our optimizer and loss</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">delta</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-1</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># we construct the target</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">true_index</span><span class="p">])</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">60</span><span class="p">):</span>
    <span class="c1">############### COMPLETE HERE ###############</span>
    <span class="c1"># we construct the batch</span>
    <span class="o">...</span>
    <span class="o">...</span>

    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">[</span><span class="si">%d</span><span class="s1">] loss: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="o">...</span>
    <span class="o">...</span>
    <span class="c1">#############################################</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="n">logit</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">True class probability:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">new_index</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">new_label</span> <span class="o">=</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">new_index</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;New class:&#39;</span><span class="p">,</span> <span class="n">new_label</span><span class="p">)</span>
</pre></div>
</div>
<p>Affichons maintenant lâ€™image ainsi obtenue et le bruit qui lui est associÃ© :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image transformÃ©e $x+\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$ amplifiÃ©&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="mi">50</span><span class="o">*</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Câ€™est beaucoup mieux ! Cependant, ce nâ€™est pas en transformant des citrons en oranges que nous arriverons Ã  prendre le contrÃ´le de lâ€™univers ! Ce que nous souhaiterions, câ€™est tromper le rÃ©seau de neurones avec une classe qui nâ€™a RIEN Ã€ VOIR !!</p>
<p>Avant dâ€™aller plus loin, il convient de comprendre un peu mieux pourquoi le rÃ©seau de neurones a choisi la classe orange Ã  la place de citron. En minimisant lâ€™opposÃ© de lâ€™entropie croisÃ©e afin de trouver notre bruit <span class="math notranslate nohighlight">\(\delta\)</span> nous avons en rÃ©alitÃ© principalement rÃ©duit lâ€™amplitude des logits (i.e. le vecteur de score associÃ© Ã  chaque classe) pour la classe citronâ€¦ Celle-ci en perdant de lâ€™importance a laissÃ© la place Ã  la deuxiÃ¨me classe la plus probable pour cette image : les oranges.</p>
</div>
<div class="section" id="vi-une-attaque-un-petit-peu-plus-ciblee">
<h2>VI. Une attaque un petit peu plus ciblÃ©e ?<a class="headerlink" href="#vi-une-attaque-un-petit-peu-plus-ciblee" title="Permalink to this headline">Â¶</a></h2>
<p>Ce que nous voulons ici, câ€™est minimiser lâ€™importance dâ€™une classe <span class="math notranslate nohighlight">\(A\)</span> tout en augmentant lâ€™importance dâ€™une classe <span class="math notranslate nohighlight">\(B\)</span>. Le problÃ¨me qui nous intÃ©resse est donc :</p>
<div class="math notranslate nohighlight">
\[\delta^\star=\text{argmin}_{\delta\in\mathcal{B}_\epsilon}-\ell(h_{\theta}(x+\delta), y)+\ell(h_{\theta}(x+\delta), y_{\text{target}}),\]</div>
<p>oÃ¹ <span class="math notranslate nohighlight">\(y_{\text{target}}\)</span> est la classe que nous aimerions voir prÃ©dite. Choisissons maintenant la classe que nous visons :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target_index</span> <span class="o">=</span> <span class="mi">589</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Selected target:&#39;</span><span class="p">,</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">target_index</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Selected target: hand blower, blow dryer, blow drier, hair dryer, hair drier
</pre></div>
</div>
</div>
</div>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>ComplÃ©tez lâ€™algorithme suivant permettant de construire notre attaque adversaire en contraignant le vecteur <span class="math notranslate nohighlight">\(\delta\)</span> Ã  rester dans une boule de rayon <span class="math notranslate nohighlight">\(\epsilon\)</span> et en ciblant une classe objectif.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we initialize delta with 0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">2.</span><span class="o">/</span><span class="mi">255</span>

<span class="c1"># we initialize delta with 0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># we construct our optimizer and loss</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">delta</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># we construct the targets</span>
<span class="n">true_target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">true_index</span><span class="p">])</span>
<span class="n">target_target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">target_index</span><span class="p">])</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1">############### COMPLETE HERE ###############</span>
    <span class="o">...</span>
    <span class="o">...</span>
    <span class="o">...</span>

    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">[</span><span class="si">%d</span><span class="s1">] loss: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="o">...</span>
    <span class="o">...</span>
    <span class="c1">#############################################</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="n">logit</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">True class probability:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">new_index</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">new_label</span> <span class="o">=</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">new_index</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;New class:&#39;</span><span class="p">,</span> <span class="n">new_label</span><span class="p">)</span>
</pre></div>
</div>
<p>Victoire ! Observons maintenant lâ€™image bruitÃ©e ainsi que le bruit associÃ©.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image transformÃ©e $x+\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$ amplifiÃ©&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="mi">50</span><span class="o">*</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Nous avons ainsi rÃ©ussi Ã  choisir notre classe objectif et Ã  perturber notre rÃ©seau de neurones avec un bruit invisible Ã  lâ€™oeil nu.</p>
</div>
<div class="section" id="vii-la-methode-fast-sign">
<h2>VII. La mÃ©thode â€œfast-signâ€<a class="headerlink" href="#vii-la-methode-fast-sign" title="Permalink to this headline">Â¶</a></h2>
<p>Nous avons pu constater dans lâ€™exemple prÃ©cÃ©dent que la construction dâ€™un exemple adversaire demandait de minimiser une fonction de coÃ»t (i.e. lâ€™opposÃ© de ce quâ€™on souhaiterait minimiser en temps normal). Cette minimisation prend un certain temps pour une unique image.</p>
<p>Il existe une mÃ©thode alternative, moins performante en terme dâ€™attaque mais plus efficace computationnellement. Il sâ€™agit de la mÃ©thode â€œfast-signâ€. Rappelons que lâ€™objectif dâ€™une attaque adversaire est de construire le bruit suivant :</p>
<div class="math notranslate nohighlight">
\[\delta^\star=\text{argmin}_{\delta\in\mathcal{B}_\epsilon}-\ell(h_{\theta}(x+\delta), y).\]</div>
<p>Lâ€™intuition derriÃ¨re la mÃ©thode â€œfast-signâ€ est de supposer que la direction du gradient au cours de la minimisation ne changera pas trÃ¨s significativement. Ainsi, au lieu de rÃ©aliser plusieurs petits pas successifs, nous pouvons rÃ©aliser un grand pas dans la direction du gradient au point de dÃ©part. Notons que nous souhaitons que notre vecteur de bruit reste dans une boule en norme infini <span class="math notranslate nohighlight">\(\ell_\infty\)</span>. Cela revient Ã  dire que pour chaque coordonnÃ©e positive de notre gradient nous voulons que <span class="math notranslate nohighlight">\(\delta_j=-\epsilon\)</span> et pour chaque coordonnÃ©e nÃ©gative, nous voulons <span class="math notranslate nohighlight">\(\delta_j=\epsilon\)</span> (nous voulons aller le plus loin possible). Notre bruit devient donc :</p>
<div class="math notranslate nohighlight">
\[\hat{\delta}=-\epsilon\cdot\text{sign}(\nabla_\delta\ell(h_{\theta}(x+\delta), y)).\]</div>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>Ã€ vous dâ€™implÃ©menter la mÃ©thode <em>fast-sign</em> dans le cas dâ€™une attaque non ciblÃ©e.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we initialize delta with 0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">2.</span><span class="o">/</span><span class="mi">255</span>

<span class="c1"># we construct our loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># we construct the target</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">true_index</span><span class="p">])</span>

<span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="c1">############### COMPLETE HERE ###############</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
<span class="o">...</span>

<span class="n">delta</span> <span class="o">=</span> <span class="o">...</span>
<span class="c1">#############################################</span>

<span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">True class probability:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">new_index</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">new_label</span> <span class="o">=</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">new_index</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;New class:&#39;</span><span class="p">,</span> <span class="n">new_label</span><span class="p">)</span>
</pre></div>
</div>
<p>La performance de lâ€™attaque est grandement rÃ©duite, mais fonctionne ! Visualisons le rÃ©sultat :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image transformÃ©e $x+\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$ amplifiÃ©&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="mi">50</span><span class="o">*</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>Ã€ vous dâ€™implÃ©menter la mÃ©thode <em>fast-sign</em> dans le cas dâ€™une attaque ciblÃ©e.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we initialize delta with 0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">50.</span><span class="o">/</span><span class="mi">255</span>

<span class="n">target_index</span> <span class="o">=</span> <span class="mi">589</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Selected target:&#39;</span><span class="p">,</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">target_index</span><span class="p">])</span>

<span class="c1"># we construct our loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># we construct the target</span>
<span class="n">true_target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">true_index</span><span class="p">])</span>
<span class="n">target_target</span> <span class="o">=</span> <span class="n">LongTensor</span><span class="p">([</span><span class="n">target_index</span><span class="p">])</span>

<span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="c1">############### COMPLETE HERE ###############</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="c1">#############################################</span>



<span class="n">batch</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">True class probability:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="n">true_index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">new_index</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">new_label</span> <span class="o">=</span> <span class="n">classes_to_labels</span><span class="p">[</span><span class="n">new_index</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;New class:&#39;</span><span class="p">,</span> <span class="n">new_label</span><span class="p">)</span>
</pre></div>
</div>
<p>Il est probable que cette attaque ait Ã©chouÃ©. En effet, nous avons dÃ©jÃ  pu observer que dans le cas non ciblÃ©, notre attaque avait eu beaucoup moins dâ€™effet. Lâ€™effet sur les logits de la bonne classe est encore plus rÃ©duit lorsque lâ€™attaque devient ciblÃ©e. Pour que lâ€™attaque fonctionne, nous devons considÃ©rer un dÃ©placement plus significatif qui risque dâ€™Ãªtre visible Ã  lâ€™Ã©cranâ€¦</p>
<p>Testez plusieurs valeurs de <span class="math notranslate nohighlight">\(\epsilon\)</span> et observez le rÃ©sultat Ã  la fois en termes de prÃ©diction que visuellement avec le code ci-dessous.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image transformÃ©e $x+\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Le bruit $\delta$ amplifiÃ©&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="mi">50</span><span class="o">*</span><span class="n">delta</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="viii-devenir-robuste-aux-attaques-adversaires">
<h2>VIII. Devenir robuste aux attaques adversaires<a class="headerlink" href="#viii-devenir-robuste-aux-attaques-adversaires" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="introduction">
<h3>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">Â¶</a></h3>
<p>Comme indiquÃ© plus haut, lâ€™objectif de notre apprentissage est de trouver la solution :</p>
<div class="math notranslate nohighlight">
\[\theta^\star=\text{argmin}_{\theta\in\mathbb{R}^p}\frac{1}{n}\sum_i \ell(h_\theta(x_i), y_i)=\text{argmin}_{\theta\in\mathbb{R}^p}\mathcal{L}(h_\theta, S_n).\]</div>
<p>Câ€™est la paramÃ©trisation qui fait le moins dâ€™erreur (au sens de la loss <span class="math notranslate nohighlight">\(\ell\)</span>) sur notre jeu de donnÃ©es dâ€™apprentissage. Si le choix de notre classe de fonctions et de nos hyperparamÃ¨tres est bon, alors cette mÃªme paramÃ©trisation fonctionnera Ã©galement sur des donnÃ©es que nous nâ€™avons pas encore vu. Cependant, cette derniÃ¨re peut Ãªtre trÃ¨s sensible aux attaques adversaires comme nous avons pu le voir ci-dessus. Une solution consiste Ã  ne pas minimiser notre loss sur le jeu dâ€™apprentissage, mais notre loss dans le pire des cas :</p>
<div class="math notranslate nohighlight">
\[\theta^\star=\text{argmin}_{\theta\in\mathbb{R}^p}\frac{1}{n}\sum_i \text{max}_{\delta\in\mathcal{B}_\epsilon}\ell(h_\theta(x_i+\delta), y_i).\]</div>
<p>Rappelons nous que lâ€™algorithme de descente de gradient a besoin de ce dernier. Il nous faut donc calculer le gradient du maximum. Il se trouve que la solution est assez simple et revient Ã  calculer le gradient au point <span class="math notranslate nohighlight">\(\delta^\star\)</span>, solution du maximum :</p>
<div class="math notranslate nohighlight">
\[\nabla_\theta \text{max}_{\delta\in\mathcal{B}_\epsilon}\ell(h_\theta(x_i+\delta), y_i)=\nabla_\theta \ell(h_\theta(x_i+\delta^\star), y_i).\]</div>
</div>
<div class="section" id="construction-du-jeu-de-donnees">
<h3>Construction du jeu de donnÃ©es<a class="headerlink" href="#construction-du-jeu-de-donnees" title="Permalink to this headline">Â¶</a></h3>
<p>Nous utiliserons ici le jeu de donnÃ©es MNIST restreint aux chiffres 0 et 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_idx</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">&lt;=</span> <span class="mi">1</span>
<span class="n">mnist_train</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">mnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>

<span class="n">test_idx</span> <span class="o">=</span> <span class="n">mnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">&lt;=</span> <span class="mi">1</span>
<span class="n">mnist_test</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">mnist_test</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
<span class="n">mnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">mnist_test</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Visualisons la tÃªte de ces donnÃ©es.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6_adversarial_70_0.png" src="../_images/6_adversarial_70_0.png" />
</div>
</div>
</div>
<div class="section" id="un-cas-simple-le-modele-lineaire-rappels">
<h3>Un cas simple : le modÃ¨le linÃ©aire (Rappels)<a class="headerlink" href="#un-cas-simple-le-modele-lineaire-rappels" title="Permalink to this headline">Â¶</a></h3>
<p>La mÃ©thode â€œfast-signâ€ permet dâ€™obtenir efficacement un adversaire mais le rÃ©sultat nâ€™est quâ€™approximatif. Le cas du modÃ¨le linÃ©aire est intÃ©ressant car il est possible de trouver analytiquement les solutions de la maximisation (lâ€™adversaire). Comme nous lâ€™avons vu, un modÃ¨le linÃ©aire cherche Ã  sÃ©parer les classes par un ou plusieurs (multi-classes) hyperplans. Supposons que nous soyons dans <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>, un hyper-plan est dÃ©crit par un vecteur <span class="math notranslate nohighlight">\(\omega\in\mathbb{R}^d\)</span> et un scalaire <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span>. Le vecteur <span class="math notranslate nohighlight">\(\omega\)</span> donne lâ€™orientation de lâ€™hyperplan et <span class="math notranslate nohighlight">\(b\)</span> sa â€œdistanceâ€ Ã  â€œlâ€™origineâ€. Ainsi, un hyperplan est reprÃ©sentÃ© par lâ€™ensemble des points suivants :</p>
<div class="math notranslate nohighlight">
\[\{x\in\mathbb{R}^d:\ \langle \omega, x\rangle+b=0\}.\]</div>
<p>Au-delÃ  des points de lâ€™hyperplan, la quantitÃ© <span class="math notranslate nohighlight">\(\langle \omega, x,\rangle+b\)</span> est positive si on est dâ€™un cÃ´tÃ© de lâ€™hyperplan et nÃ©gative de lâ€™autre. ConsidÃ©rons le cas binaire et notons nos classes <span class="math notranslate nohighlight">\(\mathcal{Y}=\{-1,+1\}\)</span>. On souhaiterait que le cÃ´tÃ© nÃ©gatif de lâ€™hyperplan soit associÃ© aux donnÃ©es dont le label est -1 et de la mÃªme maniÃ¨re que le cÃ´tÃ© positif soit associÃ© aux donnÃ©es dont le label est +1.</p>
<p>Soit la fonction <span class="math notranslate nohighlight">\(\text{sign}(z)\)</span> qui retourne <span class="math notranslate nohighlight">\(+1\)</span> si <span class="math notranslate nohighlight">\(z&gt;0\)</span> et <span class="math notranslate nohighlight">\(-1\)</span> si <span class="math notranslate nohighlight">\(z\leq 0\)</span>. Le classifieur associÃ© Ã  notre hyperplan se construit donc de la maniÃ¨re suivante :</p>
<div class="math notranslate nohighlight">
\[h_\theta(x)=\text{sign}(\langle \omega, x\rangle + b),\ \theta=\{\omega\in\mathbb{R}^d,b\in\mathbb{R}\}.\]</div>
<p>Par simplicitÃ© de notation nous ommettrons Ã  partir de maintenant le biais <span class="math notranslate nohighlight">\(b\)</span>. Notons <span class="math notranslate nohighlight">\(g(x)=\langle \omega, x\rangle\)</span>. Il sâ€™agit dâ€™une fonction qui donne le score de classification. On remarque que la fonction <span class="math notranslate nohighlight">\(g\)</span> prÃ©dit le bon label si <span class="math notranslate nohighlight">\(g(x)\)</span> a le mÃªme signe que <span class="math notranslate nohighlight">\(y\)</span>. Dit autrement, nos prÃ©dictions sont correctes si <span class="math notranslate nohighlight">\(g(x)y&gt;0\)</span>.</p>
<p>Intuitivement, nous aimerions minimiser la loss 0/1 :</p>
<div class="math notranslate nohighlight">
\[\ell_{0/1}(z)=1\{z\leq 0\}.\]</div>
<p>Cette loss retourne <span class="math notranslate nohighlight">\(1\)</span> si <span class="math notranslate nohighlight">\(z\)</span> est nÃ©gatif et <span class="math notranslate nohighlight">\(0\)</span> sinon. AppliquÃ© Ã  notre modÃ¨le, cela donnÃ©e <span class="math notranslate nohighlight">\(\ell(g(x)y)\)</span> qui vaut <span class="math notranslate nohighlight">\(1\)</span> si <span class="math notranslate nohighlight">\(g(x)\)</span> nâ€™a pas le mÃªme signe que <span class="math notranslate nohighlight">\(y\)</span>. Câ€™est exactement ce quâ€™on veut. Cependant, cette loss nâ€™est pas diffÃ©rentiable en <span class="math notranslate nohighlight">\(0\)</span> et son gradient vaut <span class="math notranslate nohighlight">\(0\)</span> partout ailleurs. Cela nous complique la tÃ¢che lorsquâ€™on cherche Ã  optimiser notre modÃ¨le. Utilisons donc une loss possÃ©dant de meilleures propriÃ©tÃ©s mathÃ©matiques ainsi que certaines garanties pour la classification. Il sâ€™agit de la fonction de perte logistique :</p>
<div class="math notranslate nohighlight">
\[\ell(z)=\text{log}(1+e^{-z}).\]</div>
<p>On remarque que si <span class="math notranslate nohighlight">\(z\)</span> est trÃ¨s grand (<span class="math notranslate nohighlight">\(g\)</span> et <span class="math notranslate nohighlight">\(y\)</span> sont de mÃªme signe et le score prÃ©dit est grand) alors la fonction est trÃ¨s proche de <span class="math notranslate nohighlight">\(0\)</span>. Si <span class="math notranslate nohighlight">\(z\)</span> est trÃ¨s petit (<span class="math notranslate nohighlight">\(g\)</span> et <span class="math notranslate nohighlight">\(y\)</span> sont de signe diffÃ©rent et le score prÃ©dit est grand) alors la fonction diverge vers <span class="math notranslate nohighlight">\(+\infty\)</span>. Il sâ€™agit en rÃ©alitÃ© exactement de lâ€™entropie croisÃ©e composÃ©e avec la sigmoid que nous avons dÃ©jÃ  vu !</p>
<p>Finalement, le problÃ¨me Ã  rÃ©soudre dans le cadre dâ€™un classifieur linÃ©aire est le suivant :</p>
<div class="math notranslate nohighlight">
\[\theta^\star=\text{argmin}_{\theta=\omega\in\mathbb{R}^d}\frac{1}{n}\sum_i \ell(y\langle \omega, x\rangle).\]</div>
</div>
<div class="section" id="construction-du-modele">
<h3>Construction du modÃ¨le<a class="headerlink" href="#construction-du-modele" title="Permalink to this headline">Â¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearClassifier</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_input</span><span class="o">=</span><span class="mi">784</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">dim_input</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_input</span> <span class="o">=</span> <span class="n">dim_input</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># we flatten the image into a vector</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_input</span><span class="p">)</span>
        <span class="c1"># we apply our linear model</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="construction-de-la-loss">
<h3>Construction de la loss<a class="headerlink" href="#construction-de-la-loss" title="Permalink to this headline">Â¶</a></h3>
<p>La logistic loss nâ€™est rien dâ€™autre que la sigmoid composÃ©e avec lâ€™entropie croisÃ©e.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LogisticLoss</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># we flatten the image into a vector</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">-</span><span class="mi">1</span>  <span class="c1"># on met les labels entre -1 (anciennement 0) et 1</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">y</span><span class="o">*</span><span class="n">y_hat</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)))</span> <span class="o">/</span> <span class="n">batch_size</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="entrainement">
<h3>EntraÃ®nement<a class="headerlink" href="#entrainement" title="Permalink to this headline">Â¶</a></h3>
<p>Notez quâ€™il sâ€™agit encore et toujours ici de lâ€™entraÃ®nement classique oÃ¹ nous ne tenons pas compte des attaques adversaires.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO DÃ©commenter les prints de loss, etc.</span>
<span class="k">def</span> <span class="nf">train_and_plot</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="n">LogisticLoss</span><span class="p">()):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearClassifier</span><span class="p">()</span>
    <span class="c1"># model.cuda()</span>
    
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
    
    <span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="c1"># labels = labels.cuda()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">%</span> <span class="n">logs</span> <span class="o">==</span> <span class="n">logs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># print every 2000 mini-batches</span>
                <span class="c1"># TODO uncomment print(&#39;\r[%d, %5d] loss: %.3f&#39; % (e + 1, idx + 1, running_loss / logs), end=&quot;&quot;)</span>
                <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span> <span class="o">/</span> <span class="n">logs</span><span class="p">)</span>
                <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># on calcule le gradient</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># on fait un pas d&#39;optimisation</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">************* Training done! *************&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_history</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_and_plot</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>************* Training done! *************
</pre></div>
</div>
<img alt="../_images/6_adversarial_80_1.png" src="../_images/6_adversarial_80_1.png" />
</div>
</div>
</div>
<div class="section" id="test-des-performances">
<h3>Test des performances<a class="headerlink" href="#test-des-performances" title="Permalink to this headline">Â¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># on passe le modele en mode evaluation</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="c1">#images = images.cuda()</span>
            <span class="c1">#labels = labels.cuda()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">((</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># on remet le modele en mode apprentissage</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy du modele sur le jeu de test: </span><span class="si">%d</span><span class="s1"> </span><span class="si">%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy du modele sur le jeu de test: 99 %
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="construction-d-une-attaque-adversaire-dans-le-cas-du-modele-lineaire">
<h3>Construction dâ€™une attaque adversaire dans le cas du modÃ¨le linÃ©aire<a class="headerlink" href="#construction-d-une-attaque-adversaire-dans-le-cas-du-modele-lineaire" title="Permalink to this headline">Â¶</a></h3>
<p>En reprenant le problÃ¨me de lâ€™apprentissage robuste aux attaques adversaires tel que dÃ©fini ci-dessus, notre loss nâ€™est plus directement <span class="math notranslate nohighlight">\(\ell\)</span>. En effet, comme indiquÃ©, nous devons non pas Ã©valuer <span class="math notranslate nohighlight">\(\ell\)</span> en <span class="math notranslate nohighlight">\(x\)</span> mais dans un voisinage de <span class="math notranslate nohighlight">\(x\)</span> tel que le score de notre modÃ¨le y est le plus mauvais possible. La <em>loss</em> dans le pire des cas est dÃ©crite par lâ€™Ã©quation suivante :</p>
<div class="math notranslate nohighlight">
\[\text{max}_{\delta\in\mathcal{B}_\epsilon}\ell(y\langle\omega, x+\delta\rangle)=\text{max}_{\delta\in\mathcal{B}_\epsilon}\text{log}(1+e^{-y\langle\omega, x+\delta\rangle}).\]</div>
<p>Avant dâ€™aller plus loin, observons notre fonction de perte logistique.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;La fonction de perte logistique&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6_adversarial_86_0.png" src="../_images/6_adversarial_86_0.png" />
</div>
</div>
<p>Celle-ci semble monotone et dÃ©croissante (et convexe). Pour nous en convaincre, calculons la dÃ©rivÃ©e :</p>
<div class="math notranslate nohighlight">
\[\ell^\prime(z)=-\frac{1}{e^z+1}&lt;0,\]</div>
<p>qui est bien toujours nÃ©gative confirmant Ã  la fois la monotonie et la dÃ©croissance. Pour le fun, constatons que notre fonction est bien Ã©galement convexe :</p>
<div class="math notranslate nohighlight">
\[\ell^{\prime\prime}(z)=\frac{e^z}{(e^z+1)^2}&gt;0.\]</div>
<p>La fonction de perte logistique est donc mÃªme strictement convexe.</p>
<hr class="docutils" />
<p>En constatant ainsi que la fonction de perte logistique est monotone ET dÃ©croissante et en exploitant la linÃ©aritÃ© du produit scalaire, on obtient donc :</p>
<div class="math notranslate nohighlight">
\[\text{max}_{\delta\in\mathcal{B}_\epsilon}\ell(y\langle\omega, x+\delta\rangle)=\ell(\text{min}y\langle\omega, x+\delta\rangle)=\ell(y\langle\omega, x\rangle+\text{min}y\langle \omega, \delta\rangle).\]</div>
<p>Il nous reste donc Ã  chercher la solution du problÃ¨me de minimisation <span class="math notranslate nohighlight">\(\text{min}_{\delta\in\mathcal{B}_\epsilon}y\langle \omega, \delta\rangle\)</span>
qui, heureusement pour nous, est convexe avec un domaine de dÃ©finition compact. Il y a donc un minimum local qui est le minimum global. La norme <span class="math notranslate nohighlight">\(\ell_\infty\)</span> nous permet de considÃ©rer chaque dimension sÃ©parÃ©ment (le problÃ¨me est sÃ©parable). Nous voulons donc calculer :</p>
<div class="math notranslate nohighlight">
\[\text{min}_{|\delta_j|\leq \epsilon}y\langle \omega_j, \delta_j\rangle.\]</div>
<p>Si <span class="math notranslate nohighlight">\(\omega_j=0\)</span>, toutes les solutions se valent. Si <span class="math notranslate nohighlight">\(\omega_j\neq 0\)</span> et <span class="math notranslate nohighlight">\(y=-1\)</span>, alors le minimum est atteint lorsque <span class="math notranslate nohighlight">\(\delta_j=\epsilon\cdot\text{sign}(\omega_j)\)</span>. Enfin, si <span class="math notranslate nohighlight">\(y=1\)</span>, alors le minimum est atteint lorsque <span class="math notranslate nohighlight">\(\delta_j=-\epsilon\cdot\text{sign}(\omega_j)\)</span>. De maniÃ¨re gÃ©nÃ©rale, nous avons :</p>
<div class="math notranslate nohighlight">
\[\delta^\star=-y \epsilon\cdot\text{sign}(\omega)\]</div>
<p>Nous avons ainsi :</p>
<div class="math notranslate nohighlight">
\[\text{min}_{\delta\in\mathcal{B}_\epsilon}y\langle \omega, \delta\rangle=y\langle\omega, -y \epsilon\cdot\text{sign}(\omega)\rangle=-y^2\epsilon\langle \omega, \text{sign}(\omega)\rangle=-\epsilon\lVert\omega\rVert_1.\]</div>
<p>Un apprentissage robuste aux attaques adversaires minimise donc la loss :</p>
<div class="math notranslate nohighlight">
\[\text{max}_{\delta\in\mathcal{B}_\epsilon}\text{log}(1+e^{-y\langle\omega, x\rangle+\epsilon\lVert\omega\rVert_1})=\ell(y\langle\omega, x\rangle-\epsilon\lVert\omega\rVert_1)\]</div>
<p>On retombe quasiment sur un problÃ¨me dâ€™optimisation avec une pÃ©nalitÃ© <span class="math notranslate nohighlight">\(\ell_1\)</span>. On cherche le vecteur <span class="math notranslate nohighlight">\(\omega\)</span> qui maximise les bonnes prÃ©dictions mais qui en mÃªme temps possÃ¨de une norme <span class="math notranslate nohighlight">\(\ell_1\)</span> faible.</p>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>En vous appuyant sur les â€œrÃ©sultats thÃ©oriquesâ€ prÃ©cÃ©dent, proposez un code permettant de gÃ©nÃ©rer un bruit adversaire.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_adversarial_noise</span><span class="p">(</span><span class="n">image_and_label</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">imagesize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">image_and_label</span>
    <span class="n">label</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="n">label</span>
    <span class="c1">############### COMPLETE HERE ###############</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1">#############################################</span>
    
    <span class="k">return</span> <span class="n">noise</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_images_and_noise</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image $x$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre image transformÃ©e $x + \delta^\star$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">((</span><span class="n">image</span><span class="o">+</span><span class="n">noise</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Notre bruit $\delta^\star$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">detach</span><span class="p">()))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">generate_adversarial_noise</span><span class="p">((</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">model</span><span class="p">)</span>

<span class="n">plot_images_and_noise</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">noise</span><span class="p">)</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PrÃ©diction:&#39;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">noise</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PrÃ©diction avec du bruit:&#39;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="apprentissage-robuste-aux-attaques-adversaires">
<h3>Apprentissage robuste aux attaques adversaires<a class="headerlink" href="#apprentissage-robuste-aux-attaques-adversaires" title="Permalink to this headline">Â¶</a></h3>
<p>Un apprentissage robuste aux exemples adversaires cherche tout simplement Ã  minimiser le pire des scÃ©nariosÂ :</p>
<div class="math notranslate nohighlight">
\[\omega^\star=\text{argmin}_{\omega\in\mathbb{R}^d}\frac{1}{n}\sum_i\text{max}_{\delta\in\mathcal{B}_\epsilon}\ell(y_i\langle\omega, x_i +\delta\rangle)=\text{argmin}_{\omega\in\mathbb{R}^d}\frac{1}{n}\sum_i\ell(y_i\langle\omega, x_i\rangle-\epsilon\lVert\omega\rVert_1).\]</div>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>En vous appuyant sur les â€œrÃ©sultats thÃ©oriquesâ€ prÃ©cÃ©dent, proposez un code permettant de construire une loss robuste aux attaques adversaires.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RobustLogisticLoss</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RobustLogisticLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># we flatten the image into a vector</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="c1">############### COMPLETE HERE ###############</span>
        <span class="n">z</span> <span class="o">=</span> <span class="o">......</span>
        <span class="c1">#############################################</span>
        
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)))</span> <span class="o">/</span> <span class="n">batch_size</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="n">train_and_plot</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="n">RobustLogisticLoss</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">generate_adversarial_noise</span><span class="p">((</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">model</span><span class="p">)</span>

<span class="n">plot_images_and_noise</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">noise</span><span class="p">)</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PrÃ©diction:&#39;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">noise</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PrÃ©diction avec du bruit:&#39;</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
<p>Il se trouve que les modÃ¨les linÃ©aires sont dÃ©jÃ  beaucoup plus robustes aux attaques adversaires que les rÃ©seaux de neurones. Malheureusement, les choses sont plus compliquÃ©es pour ces derniÃ¨res puisque il nâ€™y a dÃ©jÃ  pas de solution analytiqueâ€¦</p>
</div>
</div>
<div class="section" id="en-resume">
<h2>En rÃ©sumÃ©<a class="headerlink" href="#en-resume" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>Nous avons vu comment formaliser la notion dâ€™attaque adversaire via un problÃ¨me dâ€™optimisation sous contrainte :</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\delta^\star=\text{argmin}_{\delta\in\mathcal{B}_\epsilon}-\ell(h_{\theta}(x+\delta), y),\]</div>
<ul class="simple">
<li><p>Nous avons vu une maniÃ¨re de cibler lâ€™attaque afin de â€œforcerâ€ notre modÃ¨le Ã  prÃ©dire une classe particuliÃ¨re :</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\delta^\star=\text{argmin}_{\delta\in\mathcal{B}_\epsilon}-\ell(h_{\theta}(x+\delta), y)+\ell(h_{\theta}(x+\delta), y_{\text{target}}),\]</div>
<ul class="simple">
<li><p>Nous avons contournÃ© le processus dâ€™optimisation via une heuristique, la mÃ©thode <em>fast-sign</em> :</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\hat{\delta}=-\epsilon\cdot\text{sign}(\nabla_\delta\ell(h_{\theta}(x+\delta), y)),\]</div>
<ul class="simple">
<li><p>Nous avons Ã©galement formalisÃ© le problÃ¨me dâ€™apprentissage robuste aux attaques :</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\theta^\star=\text{argmin}_{\theta\in\mathbb{R}^p}\frac{1}{n}\sum_i \text{max}_{\delta\in\mathcal{B}_\epsilon}\ell(h_\theta(x_i+\delta), y_i),\]</div>
<ul class="simple">
<li><p>Et avons rÃ©solu la maximisation dans le cadre dâ€™un classifieur linÃ©aire :</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\omega^\star=\text{argmin}_{\omega\in\mathbb{R}^d}\frac{1}{n}\sum_i\ell(y_i\langle\omega, x_i\rangle-\epsilon\lVert\omega\rVert_1).\]</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./6_deeplearning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="5_transfer_multitask.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><em>Transfer learning</em> et apprentissage multi-tÃ¢ches â˜•ï¸â˜•ï¸</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../7_unsupervised/0_propos_liminaire.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lâ€™apprentissage non-supervisÃ©</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Servajean, Leveau & Chailan<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>