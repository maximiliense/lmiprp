*deep learning*
=======================

Lors des séquences précédentes, nous avons pu voir que l'optimisation était une étape clé du *pipeline* en *machine learning*. Cette optimisation nécessitait souvent le calcul du gradient de notre fonction de coût. Ce gradient, même dans les cas simples est compliqué à calculer. La force des *frameworks* de *deep learning* est de s'appuyer sur la différentiation automatique. Le gradient n'est pas à fournir par l'utilisateur, mais calculé directement par le *framework*. C'est ce que nous allons voir ici. au travers de deux séquences&nbsp;:

*  **La différentiation automatique et un début de *deep learning*** - Cette séquence abordera la différentiation automatique via le *framework* $\texttt{pytorch}$. Nous reverrons l'algorithme de descente de gradient via ce dernier et nous implémenterons un premier réseau de neurones.
*  **Filtres et espace de représentation des réseaux de neurones** - Cette séquence s'écarte un peu de la différentiation automatique et cherchera à étudier les différents paramètres d'un réseau de neurones. Nous visualiserons notamment les filtres convolutifs, l'espace de représentation appris par notre modèle, etc.
*  **Calibration des probabilités et quelques notions** - Nos modèles peuvent être vus comme des estimateurs de la probabilité conditionnelle des classes après avoir vu une donnée d'entrée. On note cette probabilité conditionnelle $\hat{\eta}(x)$. Malheureusement, le modèle qui minimise notre *loss* s'avère souvent un bon modèle prédictif en classification, mais un piètre estimateur de la probabilité. Hors cette dernière peut s'avérer fondamentale lorsqu'on veut par exemple seuiller (cf. le cours sur la prédiction d'ensembles). La notion de calibration est là pour corriger/limiter ces effets. Nous aborderons également quelques notions connexes.

Cependant, notre problème est souvent mal posé. Cela s'observer soit par une situation de sur-apprentissage (les performances de notre modèle ne se maintiennent pas sur de nouvelles données) voire par une problème d'optimisation lui-même mal posé. La régularisation est une technique qui, en injectant de l'information dans le problème, permet de stabiliser son optimisation ou encore de limiter les effets de surapprentissage. Ce chapitre contient également&nbsp;:

*  **Régularisation en *deep learning*** - Cette séquence se concentrera sur différentes techniques de régularisation utilisées en *deep learning* nous verrons notamment que celle-ci peut être explicitement formulée ou implite par exemple comme effet de bord du processus d'optimisation.
*  ***Transfer learning* et apprentissage multi-tâches** - Cette séquence abordera deux techniques qui cherchent à exploiter l'information contenues dans d'autres jeu de données et d'autres tâches afin d'améliorer les performance sur une tâche fixée. Il s'agit du *transfer learning* qui initialise les poids d'un réseau en les apprenants sur une tâche pour laquelle nous disposons de beaucoup de données et de l'apprentissage multi-tâches où nous cherchons simultanément à résoudre plusieurs tâches. Ces deux approches ont des effets régularisants.
*  **Les attaques adversaires** - Les réseaux de neurones ont une certaine tendance à être sensible à certaines perturbations des données. Les attaques adversaires exploitent cette sensibilité afin de tromper le réseau. Nous verrons comment cela se fait ainsi que comment régulariser l'apprentissage afin d'y devenir robuste.
