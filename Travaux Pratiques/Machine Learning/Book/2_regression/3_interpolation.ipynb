{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Interpolation \u2615\ufe0f\u2615\ufe0f\n", "\n", "**<span style='color:blue'> Objectifs de la s\u00e9quence</span>** ", "* \u00catre sensibilis\u00e9 \n", "    * \u00c0 la notion d'interpolation,\n", "    * Au fait qu'on fait des maths **sur** un ordinateur avec son lot d'approximations num\u00e9riques.\n", "\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## I. Introduction \n", "\n", "Ce TP est une ouverture et n'est pas du *machine learning* \u00e0 proprement parler. Nous allons cependant mettre en avant un ensemble de ph\u00e9nom\u00e8nes tr\u00e8s pertinents en *machine learning*. Soit un espace de d\u00e9part, not\u00e9 $\\mathcal{X}\\subseteq\\mathbb{R}^d$, $d>0$ et un espace d'arriv\u00e9e $\\mathcal{Y}\\subseteq\\mathbb{R}$. Supposons qu'il existe une fonction $f^\\star:\\mathcal{X}\\rightarrow\\mathcal{Y}$ inconnue mais qu'il soit possible de collecter un jeu de donn\u00e9es de la forme $S_n=\\{(x_i, y_i=f^\\star(x_i))\\}_{i\\leq n}$. L'objectif de l'interpolation va \u00eatre de trouver une fonction $\\hat{f}:\\mathcal{X}\\rightarrow\\mathcal{Y}$ telle que $\\forall x_i, y_i\\in S_n$, nous ayons $\\hat{f}(x_i)=y_i=f^\\star(x_i)$. De plus, on esp\u00e8re qu'en faisant cela, la fonction $\\hat{f}$ ne soit pas tr\u00e8s loin de la fonction $f^\\star$ sur les parties de son domaine entre les points de notre jeu de donn\u00e9es."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["hide-input"]}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "x = np.linspace(-1, 1, 5001)\n", "y = np.sin(np.pi*x)\n", "\n", "plt.figure(figsize=(14, 8))\n", "plt.plot(x, y)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Construisons notre jeu de donn\u00e9es en \u00e9chantilonnant quelques points dans $\\mathcal{X}$."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["hide-input"]}, "outputs": [], "source": ["n = 10\n", "X = np.random.uniform(-1, 1, n)\n", "S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "\n", "plt.figure(figsize=(14, 8))\n", "plt.plot(x, y)\n", "plt.scatter(S[:, 0], S[:, 1])\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La courbe bleue est la courbe qu'on recherche. Les points bleus sont les seules informations visibles auxquelles nous avons acc\u00e8s. L'objectif est de s'appuyer sur ces informations pour construire les meilleures fonctions possibles. Cela peut se faire de beaucoup de mani\u00e8res diff\u00e9rentes et nous allons en \u00e9tudier quelques unes."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## II. Quelques exemples simples d'interpolations"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### A. Interpolation constante par morceau (interpolateur d'ordre $0$)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["L'id\u00e9e est de consid\u00e9rer que la valeur de notre fonction est celle du point le plus proche : c'est le 1NN !"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "Proposez un code qui retourne pour chaque valeur du vecteur x, le label associ\u00e9 au point le plus proche de notre jeu de donn\u00e9es $S$.\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def f_piece_wise_constant(x):\n", "    if type(x) is not np.ndarray:\n", "        x = np.array([x])\n", "    y = np.zeros_like(x)\n", "    ####### Complete this part ######## or die ####################    \n", "    ...\n", "    ...\n", "    return ...\n", "    ###############################################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(14, 8))\n", "plt.plot(x, y)\n", "plt.scatter(S[:, 0], S[:, 1])\n", "plt.step(x, f_piece_wise_constant(x), color='red')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00c9tudions visuellement la convergence de cette m\u00e9thode."]}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(14, 15))\n", "for i, n in enumerate([5, 10, 50]):\n", "    X = np.random.uniform(-1, 1, n)\n", "    S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "    plt.subplot(3, 1, i+1)\n", "    plt.plot(x, y)\n", "    plt.scatter(S[:, 0], S[:, 1])\n", "    plt.step(x, f_piece_wise_constant(x), color='red')\n", "    plt.title('Size:' + str(n))\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["On voit que les endroits o\u00f9 l'interpolation nous g\u00eane correspondent aux angles de nos palliers. Nous pouvons faire mieux via une interpolation lin\u00e9aire."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### B. Interpolation lin\u00e9aire (interpolateur d'ordre $1$)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Au lieu de n'exploiter que l'information du point le plus proche, l'id\u00e9e est d'ici d'interpoler lin\u00e9airement entre les deux points qui encadrent notre valeur. Notons $(x_l, y_l)\\in S_n$ le point qui encadre par la gauche notre nouveau $x$ et $(x_r, y_r)\\in S_n$ celui de droite. Une interpolation lin\u00e9aire se calcule tout simplement de la mani\u00e8re suivante :\n", "\n", "$$q(x)=y_r+(y_l-y_r)\\frac{x-x_r}{x_l-x_r},\\ x\\in[x_l, x_r].$$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Proposez un code qui retourne pour chaque valeur du vecteur x, son interpolation lin\u00e9aire s'il est bien encadr\u00e9 et $\\texttt{None}$ sinon.**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def f_linear(x):\n", "    if type(x) is not np.ndarray:\n", "        x = np.array([x])\n", "    y = np.zeros_like(x)\n", "    ####### Complete this part ######## or die ####################\n", "    ...\n", "    ...\n", "    return ...\n", "    ###############################################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(14, 15))\n", "for i, n in enumerate([5, 10, 50]):\n", "    X = np.random.uniform(-1, 1, n)\n", "    S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "    plt.subplot(3, 1, i+1)\n", "    plt.plot(x, y)\n", "    plt.scatter(S[:, 0], S[:, 1])\n", "    plt.plot(x, f_linear(x), color='red')\n", "    plt.title('Size:' + str(n))\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## III. Interpolation polynomiale"]}, {"cell_type": "markdown", "metadata": {}, "source": ["L'interpolation lin\u00e9aire donne de bon r\u00e9sultats sauf qu'en pratique les fonctions qu'on cherche \u00e0 estimer sont plus \"lisses\". L'id\u00e9e va \u00eatre de contourner cela par une interpolation polynomiale.  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### A. Polynome interpolateur de Lagrange"]}, {"cell_type": "markdown", "metadata": {}, "source": ["On souhaite construire un polynome interpolateur d'une fonction dont nous poss\u00e9dons des points de mesure $\\mathcal{S} = \\{(x_1, y_1), \\dots (x_n, y_n)\\}$ et o\u00f9 on suppose les $x_i$ deux \u00e0 deux distincts. Pour cela, nous allons construire une solution de ce type&nbsp;:\n", "\n", "$$L(x) = \\sum_{j=1}^{N}y_jL_j(x)$$\n", "             \n", "C'est-\u00e0-dire une combinaison de polynomes $L_j$ dont on souhaitera qu'ils aient la propri\u00e9t\u00e9 suivante&nbsp;:\n", "\n", "$$L_j(x) = \\begin{cases} \n", "      1 & x = x_j \\\\\n", "      0 & x \\neq x_j, \\exists l\\leq n, x=x_l\n", "\\end{cases}$$\n", "\n", "\n", "Chaque polynome s'annule exactement en tous les points d'interpolation sauf un. La somme passe donc exactement par tous les points. On aura donc $L(x_i)=y_i$ $\\forall (x_i, y_i) \\in \\mathcal{S}$."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Premi\u00e8re tentative naive&nbsp;:**\n", "\n", "On peut d\u00e9finir les $L_j$, polyn\u00f4mes interm\u00e9diaires dont l'expression est donn\u00e9e par&nbsp;:\n", "\\begin{equation*}\n", "    L_j(x) = \\prod\\limits_{\\substack{k=1 \\\\ k\\neq j}}^N x - x_k\n", "\\end{equation*}\n", "on aurait donc $\\forall i \\neq j, L_j(x_i) = 0$. Nous avons bien $0$ lorsque $i\\neq j$, mais nous \u00e9chouons \u00e0 obtenir $1$ lors que $i=j$&nbsp;:\n", "\\begin{equation*}\n", "    L_j(x_j) = \\prod\\limits_{\\substack{k=1 \\\\ k\\neq j}}^N x_j  - x_k \\neq 1\n", "\\end{equation*}\n", "Nous pouvons r\u00e9soudre cela en normalisant notre premi\u00e8re tentative par ce terme pour qu'on obtienne bien ce qu'on veut&nbsp;:\n", "\\begin{equation*}\n", "    L_j(x) =  \\frac{\\prod\\limits_{\\substack{k=1 \\\\ k\\neq j}}^Nx - x_k}{\\prod\\limits_{\\substack{k=1 \\\\ k\\neq j}}^Nx_j - x_k} = \\prod\\limits_{\\substack{k=1 \\\\ k\\neq j}}^N\\frac{x - x_k}{x_j - x_k}\n", "\\end{equation*}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous obtenons donc&nbsp;:\n", "\\begin{equation*}\n", "    L(x) = \\sum_{j=1}^{N}y_j\\prod\\limits_{\\substack{k=1 \\\\ k\\neq j}}^N  \\frac{x - x_k}{x_j - x_k}\n", "\\end{equation*}\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "**Montrez que le polyn\u00f4me r\u00e9sultant est bien de degr\u00e9 $N-1$.**\n", "\n\n ----", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice compl\u00e9mentaire</span>** ", "\n", "**D\u00e9montrez que le polyn\u00f4me est bien un polyn\u00f4me interpolateur et passe bien par l'ensemble des points de notre jeu de donn\u00e9es.**\n", "\n", "\n\n ----", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Proposez un code qui r\u00e9alise l'interpolation de Lagrange et retourne pour chacune des valeurs de $x$ son interpolation.**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def f_polynomial(x):\n", "    ####### Complete this part ######## or die ####################\n", "    ...\n", "    ...\n", "    return ...\n", "    ###############################################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(14, 15))\n", "for i, n in enumerate([5, 10, 30, 60]):\n", "    X = np.random.uniform(-1, 1, n)\n", "    S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "    plt.subplot(4, 1, i+1)\n", "    plt.plot(x, y)\n", "    plt.scatter(S[:, 0], S[:, 1])\n", "    plt.plot(x, f_polynomial(x), color='red')\n", "    plt.ylim(-1, 1)\n", "    plt.title('Size:' + str(n))\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["On remarque que notre polyn\u00f4me en s'\u00e9cartant des points de notre jeu de donn\u00e9es et notamment sur les bords, devient tr\u00e8s instable. Et cela est d'autant plus vrai que nous avons augment\u00e9 le nombre de points (ce qui peut sembler contre-intuitif)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### B. Interpolation polynomiale par r\u00e9gression (non) lin\u00e9aire"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous allons voir dans cette section qu'il est aussi possible de produire des fonctions interpolatrices \u00e0 partir du formalisme des moindres carr\u00e9s que nous avons vu pr\u00e9c\u00e9demment. En effet, comme nous l'avons vu dans le TP sur la regression lin\u00e9aire, il est possible de repr\u00e9senter n'importe quel polyn\u00f4me de la fa\u00e7on suivante&nbsp;:\n", "\n", "\n", "$$L(x)  = \\beta_0 + \\sum_{i=1}^p \\beta_i x^i = \\langle \\boldsymbol{\\beta},  \\phi_p(x) \\rangle$$\n", "\n", "avec&nbsp;:\n", "\n", "\n", "$$\\begin{aligned}\\phi_p(x) =  \\begin{bmatrix}\n", "           1 \\\\\n", "           x\\\\\n", "           \\vdots\\\\\n", "           x^p\n", "         \\end{bmatrix}\\end{aligned}$$\n", "\n", "\n", "Apr\u00e8s avoir proc\u00e9d\u00e9 \u00e0 ce changement de variable sur les tous les \u00e9chantillons, nous pouvons d\u00e9finir la nouvelle matrice des donn\u00e9es comme&nbsp;:\n", "\n", "$$\\begin{aligned}\\boldsymbol{\\Phi}_p(\\boldsymbol{X}) = \n", "\\begin{pmatrix} \n", "1 & x_{1} & x_{1}^2 & \\dots & x_1^p \\\\\n", ". & . & \\dots & .\\\\\n", "1 & x_{j}  & x_{j}^2 & \\dots & x_j^p\\\\\n", ". & . & \\dots & .\\\\\n", "1 & x_{N}  & x_{N}^2 & \\dots & x_N^p\n", "\\end{pmatrix}\\end{aligned}$$\n", "\n", "Et notre polyn\u00f4me se construit de la mani\u00e8re suivante&nbsp;:\n", "\n", "$$\\begin{aligned}\\boldsymbol{L(X)} = \\Big[\\boldsymbol{\\Phi}_p(\\boldsymbol{X}) \\Big]\n", "\\boldsymbol{\\beta}  = \n", "\\begin{pmatrix} \n", "\\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{1}^2 + \\dots + \\beta_p x_1^p \\\\\n", "\\dots \\\\\n", "\\beta_0 + \\beta_1 x_{j} + \\beta_2 x_{j}^2 + \\dots + \\beta_p x_j^p\\\\\n", "\\dots\\\\\n", "\\beta_0 + \\beta_1 x_{N}  + \\beta_2 x_{N}^2 + \\dots + \\beta_p x_N^p\n", "\\end{pmatrix},\\ \\boldsymbol{\\beta}\\in\\mathbb{R}^{p+1}\\text{ et }\\boldsymbol{L(X)}\\in\\mathbb{R}^N.\n", "\\end{aligned}$$\n", "\n", "Nous avons donc donc un syst\u00e8me lin\u00e9aire de $p+1$ \u00e9quations et $N$ inconnues. Il est ainsi possible d'approximer une fonction non lin\u00e9aire qui minimise les erreurs au carr\u00e9 entre les valeurs du polyn\u00f4me \u00e9valu\u00e9s avec les vraies valeurs de notre jeu de donn\u00e9es. Nous avons transform\u00e9 noter probl\u00e8me de regression lin\u00e9aire en un probleme de regression polyn\u00f4miale (non lin\u00e9aire). \n", "\n", "**<span style='color:blue'> Question 1</span>** ", "**Rappellez l'expression de la solution des equations normales des moindres carr\u00e9s et adaptez-la \u00e0 ce changement de variable pour trouver les coefficients du polyn\u00f4me qui minimise les moindres carr\u00e9s.**\n", "\n\n ----", "\n", "\n", "\n", "**<span style='color:blue'> Question 2</span>** ", "**Pour quelle(s) valeur(s) de $p$ (ordre du polyn\u00f4me) nous avons une solution interpolatrice de mani\u00e8re garantie ? Rappellez l'origine des difficult\u00e9s sur la stabilit\u00e9 de la solution obtenues par la m\u00e9thodes des EQN ?**\n", "\n\n ----", "\n", "\n", "**<span style='color:orange'> Remarque</span>** ", "\n", "Il est int\u00e9ressant de montrer que la solution des EQN obtenue \u00e0 partir de la matrice  $\\boldsymbol{\\Phi_{N-1}(X)}$ (matrice carr\u00e9 $N=p+1$ aussi appell\u00e9e la matrice de *Vandermonde*) correspond en fait exactement aux coefficients du polyn\u00f4me interpolateur de Lagrange qui en est l'unique solution (si $x_j\\neq x_i\\forall j\\neq i$)&nbsp;! \n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice </span>** ", "**Proposez un code qui r\u00e9alise l'interpolation de Lagrange par la m\u00e9thode des EQN des moindres carr\u00e9s et qui retourne pour chacune des valeurs de $x$ son interpolation. (On pourra reprendre le code du TP sur la regresion lin\u00e9aire).**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["class Polynomial(object):\n", "    def __init__(self, deg):\n", "        self.deg = deg\n", "\n", "    def _transform(self, X):\n", "        # here we transform the input into a polynomial\n", "        t = []\n", "        X = X.reshape((X.shape[0], 1)) if len(X.shape) == 1 else X\n", "        for i in range(0, self.deg+1):\n", "            t.append(X**i)\n", "        return np.concatenate(t, axis=1)\n", "    \n", "    def fit(self, X, y):\n", "        ####### Complete this part ######## or die ####################\n", "        X_transformed = self._transform(X)\n", "        ...\n", "        ###############################################################\n", "        \n", "    def predict(self, X):\n", "        if self.beta is None:\n", "            print('You must fit the model first')\n", "        else:\n", "            X_transformed = self._transform(X)\n", "            return np.dot(X_transformed, self.beta)\n", "    def score(self, X, y):\n", "        prediction = self.predict(X)\n", "        errors = (prediction - y) **2\n", "        return errors.sum()/errors.shape[0]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["import matplotlib\n", "\n", "plt.figure(figsize=(14, 15))\n", "for i, n in enumerate([5, 10, 30, 60]):\n", "    X = np.random.uniform(-1, 1, n)\n", "    S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "    model = Polynomial(n-1)\n", "    model.fit(S[:, 0], S[:, 1])\n", "    plt.subplot(4, 1, i+1)\n", "    plt.plot(x, y)\n", "    plt.scatter(S[:, 0], S[:, 1])\n", "    plt.plot(x, model.predict(x), color='red', label='EQN')\n", "    plt.plot(x, f_polynomial(x), \"--\", color='green', label='Lagrange')\n", "    plt.ylim(-1, 1)\n", "    plt.title('Size:' + str(n))\n", "    plt.legend()\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "Dans votre r\u00e9ponse pour l'exercice pr\u00e9c\u00e9dent, jouez avec $\\texttt{pinv}$ et $\\texttt{inv}$. Comprenez-vous pourquoi la solution n'est pas identique ?\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## IV. Splines"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comme nous l'avons vu, il existe parfois certains effets pathologiques de l'interpolation polynomiale o\u00f9 la fonction peut avoir des variations arbitrairement hautes entre les points de contr\u00f4le. On aimerait d'une certaine mani\u00e8re \u00e9viter ces comportements de sorte \u00e0 ce que la fonction prenne des valeurs raisonnables entre les points. Nous allons voir ici une autre fa\u00e7on de construire une solution interpolatrice de notre jeu de donn\u00e9e.\n", "\n", "L'interpolation par *spline* consiste \u00e0 trouver des approximations locales de notre fonction. Plus formellement, il s'agit de trouver pour chaque intervalle $[x_i, x_{i+1}]$ un polyn\u00f4me $P_i(x)$ qui satisfait certaines propri\u00e9t\u00e9s. On aura ainsi une interpolation $S(x)$ de la fonction qui nous int\u00e9resse par&nbsp;:\n", "\n", "\n", "$$\\begin{aligned}S(x) =  \n", "\\begin{cases} \n", "P_1(x) & x_1\\leq x \\leq x_2 \\\\\n", "P_2(x) & x_2\\leq x \\leq x_3 \\\\\n", "\\dots \\\\\n", "P_{N-1}(x) & x_{N-1}\\leq x \\leq x_N \\\\\n", "\\end{cases}\\end{aligned}$$\n", "\n", "o\u00f9 chaque polyn\u00f4me interm\u00e9diaire $P_i$ d'ordre $p$ peut s'\u00e9crire de la mani\u00e8re suivante&nbsp;:\n", "\n", "$$P_i(x) = a_i^{(0)} + a_i^{(1)}(x - x_i) + \\frac{a_i^{(2)}}{2}(x - x_i)^2 + \\ldots + \\frac{a_i^{(p)}}{p!}(x - x_i)^p$$\n", "\n", "et o\u00f9 l'on note $(k)$ comme un indice et non comme une puissance. Il s'agira donc de determiner $p+1$ coeficients pour chacun des $N-1$ intervalles s\u00e9parant les points de controles successifs. \n", "\n", "**<span style='color:orange'> Remarque</span>** ", "On remarque que les cas ou $p=0$ et $p=1$ correspondent respectivement \u00e0 l'interpolateur constant par morceaux (ordre $0$) comme nous avons pu les voir dans les parties pr\u00e9c\u00e9dentes. Les *splines* sont donc une g\u00e9n\u00e9ralisation des premi\u00e8res approches triviales vues dans la premi\u00e8re partie de ce TP. Lorsque $p=1$, certaines propri\u00e9t\u00e9s souhaitables ne sont plus garanties. On voudrait ainsi que la fonction soit au moins $\\mathcal{C}^2$ partout y compris au niveau des points de contr\u00f4les o\u00f9 on constate pour l'ordre 1 par exemple que la fonction n'est pas lisse.\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### A. Les splines cubiques\n", "\n", "Nous allons donc travailler avec un ordre $p=3$ (les *splines* cubiques), et les polyn\u00f4mes $P_i$ sont de la forme&nbsp;:\n", "\n", "\n", "$$P_i(x) = a_i^{(0)} + a_i^{(1)}(x - x_i) + \\frac{a_i^{(2)}}{2}(x - x_i)^2 + \\frac{a_i^{(3)}}{6}(x - x_i)^3,$$\n", "\n", "\n", "et tenter de construire une fonction interpolatrice $S$ qui est $C^2$, c'est-\u00e0-dire continue avec les d\u00e9riv\u00e9es et d\u00e9riv\u00e9es doubles continues. Pour cela posons un certain nombre de contraintes&nbsp;:\n", "\n", "- $P_i(x_{i+1}) = P_{i+1}(x_{i+1}) = y_{i+1}$ : la fonction doit \u00eatre continue au niveau des points de contr\u00f4le,\n", "\n", "- $P_i^{'}(x_{i+1}) = P_{i+1}^{'}(x_{i+1})$ : la fonction d\u00e9riv\u00e9e doit \u00eatre continue au niveau des points de contr\u00f4le,\n", "\n", "- $P_i^{''}(x_{i+1}) = P_{i+1}^{''}(x_{i+1})$ : et les d\u00e9riv\u00e9es secondes doivent \u00eatre continues au niveau des points de contr\u00f4le.\n", "\n", "Pour $N$ points, nous avons $N-1$ intervalles et donc $N-1$ polyn\u00f4mes \u00e0 trouver. Chaque polyn\u00f4me $P_i$ poss\u00e8de quatre coefficients $a_i^{(0)}, a_i^{(1)}, a_i^{(2)}$ et $a_i^{(3)}$ \u00e0 trouver. Cela nous donne $4(N-1)$ coefficients \u00e0 trouver pour estimer S."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Question</span>** ", "**Existe-t-il un ensemble unique de coeficients satisfaisant ces contraintes ? Si non, que rajouter comme contraintes afin de garantir l'unicit\u00e9 de la solution ?**\n", "\n\n ----", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### B. Estimation des coefficients\n", "\n", "**<span style='color:blue'> Question 1</span>** ", "**Montrez \u00e0 partir de la contrainte 1 par identification qu'on peut trouver tr\u00e8s facilement que $a_i^{(0)} = y_i$**\n", "\n\n ----", "\n", "\n", "Nous allons exprimer les $a_i^{(1)}, a_i^{(2)}$ et $a_i^{(3)}$ en fonction des d\u00e9riv\u00e9e et d\u00e9riv\u00e9e doubles de nos polyn\u00f4mes $P_i^\\prime$ et $P_i^{\\prime\\prime}$&nbsp;:\n", "\n", "$$P_i^{'}(x) = a_i^{(1)} + a_i^{(2)}(x - x_i) + \\frac{a_i^{(3)}}{2}(x - x_i)^2$$\n", "\n", "$$P_i^{''}(x) = a_i^{(2)}+ a_i^{(3)}(x - x_i)$$\n", "\n", "**<span style='color:blue'> Question 2</span>** ", "**Montrez \u00e0 partir de la contrainte 4 qu'on obtient $ a_i^{(3)} = \\frac{a_{i+1}^{(2)} -  a_i^{(2)}}{\\Delta x_i}$ en notant $\\Delta x_i = x_{i+1}-x_i, \\forall i$**\n", "\n\n ----", "\n", "\n", "**<span style='color:blue'> Question 3</span>** ", "**Montrez \u00e0 partir de $P_i(x_{i+1})=y_{i+1}$ que $a_i^{(1)} = \\frac{\\Delta y_i}{\\Delta x_i} - \\frac{a_i^{(2)}}{3}\\Delta x_i  -\\frac{a_{i+1}^{(2)}}{6} \\Delta x_i$ en notant $\\Delta y_i = y_{i+1} - y_i$**\n", "\n\n ----", "\n", "\n", "**<span style='color:blue'> Question 4</span>** ", "**Finalement, montrez \u00e0 partir de la contrainte 3 et en injectant les expression de $a_i^{(1)}$, $a_{i+1}^{(1)}$ et $a_i^{(3)}$ \u00e0 partir de la formule pr\u00e9c\u00e9dente que nous obtenons bien&nbsp;:**\n", "\n", "$$\\Delta x_i a_i^{(2)} + 2\\big[ \\Delta x_i + \\Delta x_{i+1}\\big]a_{i+1}^{(2)} + \\Delta x_{i+1}a_{i+2}^{(2)} = 6 \\big[F_{i+1} -  F_i\\big],$$\n", "\n", "o\u00f9 $F_i=\\frac{\\Delta y_i}{\\Delta x_i}=\\frac{y_{i+1}-y_i}{\\Delta x_i}$.\n", "\n\n ----", "\n", "\n", "On a donc un syst\u00e8me de $N-2$ \u00e9quations et $N-2$ inconnues (les $a_i^{(2)}$ sans $a_1^{(2)}$ et $a_{N}^{(2)}$ qu'on \u00e0 fix\u00e9 \u00e0 0). \n", "\n", "**<span style='color:orange'> Remarque</span>** ", "On peut \u00e9crire l'\u00e9quation pr\u00e9c\u00e9dente sous une forme matricielle&nbsp;:\n", "\n", "$$\\begin{pmatrix} \n", "2[\\Delta x_1 + \\Delta x_2] & \\Delta x_2 & \\dots & 0\\\\\n", "\\Delta x_2 & 2[\\Delta x_2 + \\Delta x_3] & \\Delta x_3 & \\dots\\\\\n", "\\vdots &   \\vdots  &  \\vdots  & \\vdots \\\\\n", "0 & 0 & \\dots & 0\\\\\n", "0 & \\dots & \\Delta x_{N-2}  & 2[\\Delta x_{N-2}+\\Delta x_{N-1}]\\\\\n", "\\end{pmatrix} \\begin{pmatrix} \n", "a_2^{(2)} \\\\\n", ".\\\\\n", "a_i^{(2)}\\\\\n", ".\\\\\n", "a_{N-1}^{(2)}\n", "\\end{pmatrix}  = \\begin{pmatrix} \n", "\\Delta F_1 \\\\\n", ".\\\\\n", "\\Delta F_i\\\\\n", ".\\\\\n", "\\Delta F_{N-1}\n", "\\end{pmatrix}$$\n", "\n", "en notant $\\Delta F_i = 6 \\big[F_{i+1} -  F_i\\big]$. On remarque que cette matrice est creuse, l'inversion d'une telle matrice sera donc efficace num\u00e9riquement:\n", "\n", "\n", "$$\\Big[D\\Big]\\boldsymbol{a}^{(2)}  = \\boldsymbol{\\Delta F} \\Leftrightarrow  \\boldsymbol{a}^{(2)}  = \\Big[D\\Big]^{-1}\\boldsymbol{\\Delta F}$$\n", "\n\n ----", "\n", "La suite consiste \u00e0 trouver les autres coefficients qu'on a d\u00e9j\u00e0 exprim\u00e9s en fonction de ceux que l'on vient de trouver. Il ne nous reste plus qu'\u00e0 appliquer les relations d\u00e9crites par les \u00e9quations&nbsp;:\n", "- $a_i^{(0)} = y_i$ $\\forall i$, \n", "- $\\boldsymbol{a}^{(2)}  = \\Big[D\\Big]^{-1}\\boldsymbol{\\Delta F}$\n", "- $a_i^{(1)} = F_i - \\frac{1}{3}\\Big[a_i^{(2)}  + \\frac{a_{i+1}^{(2)}}{2}\\Big] \\Delta x_i$ $\\forall i$,\n", "- $a_i^{(3)} = \\frac{a_{i+1}^{(2)} -  a_i^{(2)}}{\\Delta x_i}$ $\\forall i$.\n", "\n", "Et le tour est jou\u00e9, nous avons determin\u00e9 totalement les param\u00e8tres de notre spline $S$."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Proposez un code qui r\u00e9alise le calcul d'une spline cubique**\n", "\n\n ----", "---"]}, {"cell_type": "code", "metadata": {}, "source": ["class CubicSpline(object):\n", "        def __init__(self, X, y): \n", "            idx = np.argsort(X)\n", "            self.X = X[idx] \n", "            self.y = y[idx]\n", "            \n", "            self.N = X.shape[0]\n", "            self.coefs = np.zeros((self.N - 1,4))\n", "            \n", "            # Fit Intermediate variables\n", "            #  Complete Code  here ######## or die ##\n", "            dx = ...\n", "            F  = ...\n", "            dF = ...\n", "            D  = np.zeros((self.N-1,self.N-1))\n", "            for i in range(self.N-1):\n", "                ...\n", "            #########################################\n", "            \n", "            # Fit Spline coefficients\n", "            #  Complete Code  here ######## or die ##\n", "            self.coefs[:,0] = ...\n", "            self.coefs[:,2] = ...\n", "            self.coefs[:,1] = ...\n", "            self.coefs[:,3] = ...\n", "            #########################################\n", "            \n", "        def __call__(self, x):\n", "            if type(x) is not np.ndarray:\n", "                x = np.array([x])\n", "            y = np.zeros_like(x)\n", "            for j, v in enumerate(x):\n", "                dist = self.X - v\n", "                left = np.copy(dist)\n", "                left[left >= 0] = float('inf')\n", "                left = np.abs(left)\n", "                right = np.copy(dist)\n", "                right[right < 0] =float('inf')\n", "                right = np.abs(right)\n", "\n", "                i = np.argmin(left)\n", "                i_ = np.argmin(right)\n", "\n", "                if not np.isfinite(left[i]):\n", "                    i = 0\n", "                elif not np.isfinite(right[i_]):\n", "                    i =  self.N - 1\n", "                #  Complete Code  here ######## or die ##\n", "                ...\n", "                #########################################\n", "            return y\n", "        \n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["plt.figure(figsize=(14, 15))\n", "for i, n in enumerate([5, 10, 50]):\n", "    X = np.random.uniform(-1, 1, n)\n", "    S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "    idx = np.argsort(S[:, 0])\n", "    spline = CubicSpline(S[idx, 0], S[idx, 1])\n", "    plt.subplot(3, 1, i+1)\n", "    plt.plot(x, y)\n", "    plt.scatter(S[:, 0], S[:, 1])\n", "    plt.plot(x, spline(x), color='red')\n", "    plt.ylim(-1, 1)\n", "    plt.title('Size:' + str(n))\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous pouvons aussi utiliser l'outil $\\texttt{CubicSpline}$ de $\\texttt{scipy}$."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.interpolate import CubicSpline\n", "\n", "plt.figure(figsize=(14, 15))\n", "for i, n in enumerate([5, 10, 50]):\n", "    X = np.random.uniform(-1, 1, n)\n", "    S = np.stack([X, np.sin(np.pi*X)], axis=1)\n", "    idx = np.argsort(S[:, 0])\n", "    spline = CubicSpline(S[idx, 0], S[idx, 1])\n", "    plt.subplot(3, 1, i+1)\n", "    plt.plot(x, y)\n", "    plt.scatter(S[:, 0], S[:, 1])\n", "    plt.plot(x, spline(x), color='red')\n", "    plt.ylim(-1, 1)\n", "    plt.title('Size:' + str(n))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## V. De l'interpollation vers l'approximation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous allons voir ici une autre mani\u00e8re de contr\u00f4ler un peu les fluctuations entre les points de contr\u00f4le qui va consister \u00e0 trouver une fonction qui ne passe plus n\u00e9cessairement exactement sur chaque point mais qui reste tout de m\u00eame proche de la solution d'interpolation. Plus formellement, au lieu d'avoir $\\forall x_i \\in \\mathcal{S}, \\tilde{f}(x_i) = f^{\\star}(x_i)$, nous aurons plut\u00f4t $\\forall x_i \\in \\mathcal{S}, \\tilde{f}(x_i) \\approx f^{\\star}(x_i)$. On parlera plut\u00f4t d'approximation de la fonction."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comme nous l'avons vu, il est possible d'avoir des comportements non souhaitables via la solution des EQN quand la matrice $X^TX$ est mal conditionn\u00e9e. Ce comportement appara\u00eet notamment, si ses valeurs propres sont tr\u00e8s petites voir nulles, on parle de matrice presque singuli\u00e8re dont l'inverse poss\u00e8de alors une norme forte. Le probl\u00e8me est alors *mal pos\u00e9* car la solution devient tr\u00e8s sensible aux fluctuations du bruit dans les donn\u00e9es. "]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous allons donc ici consid\u00e9rer une formulation dite r\u00e9gularis\u00e9e de notre probl\u00e8me de r\u00e9gression polynomiale afin de mieux contr\u00f4ler les fluctuations de ce dernier. Plus formellement, cela correspond \u00e0 transformer notre probl\u00e8me *mal pos\u00e9* $\\mathcal{P}$ en une suite de probl\u00e8mes *bien pos\u00e9s* $\\mathcal{P}_\\lambda, \\lambda \\in \\mathbb{R}^{+}$, tel que $ \\lim\\limits_{\\lambda \\rightarrow 0}\\hat{\\beta}_{\\lambda} = \\hat{\\beta}$. Avec $\\hat{\\beta}$ et $\\hat{\\beta}_{\\lambda}$ les solutions respectives des probl\u00e8mes $\\mathcal{P}$ et $\\mathcal{P}_\\lambda$. La formulation r\u00e9gularis\u00e9e d'un probl\u00e8me d\u2019optimisation s'\u00e9crit de la fa\u00e7on suivante&nbsp;:\n", "\n", "$$J^{\\mathcal{D}}_{\\lambda}(\\beta) =  J_{\\mathcal{D}}(\\beta) + \\lambda  \\mathcal{\\Omega}(\\beta)$$\n", "\n", "o\u00f9&nbsp;:\n", "1. $J_{\\mathcal{D}}(\\beta)$ correspond \u00e0 l'expression de la fonction objectif du probl\u00e8me original,\n", "2. $ \\mathcal{\\Omega}(\\beta)$ correspond au terme de r\u00e9gularisation sur le vecteur des param\u00e8tres. Ce dernier terme correspond \u00e0 une contrainte que l'on souhaiterait optimiser conjointement sur le vecteur des param\u00e8tres avec plus ou moins d'importance par rapport \u00e0 la fonction objectif d'origine,\n", "3. On r\u00e9glera $\\lambda$ en fonction de l'importance relative de la contrainte sur le vecteur des param\u00e8tres (et nous verrons pus tard que cela est \u00e9quivalent \u00e0 un probl\u00e8me d'optimisation sous contrainte ou \\lambda joue le r\u00f4le du multiplicateur de Lagrange).\n", "\n", "Pour limiter l'amplitude des fluctuations du polyn\u00f4me entre les points nous pouvons donc construire une version r\u00e9gularis\u00e9e de la fonction objectif des moindres carr\u00e9s suivante pour trouver une solution dont les coeficients sont les plus petits possibles&nbsp;:\n", "\n", "\n", "$$J_{\\lambda}^{\\mathcal{D}}(\\beta) = ||\\boldsymbol{y} - \\boldsymbol{X}\\boldsymbol{\\beta}||_2^2 + \\lambda||\\boldsymbol{\\beta}||_2^2$$\n", "\n", " \n", "**<span style='color:orange'> Remarque</span>** ", " Quand $\\lambda \\rightarrow 0$, $J_{\\lambda}(\\beta)^{\\mathcal{D}} \\rightarrow J(\\beta)$. Quand $\\lambda \\rightarrow +\\infty$, $J_{\\lambda}(\\beta)^{\\mathcal{D}} \\approx \\lambda ||\\boldsymbol{\\beta}||_2^2 = \\sum_{d=0}^p\\beta_d^2$ et la solution optimal $\\hat{\\boldsymbol{\\beta}}_{\\lambda} \\rightarrow \\boldsymbol{0}$, *i.e.* la p\u00e9nalit\u00e9 \"domine\" et la solution est ind\u00e9pendante des donn\u00e9es.\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "Chercher \u00e0 trouver le minimum de la fonction revient \u00e0 trouver les $\\beta$ tels que le gradient s'annule. \n", "\n", "**<span style='color:blue'> Question</span>** ", "**Calculer la nouvelle valeur de $\\boldsymbol{\\beta}$ qui annule le gradient de cette nouvelle fonction objectif.**\n", "\n\n ----", "\n", "\n", "**<span style='color:blue'> Question</span>** ", "**Peut on trouver une solution interpolatrice avec cette version r\u00e9gularis\u00e9e des moindres carr\u00e9s ?**\n", "\n\n ----", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "**<span style='color:blue'> Exercice</span>** ", "**Proposez une impl\u00e9mentation d'approximation du polynome interpolateur bas\u00e9 sur cette version r\u00e9gularis\u00e9e des moindres carr\u00e9s. On pourra reprendre le code d\u00e9j\u00e0 effectu\u00e9 dans le TP regression lin\u00e9aire.**\n", "\n\n ----", "--- "]}, {"cell_type": "code", "metadata": {}, "source": ["class Polynomial_reg(object):\n", "    def __init__(self, deg):\n", "        self.deg = deg\n", "\n", "    def _transform(self, X):\n", "        # here we transform the input into a polynomial\n", "        t = []\n", "        X = X.reshape((X.shape[0], 1)) if len(X.shape) == 1 else X\n", "        for i in range(0, self.deg+1):\n", "            t.append(X**i)\n", "        return np.concatenate(t, axis=1)\n", "    \n", "    def fit(self, X, y):\n", "        ####### Complete this part ######## or die ####################\n", "        X_transformed = self._transform(X)\n", "        ...\n", "        ###############################################################\n", "        \n", "    def predict(self, X):\n", "        if self.beta is None:\n", "            print('You must fit the model first')\n", "        else:\n", "            X_transformed = self._transform(X)\n", "            return np.dot(X_transformed, self.beta)\n", "    def score(self, X, y):\n", "        prediction = self.predict(X)\n", "        errors = (prediction - y) **2\n", "        return errors.sum()/errors.shape[0]\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["n = 15\n", "X = np.random.uniform(-1, 1, n)\n", "Y = np.sin(np.pi*X)+np.random.normal(0, 0.005, size=(n,))\n", "S = np.stack([X, Y], axis=1)\n", "    \n", "plt.figure(figsize=(14, 8))\n", "\n", "d = n-1\n", "\n", "plt.plot(x, y)\n", "plt.scatter(S[:, 0], S[:, 1])\n", "\n", "k = 6\n", "colors = matplotlib.cm.jet(np.linspace(0, 1, k+1))#[2:2+3]\n", "alphas = np.append([0.0], np.logspace(-6, -1, k))\n", "\n", "for c, alpha in zip(colors, alphas):#[0, 1e-06, 1e-01]):\n", "    model = Polynomial_reg(d, alpha)\n", "    model.fit(X, Y)\n", "    plt.plot(x, model.predict(x), c=c, label='regularity:' + str(alpha))\n", "\n", "plt.ylim(-1, 1)\n", "plt.legend()\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:orange'> Remarques</span>** ", "\n", "- La solution $\\hat{\\boldsymbol{\\beta}}_{\\lambda}$ augmente en \"compl\u00e9xit\u00e9\" quand $\\lambda \\rightarrow 0$ et converge vers la solution interpolatrice $\\hat{\\boldsymbol{\\beta}}$.\n", "\n", "- En r\u00e9gularisant, on paye le prix de s'\u00e9loigner des valeurs ${(x_i, y_i})$ au profit d'\u00eatre plus \"raisonable\" entre elles. Il est d'autant plus raisonable de ne pas passer exactement sur les donn\u00e9es que les fluctuations de $y$ dues au bruit sont importantes.\n", "\n", "- $\\mathcal{P}_{\\lambda}^{\\mathcal{D}}$ pour $( \\lambda, \\mathcal{D})$ donn\u00e9s est unique (m\u00eame si le probl\u00e8me non r\u00e9gularis\u00e9 ne l'est pas), on peut d\u00e9finir un *chemin de r\u00e9gularisation* unique en faisant varier $\\lambda$, c'est \u00e0 dire une unique s\u00e9quence de solutions r\u00e9gularis\u00e9es $\\hat{\\boldsymbol{\\beta}}_{\\lambda}$ convergeant vers la solution interpolatrice \u00e0 mesure que $\\lambda \\rightarrow 0$. \n", "\n", "- Ainsi, on peut voir l'approximation d'une fonction comme un *arr\u00eat pr\u00e9matur\u00e9* (*early stopping* en anglais) le long de ce chemin de r\u00e9gularisation.\n", "\n\n ----"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 4}