
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Les moindres carr√©s via une d√©composition QR (et plus)‚òïÔ∏è &#8212; Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Une analyse de la r√©gularisation Ridge ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è" href="6_ridge.html" />
    <link rel="prev" title="Sous-diff√©rentiel et le cas du Lasso ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è" href="4_algo_proximal_lasso.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-72WWYCKNK6"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-72WWYCKNK6');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../0_requisite/rappels_python.html">
   Rappels de Python et Numpy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../1_what_is_ml/0_propos_liminaire.html">
   <em>
    Machine Learning
   </em>
   , initiation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_what_is_ml/1_introduction_ml.html">
     <em>
      Machine learning
     </em>
     et mal√©diction de la dimension
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_what_is_ml/2_regression_and_classification_trees.html">
     Les arbres de r√©gression et de classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="0_propos_liminaire.html">
   La
   <em>
    r√©gression
   </em>
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="1_linear_regression.html">
     La r√©gression lin√©aire ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="2_optimization.html">
     L‚Äôoptimisation ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3_interpolation.html">
     Interpolation ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="4_algo_proximal_lasso.html">
     Sous-diff√©rentiel et le cas du Lasso ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Les moindres carr√©s via une d√©composition QR (et plus)‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="6_ridge.html">
     Une analyse de la r√©gularisation Ridge ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../3_classification/0_propos_liminaire.html">
   La
   <em>
    classification
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/1_logistic_regression.html">
     La r√©gression logistique ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/2_fonctions_proxy.html">
     Les fonctions de perte (loss function) ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/3_bayes_classifier.html">
     Le classifieur de Bayes ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3_classification/4_VC_theory.html">
     Un mod√®le formel de l‚Äôapprentissage ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è (üíÜ‚Äç‚ôÇÔ∏è)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../4_kernel_methods/0_propos_liminaire.html">
   Les m√©thodes √† noyaux
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../4_kernel_methods/1_svm.html">
     Le SVM ou l‚Äôhypoth√®se max-margin ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../5_ensembles/0_propos_liminaire.html">
   Les m√©thodes
   <em>
    ensemblistes
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_ensembles/1_ensembles.html">
     M√©thodes ensemblistes ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5_ensembles/2_bayesian_linear_regression.html">
     Bayesian linear regression ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../6_deeplearning/0_propos_liminaire.html">
   <em>
    deep learning
   </em>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_deeplearning/1_autodiff.html">
     La diff√©rentiation automatique et un d√©but de
     <em>
      deep learning
     </em>
     ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_deeplearning/2_filters_representation.html">
     Filtres et espace de repr√©sentation des r√©seaux de neurones ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_deeplearning/3_probabilities_calibration.html">
     Calibration des probabilit√©s et quelques notions ‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_deeplearning/4_regularization_deep.html">
     R√©gularisation en
     <em>
      deep learning
     </em>
     ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_deeplearning/5_transfer_multitask.html">
     <em>
      Transfer learning
     </em>
     et apprentissage multi-t√¢ches ‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_deeplearning/6_adversarial.html">
     Les attaques adversaires ‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../7_unsupervised/0_propos_liminaire.html">
   L‚Äôapprentissage non-supervis√©
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_unsupervised/1_principal_component_analysis.html">
     L‚ÄôAnalyse en Composantes Principales ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7_unsupervised/2_em_gaussin_mixture_model.html">
     Mod√®le de M√©lange Gaussien et algorithme
     <em>
      Expectation-Maximization
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../8_set_prediction/0_propos_liminaire.html">
   Pr√©diction d‚Äôensembles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_set_prediction/1_well_defined.html">
     Jeu d‚Äôapprentissage
     <em>
      set-valued
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../8_set_prediction/2_ill_defined.html">
     Jeu d‚Äôapprentissage uniquement multi-classes ‚òïÔ∏è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../biblio.html">
   Bibliographie
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/2_regression/5_least_square_qr.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/maximiliense/lmiprp"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/maximiliense/lmiprp/issues/new?title=Issue%20on%20page%20%2F2_regression/5_least_square_qr.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/maximiliense/lmiprp/blob/master/Travaux Pratiques/Machine Learning/Book/2_regression/5_least_square_qr.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#i-introduction">
   I. Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ii-decomposition-qr">
   II. D√©composition QR
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-procede-de-gram-schmidt">
     A. Proc√©d√© de Gram-Schmidt
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-decomposition-qr">
     B. D√©composition QR
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-exemple">
     C. Exemple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iii-application-aux-moindres-carres">
   III. Application aux moindres carr√©s
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-notre-estimation-via-une-decomposition-qr">
     A. Notre estimation via une d√©composition QR
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-exercice">
     B. Exercice
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iv-autres-decompositions-et-conclusion">
   IV. Autres d√©compositions et conclusion
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="les-moindres-carres-via-une-decomposition-qr-et-plus">
<h1>Les moindres carr√©s via une d√©composition QR (et plus)‚òïÔ∏è<a class="headerlink" href="#les-moindres-carres-via-une-decomposition-qr-et-plus" title="Permalink to this headline">¬∂</a></h1>
<div class="admonition-objectifs-de-la-sequence admonition">
<p class="admonition-title">Objectifs de la s√©quence</p>
<ul class="simple">
<li><p>Comprendre les √©quations normales via une d√©composition QR,</p></li>
<li><p>√ätre sensibilis√© aux probl√®mes li√©s aux approximations num√©riques et √† leur r√©solution.</p></li>
</ul>
</div>
<div class="section" id="i-introduction">
<h2>I. Introduction<a class="headerlink" href="#i-introduction" title="Permalink to this headline">¬∂</a></h2>
<p>En <em>data science</em>, nous ne faisons pas seulement face √† des mod√®les math√©matiques que nous souhaitons programmer. Nous devons aussi tenir compte du fait que les nombres que nous manipulons ont une repr√©sentation sur la machine qui les stocke. De mani√®re paradigmatique, consid√©rons la fonction suivante¬†:</p>
<div class="math notranslate nohighlight">
\[f(x)=\text{ln}\big(\text{exp}(x)\big)=x.\]</div>
<p>Les deux formulations sont parfaitement indentiques. Observons cela via <span class="math notranslate nohighlight">\(\texttt{numpy}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">y_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">x</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_1</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ln(exp(x))$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-2-4fd55f099922&gt;:2: RuntimeWarning: overflow encountered in exp
  y_1 = np.log(np.exp(x))
</pre></div>
</div>
<img alt="../_images/5_least_square_qr_2_1.png" src="../_images/5_least_square_qr_2_1.png" />
</div>
</div>
<p>Nous rencontrons une erreur ! Cela vient √©videmment du fait que le calcul de l‚Äôexponentielle lorsque <span class="math notranslate nohighlight">\(x\)</span> devient trop grand induit un <span class="math notranslate nohighlight">\(\texttt{overflow}\)</span> que le logarithme ne peut plus interpr√©ter. En observant <span class="math notranslate nohighlight">\(\text{ln}\big(\text{exp}(x)\big)=x\)</span>, nous avons en quelque sorte utilis√© une astuce (clairement triviale ici) math√©matique nous permettant d‚Äôobtenir notre r√©sultat malgr√© tout. De mani√®re similaire, nous utilisons souvent en <em>machine learning</em> la fonction <em>softmax</em>:</p>
<div class="math notranslate nohighlight">
\[\text{softmax}(x)_j=\frac{e^{x_j}}{\sum_i e^{x_i}},\]</div>
<p>notamment comme fonction de lien en <em>deep learning</em> ou en <em>r√©gression logistique</em> afin de transformer notre vecteur de <em>logit</em> en vecteur de probabilit√©s. Impl√©mentons cette fonction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Softmax [10, 12]:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Softmax [-10, 12]:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">748</span><span class="p">,</span> <span class="mi">750</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Softmax [748, 750]:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Softmax [10, 12]: [0.11920292 0.88079708]
Softmax [-10, 12]: [2.78946809e-10 1.00000000e+00]
Softmax [748, 750]: [nan nan]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-3-cdc4f3bc964f&gt;:4: RuntimeWarning: overflow encountered in exp
  return np.exp(x)/np.exp(x).sum()
&lt;ipython-input-3-cdc4f3bc964f&gt;:4: RuntimeWarning: invalid value encountered in true_divide
  return np.exp(x)/np.exp(x).sum()
</pre></div>
</div>
</div>
</div>
<p>Le calcul de l‚Äôexponentielle de <span class="math notranslate nohighlight">\(750\)</span> entra√Æne √† nouveau un <span class="math notranslate nohighlight">\(\texttt{overflow}\)</span> et nous emp√™che de calculer le <em>softmax</em>. La strat√©gie consiste √† r√©duire la taille du plus grand nombre que notre exponentielle devra calculer de la mani√®re suivante¬†:</p>
<div class="math notranslate nohighlight">
\[\text{softmax}(x)_j=\frac{e^{x_j}}{\sum_i e^{x_i}}=\frac{e^{x_j}}{\sum_i e^{x_i}}\frac{e^{-\text{max}(x)}}{e^{-\text{max}(x)}}=\frac{e^{x_j-\text{max}(x)}}{\sum_i e^{x_i-\text{max}(x)}}.\]</div>
<p>R√©impl√©mentons notre <em>softmax</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Softmax [10, 12]:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Softmax [-10, 12]:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">748</span><span class="p">,</span> <span class="mi">750</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Softmax [748, 750]:&#39;</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Softmax [10, 12]: [0.11920292 0.88079708]
Softmax [-10, 12]: [2.78946809e-10 1.00000000e+00]
Softmax [748, 750]: [0.11920292 0.88079708]
</pre></div>
</div>
</div>
</div>
<p>De tr√®s nombreuses astuces de ce type existent et sont impl√©ment√©es dans les diff√©rents <em>frameworks</em>.</p>
<p>C‚Äôest exactement cela que nous voulons faire avec les moindres carr√©s via une d√©composition QR. Calculer notre estimateur des moindres carr√©s est beaucoup plus stable apr√®s une d√©composition QR que dans sa formulation telle que nous l‚Äôavons vue.</p>
</div>
<div class="section" id="ii-decomposition-qr">
<h2>II. D√©composition QR<a class="headerlink" href="#ii-decomposition-qr" title="Permalink to this headline">¬∂</a></h2>
<p>Soit une matrice <span class="math notranslate nohighlight">\(A\in\mathbb{R}^{m\times n}\)</span>. La d√©composition <span class="math notranslate nohighlight">\(QR\)</span> de la matrice <span class="math notranslate nohighlight">\(A\)</span> est¬†:</p>
<div class="math notranslate nohighlight">
\[A=QR,\]</div>
<p>o√π <span class="math notranslate nohighlight">\(Q\)</span> est une matrice orthogonale (par colonne si rectangulaire) et <span class="math notranslate nohighlight">\(R\)</span> une matrice diagonale sup√©rieure. On retrouve d‚Äôailleurs parfois l‚Äôappellation ‚Äúd√©composition <span class="math notranslate nohighlight">\(QU\)</span>‚Äù o√π <span class="math notranslate nohighlight">\(U\)</span> signifie <em>Upper triangular</em>. Une matrice orthogonale par colonne implique <span class="math notranslate nohighlight">\(Q^TQ=I\)</span> et donc <span class="math notranslate nohighlight">\(m\geq n\)</span>. En effet, si une famille de vecteurs est plus grande que la dimension de l‚Äôespace, alors elle est forc√©ment li√©e.</p>
<div class="section" id="a-procede-de-gram-schmidt">
<h3>A. Proc√©d√© de Gram-Schmidt<a class="headerlink" href="#a-procede-de-gram-schmidt" title="Permalink to this headline">¬∂</a></h3>
<p>Il existe plusieurs strat√©gies permettant de r√©aliser cette d√©composition et nous utiliserons celle bas√©e sur le proc√©d√© (ou algorithme) de Gram-Schmidt. Soit <span class="math notranslate nohighlight">\(F=\{u_1, ..., u_n\}\)</span> une famille de vecteurs libres. Le proc√©d√© de Gram-Schmidt a pour objectif de construire une base orthonormale <span class="math notranslate nohighlight">\(B=\{e_1, ..., e_n\}\)</span> √† partir de <span class="math notranslate nohighlight">\(F\)</span>.</p>
<p>L‚Äôop√©ration de base du proc√©d√© de Gram-Schmidt est l‚Äôop√©rateur de projection¬†:</p>
<div class="math notranslate nohighlight">
\[\textrm{proj}_u(v)=\Pi_u(v)=\frac{\langle v, u\rangle }{\langle u, u\rangle}u,\]</div>
<p>o√π le vecteur <span class="math notranslate nohighlight">\(v\)</span> est projet√© orthogonalement sur <span class="math notranslate nohighlight">\(u\)</span>.</p>
<p>Le proc√©d√© it√®re sur l‚Äôensemble des vecteurs de la famille <span class="math notranslate nohighlight">\(F\)</span> de la mani√®re suivante.</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(v_1=u_1\)</span> et <span class="math notranslate nohighlight">\(e_1=v_1/\lVert v_1\rVert_2\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(v_2=u_2-\Pi_{e_1}(u_2)\)</span> et <span class="math notranslate nohighlight">\(e_2=v_2/\lVert v_2\rVert_2\)</span>,</p></li>
<li><p>‚Ä¶</p></li>
<li><p><span class="math notranslate nohighlight">\(v_n=u_n-\sum_{i=1}^{n-1}\Pi_{e_i}(u_n)\)</span> et <span class="math notranslate nohighlight">\(e_n=v_n/\lVert v_n\rVert_2\)</span>.</p></li>
</ol>
<p>La famille <span class="math notranslate nohighlight">\(\{e_1, ..., e_n\}\)</span> ainsi construite est une base orthonorm√©e et engendre le m√™me sous-espace vectoriel que la famille <span class="math notranslate nohighlight">\(F\)</span>.</p>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p><strong>Compl√©tez le code ci-dessous afin d‚Äôimpl√©menter le proc√©d√© de Gram-Schmidt.</strong></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">projector</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="c1">####### Complete this part ######## or die ####################</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="o">...</span>
    <span class="c1">###############################################################</span>

<span class="k">def</span> <span class="nf">gram_schmidt</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
    <span class="c1">####### Complete this part ######## or die ####################</span>
    <span class="o">...</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="o">...</span>
    <span class="c1">###############################################################</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">Q</span> <span class="o">=</span> <span class="n">gram_schmidt</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Une matrice identite :</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Q</span><span class="p">))</span>

</pre></div>
</div>
</div>
<div class="section" id="b-decomposition-qr">
<h3>B. D√©composition QR<a class="headerlink" href="#b-decomposition-qr" title="Permalink to this headline">¬∂</a></h3>
<p>Soit <span class="math notranslate nohighlight">\(A\in\mathbb{R}^{m\times n}\)</span> telle que les vecteurs colonnes sont libres. Notons <span class="math notranslate nohighlight">\(\{a_1, ..., a_n\}\)</span> l‚Äôensemble des vecteurs colonnes. Soit <span class="math notranslate nohighlight">\(\{e_1, ..., e_n\}\)</span> une base orthonormale r√©sultant du proc√©d√© de Gram-Schmidt appliqu√© aux vecteurs colonnes de <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>De mani√®re assez directe, on observe que¬†:</p>
<div class="math notranslate nohighlight">
\[a_1=\langle a_1, e_1\rangle e_1.\]</div>
<p>Dit autrement, <span class="math notranslate nohighlight">\(a_1\)</span> est un vecteur co-lin√©aire √† <span class="math notranslate nohighlight">\(e_1\)</span> dont la norme est <span class="math notranslate nohighlight">\(\langle e_1, a_1\rangle\)</span> (sachant que <span class="math notranslate nohighlight">\(e_1\)</span> est unitaire). Le vecteur <span class="math notranslate nohighlight">\(a_2\)</span> est un peu plus complexe √† reconstruire¬†:</p>
<div class="math notranslate nohighlight">
\[a_2=\langle a_2, e_2\rangle e_2+\langle a_2, e_1\rangle e_1.\]</div>
<p>Autrement dit, <span class="math notranslate nohighlight">\(a_2\)</span> est une combinaison lin√©aire de <span class="math notranslate nohighlight">\(e_1\)</span> et <span class="math notranslate nohighlight">\(e_2\)</span>, ce qui est logique puisque <span class="math notranslate nohighlight">\(e_2\)</span> est construit en retirant la composante non orthogonale √† <span class="math notranslate nohighlight">\(e_1\)</span> de <span class="math notranslate nohighlight">\(a_2\)</span>.
On r√©it√®re l‚Äôop√©ration jusqu‚Äô√† <span class="math notranslate nohighlight">\(a_n=\sum_i \langle e_i, a_n\rangle e_i\)</span>.</p>
<p>En notant¬†:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    Q=[e_1, ..., e_n]\textrm{ et }R=\begin{bmatrix}
        \langle e_1, a_1\rangle &amp; \langle e_1, a_2\rangle &amp; \langle e_1, a_3\rangle &amp; \ldots&amp;\langle e_1, a_n\rangle\\
        0 &amp; \langle e_2, a_2\rangle &amp; \langle e_2, a_3\rangle&amp; \ldots&amp;\langle e_2, a_n\rangle\\
        0 &amp;0 &amp; \langle e_3, a_3\rangle&amp; \ldots&amp;\langle e_3, a_n\rangle\\
        0 &amp; 0 &amp; 0 &amp; \ddots &amp; \vdots\\
        0 &amp; 0 &amp; 0 &amp; \ldots &amp; \langle e_n, a_n\rangle
        \end{bmatrix}
    \end{aligned}\end{split}\]</div>
<p>on retrouve bien <span class="math notranslate nohighlight">\(A=QR\)</span>.</p>
</div>
<div class="section" id="c-exemple">
<h3>C. Exemple<a class="headerlink" href="#c-exemple" title="Permalink to this headline">¬∂</a></h3>
<p>Soit la matrice suivante¬†:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    A=\begin{bmatrix}
    1&amp;-1\\
    2&amp;0\\
    2&amp;2
    \end{bmatrix}=[a_1, a_2]
\end{aligned}\end{split}\]</div>
<p>Commen√ßons la proc√©dure de Gram-Schmidt. On note¬†:</p>
<div class="math notranslate nohighlight">
\[v_1=a_1\textrm{ et }e_1=v_1/\lVert v_1\rVert_2=\Big[\frac{1}{3},\frac{2}{3}, \frac{2}{3}\Big]^T\]</div>
<p>Et¬†:</p>
<div class="math notranslate nohighlight">
\[v_2=a_2-\Pi_{e_1}(a_2)\textrm{ et }e_2=v_2/\lVert v_2\rVert_2=\Big[-\frac{2}{3},-\frac{1}{3}, \frac{2}{3}\Big]^T\]</div>
<p>On v√©rifie assez bien que <span class="math notranslate nohighlight">\(e_1\)</span> et <span class="math notranslate nohighlight">\(e_2\)</span> sont orthogonaux et unitaires.
Calculons maintenant les produits scalaires¬†:</p>
<div class="math notranslate nohighlight">
\[\langle e_1, a_1\rangle=3,\ \langle e_1, a_2\rangle=1\textrm{ et }\langle e_2, a_2\rangle=2\]</div>
<p>Nous avons donc</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    Q=\begin{bmatrix}
    1/3&amp;-2/3\\
    2/3&amp;-1/3\\
    2/3&amp;2/3
    \end{bmatrix}\text{ et }R=\begin{bmatrix}
    3&amp;1\\
    0&amp;2
    \end{bmatrix}
    \end{aligned}\end{split}\]</div>
<p>On v√©rifie facilement qu‚Äôon a bien l‚Äô√©galit√© <span class="math notranslate nohighlight">\(A=QR\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title">Dans <span class="math notranslate nohighlight">\(\texttt{sklearn}\)</span></p>
<p>La m√©thode <span class="math notranslate nohighlight">\(\texttt{np.linalg.qr}\)</span> de <span class="math notranslate nohighlight">\(\texttt{sklearn}\)</span> permet de faire une d√©composition QR d‚Äôune matrice <span class="math notranslate nohighlight">\(A\)</span>.</p>
</div>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p><strong>Compl√©tez le code ci-dessous en r√©-utilisant votre impl√©mentation du proc√©d√© de Gram-Schmidt afin d‚Äôobtenir une d√©composition QR.</strong></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">qr</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
    <span class="c1">####### Complete this part ######## or die ####################</span>
    <span class="o">...</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="o">...</span>
    <span class="c1">###############################################################</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>

<span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Notre matrice initiale :</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Notre matrice initiale reconstruite :</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="iii-application-aux-moindres-carres">
<h2>III. Application aux moindres carr√©s<a class="headerlink" href="#iii-application-aux-moindres-carres" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="a-notre-estimation-via-une-decomposition-qr">
<h3>A. Notre estimation via une d√©composition QR<a class="headerlink" href="#a-notre-estimation-via-une-decomposition-qr" title="Permalink to this headline">¬∂</a></h3>
<p>Soit <span class="math notranslate nohighlight">\(X\in\mathbb{R}^{n\times d}\)</span>, <span class="math notranslate nohighlight">\(y\in\mathbb{R}^n\)</span> et <span class="math notranslate nohighlight">\(\beta\in\mathbb{R}^d\)</span>. Notre objectif est de r√©soudre le probl√®me d‚Äôoptimisation suivant¬†</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}=\text{argmin}_{\beta\in\mathbb{R}^d}\lVert X\beta-y\rVert_2^2.\]</div>
<p>Nous avons d√©j√† vu que si <span class="math notranslate nohighlight">\(X^TX\)</span> est inversible, alors nous avons la solution analytique suivante¬†:</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}=(X^TX)^{-1}X^Ty.\]</div>
<p>Consid√©rons maintenant la d√©composition <span class="math notranslate nohighlight">\(QR\)</span> de la matrice <span class="math notranslate nohighlight">\(X\)</span> (i.e. <span class="math notranslate nohighlight">\(X=QR\)</span>). Nous avons ainsi¬†:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \hat{\beta}&amp;=(X^TX)^{-1}X^Ty\\
    &amp;=((QR)^TQR)^{-1}(QR)^Ty\\
    &amp;= ((R^TQ^TQR)^{-1}R^TQ^Ty\\
    &amp;=(R^TR)^{-1}R^TQ^Ty\\
    &amp;=R^{-1}(R^T)^{-1}R^TQ^Ty\\
    &amp;=R^{-1}Q^Ty.
\end{aligned}\end{split}\]</div>
<p>Rappellons que si <span class="math notranslate nohighlight">\(A\)</span> et <span class="math notranslate nohighlight">\(B\)</span> sont deux matrices inversibles, nous avons <span class="math notranslate nohighlight">\((AB)^{-1}=B^{-1}A^{-1}\)</span>.</p>
</div>
<div class="section" id="b-exercice">
<h3>B. Exercice<a class="headerlink" href="#b-exercice" title="Permalink to this headline">¬∂</a></h3>
<p>Soit la matrice suivante¬†:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    X=\begin{bmatrix}
    1&amp;-1\\
    0&amp;10^{-5}\\
    0&amp;0
    \end{bmatrix}\textrm{ et }Y=\begin{bmatrix}
    0\\
    10^{-5}\\
    0
    \end{bmatrix}
    \end{aligned}\end{split}\]</div>
<div class="admonition-exercice-1 admonition">
<p class="admonition-title">Exercice 1</p>
<p><strong>Supposons que l‚Äôalgorithme tourne sur une machine o√π les nombres sont arrondis apr√®s 8 d√©cimales (i.e. si <span class="math notranslate nohighlight">\(|x|&lt;10^{-8}\)</span> alors <span class="math notranslate nohighlight">\(x:=0\)</span>). Calculez l‚Äôestimateur des moindres carr√©s SANS passer par une d√©composition QR.</strong></p>
</div>
<div class="admonition-exercice-2 admonition">
<p class="admonition-title">Exercice 2</p>
<p><strong>Supposons que l‚Äôalgorithme tourne sur une machine o√π les nombres sont arrondis apr√®s 8 d√©cimales (i.e. si <span class="math notranslate nohighlight">\(|x|&lt;10^{-8}\)</span> alors <span class="math notranslate nohighlight">\(x:=0\)</span>). Calculez l‚Äôestimateur des moindres carr√©s AVEC une d√©composition QR.</strong></p>
</div>
<div class="admonition-exercice-3 admonition">
<p class="admonition-title">Exercice 3</p>
<p><strong>Impl√©mentez les deux strat√©gies pr√©c√©dentes en utilisant <span class="math notranslate nohighlight">\(\texttt{numpy}\)</span>. Que constatez-vous ?</strong></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

<span class="c1">####### Complete this part ######## or die ####################</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="c1">###############################################################</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Notre estimateur avec la m√©thode classique :</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Notre estimateur avec la m√©thode QR :</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">beta_qr_est</span><span class="p">)</span>
</pre></div>
</div>
<p>Cette exemple simple montre d√©j√† les avantages de la d√©composition QR dans le cadre des moindres carr√©s. On imagine sans mal son int√©r√™t dans des exemples beaucoup plus compliqu√©s o√π les d√©pendances lin√©aires sont peut-√™tre plus difficiles √† discerner au milieu des perturbations et du bruit.</p>
</div>
</div>
<div class="section" id="iv-autres-decompositions-et-conclusion">
<h2>IV. Autres d√©compositions et conclusion<a class="headerlink" href="#iv-autres-decompositions-et-conclusion" title="Permalink to this headline">¬∂</a></h2>
<p>Soit <span class="math notranslate nohighlight">\(X\)</span> notre matrice, la solution des moindres carr√©s est obtenue par la pseudo-inverse de <span class="math notranslate nohighlight">\(X\)</span> (nous l‚Äôavons d√©montr√© dans la s√©quence de cours sur la r√©gression lin√©aire)¬†:</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}=X^\dagger y.\]</div>
<p>Lorsque <span class="math notranslate nohighlight">\(X^TX\)</span> est inversible, nous pouvons obtenir cette pseudo-inverse par ¬†:</p>
<div class="math notranslate nohighlight">
\[X^\dagger=(X^TX)^{-1}X^T,\]</div>
<p>comme nous l‚Äôavons vu au-dessus. Nous pouvons √©galement retrouver l‚Äôexpression <span class="math notranslate nohighlight">\(\hat{\beta}=(X^TX)^{-1}X^Ty=X^\dagger y\)</span> en annulant le gradient des moindres carr√©s. Afin de limiter les probl√®mes de stabilit√© num√©rique li√©s √† <span class="math notranslate nohighlight">\((X^TX)^{-1}\)</span>, nous avons remplac√© dans l‚Äôexpression pr√©c√©dente <span class="math notranslate nohighlight">\(X\)</span> par sa d√©composition <span class="math notranslate nohighlight">\(QR\)</span>.</p>
<p>√âtudions maintenant les moindres carr√©s au travers d‚Äôune d√©composition en valeurs singuli√®res. Attention, ici l‚Äôobjectif n‚Äôest pas de remplacer <span class="math notranslate nohighlight">\(X\)</span> par cette nouvelle d√©composition mais d‚Äôutiliser cette derni√®re afin de trouver une expression de la pseudo-inverse de <span class="math notranslate nohighlight">\(X\)</span>. Une d√©composition en valeurs singuli√®res donne¬†:</p>
<div class="math notranslate nohighlight">
\[X=U\Sigma V^T,\]</div>
<p>o√π <span class="math notranslate nohighlight">\(X\in\mathbb{R}^{n\times d}\)</span>, <span class="math notranslate nohighlight">\(V\)</span> est une matrice de taille <span class="math notranslate nohighlight">\(d\times d\)</span> compos√©e d‚Äôune base orthonormale de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>, <span class="math notranslate nohighlight">\(U\)</span> est une matrice de taille <span class="math notranslate nohighlight">\(n\times n\)</span> contenant une base orthonormale de <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> et <span class="math notranslate nohighlight">\(\Sigma\)</span> est une matrice ‚Äúdiagonale‚Äù de taille <span class="math notranslate nohighlight">\(n\times d\)</span> contenant les valeurs singuli√®res de <span class="math notranslate nohighlight">\(X\)</span> g√©n√©ralement tri√©es de la plus grande √† la moins grande. Les valeurs singuli√®res sont les racines des valeurs propres de <span class="math notranslate nohighlight">\(X^TX\)</span> (celles-ci sont n√©cessairement positives ou nulles).</p>
<p>Soit <span class="math notranslate nohighlight">\(\Sigma^{-1}\)</span> la matrice <span class="math notranslate nohighlight">\(\Sigma\)</span> dont chaque valeur singuli√®re diff√©rente de <span class="math notranslate nohighlight">\(0\)</span> a √©t√© invers√©e¬†: <span class="math notranslate nohighlight">\(\lambda_i^{-1}=1/\lambda_i\)</span>. La pseudo-inverse de <span class="math notranslate nohighlight">\(X\)</span> est donn√©e par¬†:</p>
<div class="math notranslate nohighlight">
\[X^\dagger=V\Sigma^{-1}U^T.\]</div>
<div class="admonition-exercice admonition">
<p class="admonition-title">Exercice</p>
<p>V√©rifier qu‚Äôil s‚Äôagit bien d‚Äôune pseudo-inverse.</p>
</div>
<div class="hint dropdown admonition">
<p class="admonition-title">Indice</p>
<p>Montrer les √©galit√©s suivantes¬†:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
AA^\dagger A&amp;=A\text{ (appliquer }A\text{, son inverse }A^\dagger\text{ puis }A\text{ √† nouveau revient √† appliquer }A\text{)}\\
A^\dagger AA^\dagger&amp;=A^\dagger\text{ (c'est la m√™me chose du point de vu de l'inverse)}\\
(AA^\dagger)^T&amp;=AA^\dagger\text{ (la transposition n'a pas d'effet)}\\
(A^\dagger A)^T&amp;=A^\dagger A\text{ (m√™me chose que pr√©c√©demment du point de vu de l'inverse)}
\end{aligned}\end{split}\]</div>
</div>
<p>Comparons dans le code ci-dessous la d√©composition QR et la d√©composition SVD sur un jeu de donn√©es synth√©tique.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">nb_elements</span> <span class="o">=</span> <span class="mi">500</span>

<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">nb_elements</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">nb_elements</span><span class="p">,</span> <span class="n">nb_elements</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">nb_elements</span><span class="p">,</span> <span class="n">nb_elements</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># on fait notre d√©composition QR</span>
<span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># on calcule notre estimateur</span>

<span class="n">beta_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">R</span><span class="p">),</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>


<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span><span class="o">-</span><span class="n">y</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Erreur sur le jeu d</span><span class="se">\&#39;</span><span class="s1">apprentissage (QR):&#39;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>

<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span><span class="o">-</span><span class="n">y_test</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Erreur sur le jeu de test (QR):&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">)))</span>

<span class="c1"># SVD decomposition</span>
<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># on inverse la matrice diagonale sauf pour ses elements nulls</span>
<span class="n">S</span><span class="p">[</span><span class="n">S</span><span class="o">!=</span><span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">S</span><span class="p">[</span><span class="n">S</span><span class="o">!=</span><span class="mf">0.</span><span class="p">]</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>

<span class="n">beta_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">VT</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="p">),</span> <span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span><span class="o">-</span><span class="n">y</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Erreur sur le jeu d</span><span class="se">\&#39;</span><span class="s1">apprentissage (SVD):&#39;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>

<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span><span class="o">-</span><span class="n">y_test</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Erreur sur le jeu de test (SVD):&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Erreur sur le jeu d&#39;apprentissage (QR): 1.4321170199999501e-24
Erreur sur le jeu de test (QR): 486.6060026505997
Erreur sur le jeu d&#39;apprentissage (SVD): 7.531901145537263e-24
Erreur sur le jeu de test (SVD): 486.60600265068
</pre></div>
</div>
</div>
</div>
<p>Nous avons bien <span class="math notranslate nohighlight">\(X\hat{\beta} = y\)</span> (aux approximations num√©riques pr√®s) pour les deux d√©compositions. Cependant, lorsqu‚Äôon passe sur un jeu de donn√©es de test, la pr√©diction ne correspond plus du tout √† la r√©alit√©.</p>
<p>Cela ne vient plus du probl√®me de stabilit√© num√©rique mais du bruit qu‚Äôil y a dans les donn√©es. En effet, nous avons¬†:</p>
<div class="math notranslate nohighlight">
\[\textbf{y}=\textbf{X}\beta + \mathbf{\epsilon},\]</div>
<p>o√π <span class="math notranslate nohighlight">\(\mathbf{\epsilon}\)</span> est un vecteur de bruit centr√© en <span class="math notranslate nohighlight">\(\mathbf{0}\)</span>. Notons <span class="math notranslate nohighlight">\(\textbf{y}_\text{pred}=\textbf{X}\beta \)</span> o√π <span class="math notranslate nohighlight">\(\beta\)</span> est le ‚Äúvrai‚Äù vecteur de param√®tres. Nous pouvons retrouver <span class="math notranslate nohighlight">\(\beta\)</span> en passant par la pseudo-inverse¬†:</p>
<div class="math notranslate nohighlight">
\[\beta=\textbf{X}^\dagger \textbf{y}_\text{pred}.\]</div>
<p>En pratique, nous n‚Äôavons acc√®s ni √† <span class="math notranslate nohighlight">\(\beta\)</span> ni √† <span class="math notranslate nohighlight">\(y_\text{pred}\)</span> et notre estimateur est¬†:</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}=\textbf{X}^\dagger \textbf{y}=\textbf{X}^\dagger (\textbf{y}_\text{pred}+\mathbf{\epsilon})=\beta + \mathbf{X}^\dagger \mathbf{\epsilon}.\]</div>
<p>Lorsque la matrice <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> est mal conditionn√©e (e.g. matrice al√©atoire presque carr√©e, colonnes presque d√©pendantes lin√©airement), alors <span class="math notranslate nohighlight">\(\mathbf{X}^\dagger\)</span> aura un effet excessivement important dans certaines directions et <span class="math notranslate nohighlight">\(\mathbf{X}^\dagger \mathbf{\epsilon}\)</span> aura un impact catastrophique sur notre estimateur et nos pr√©dictions seront mauvaises.</p>
<p>La bonne nouvelle est qu‚Äôon peut r√©soudre ce probl√®me via une strat√©gie de r√©gularisation comme nous pourrons le voir plus tard. Une autre strat√©gie de r√©gularisation est possible via notre d√©composition SVD. En effet, le mauvais conditionnement vient du ratio entre la plus grande et la plus petite valeur singuli√®re (ou valeurs propres lorsqu‚Äôelles existent).</p>
<p>Le param√®tre de r√©gularisation, not√© <span class="math notranslate nohighlight">\(\texttt{rcond}\)</span> n‚Äôest autre que le ratio entre la plus grande et la plus petite valeur singuli√®re (diff√©rente de <span class="math notranslate nohighlight">\(0\)</span>) qu‚Äôon autorise. Toutes les valeurs singuli√®res (ou propres) plus petites que <span class="math notranslate nohighlight">\(\texttt{rcond}\times \lambda_\text{max}\)</span> sont mises √† <span class="math notranslate nohighlight">\(0\)</span>. Bien s√ªr, en faisant cela, nous nous √©cartons de la vraie pseudo-inverse. Cependant, cela permet de r√©duire consid√©rablement la norme du vecteur <span class="math notranslate nohighlight">\(\mathbf{X}^\dagger\epsilon\)</span>, vecteur qui n‚Äôa que des effets ind√©sirables.</p>
<p>Reprenons l‚Äôexemple pr√©c√©dent et observons les r√©sultats.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># on autorise un ratio de 100 entre la plus grande </span>
<span class="c1"># et la plus petite valeur singuliere</span>
<span class="n">rcond</span> <span class="o">=</span><span class="mf">1e-2</span>
<span class="n">S</span><span class="p">[</span><span class="n">S</span><span class="o">&lt;=</span><span class="n">rcond</span><span class="o">*</span><span class="n">S</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">S</span><span class="p">[</span><span class="n">S</span><span class="o">!=</span><span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">S</span><span class="p">[</span><span class="n">S</span><span class="o">!=</span><span class="mf">0.</span><span class="p">]</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>

<span class="n">beta_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">VT</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="p">),</span> <span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span><span class="o">-</span><span class="n">y</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Erreur sur le jeu d</span><span class="se">\&#39;</span><span class="s1">apprentissage (SVD avec filtre):&#39;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>

<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">beta_est</span><span class="p">)</span><span class="o">-</span><span class="n">y_test</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Erreur sur le jeu de test (SVD avec filtre):&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nb_elements</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Erreur sur le jeu d&#39;apprentissage (SVD avec filtre): 0.27668371335748604
Erreur sur le jeu de test (SVD avec filtre): 3.5522910930652705
</pre></div>
</div>
</div>
</div>
<p>On observe donc que notre nouvel estimateur est beaucoup plus robuste et permet d‚Äôobtenir de biens meilleurs r√©sultats sur le test. Cependant, nous n‚Äôavons effectivement plus une vraie pseudo-inverse et l‚Äôerreur sur le train n‚Äôest plus n√©gligeable.</p>
<p>La m√©thode <span class="math notranslate nohighlight">\(\texttt{np.linalg.pinv}\)</span> utilise <span class="math notranslate nohighlight">\(\texttt{np.linalg.svd}\)</span> et poss√®de un param√®tre <span class="math notranslate nohighlight">\(\texttt{rcond}\)</span> fix√© par d√©faut √† <span class="math notranslate nohighlight">\(10^{-15}\)</span> qui permet de g√©rer cette r√©gularisation.</p>
<p>En r√®gle g√©n√©ral, lorsque la matrice <span class="math notranslate nohighlight">\(X^TX\)</span> est bien inversible les solutions <span class="math notranslate nohighlight">\((X^TX)^{-1}X^T\)</span>, QR ou SVD sont comparables en termes de r√©sultats. Lorsqu‚Äôon se rapproche d‚Äôun d√©terminant nul, la m√©thode <span class="math notranslate nohighlight">\((X^TX)^{-1}X^T\)</span> est la premi√®re √† devenir instable, suivi de <span class="math notranslate nohighlight">\(QR\)</span>. La m√©thode bas√©e sur <span class="math notranslate nohighlight">\(SVD\)</span> permet d‚Äôobtenir une pseudo-inverse qui fonctionne m√™me si <span class="math notranslate nohighlight">\(X^TX\)</span> poss√®de un d√©terminant nul.</p>
<p>Cela fait qu‚Äôen pratique, sur certains probl√®mes tr√®s mal conditionn√©s, la solution de <span class="math notranslate nohighlight">\(\texttt{LinearRegression}\)</span> ou via <span class="math notranslate nohighlight">\(\texttt{pinv}\)</span> ou via <span class="math notranslate nohighlight">\(\texttt{SVD}\)</span> poss√®dent de bonnes performances en test.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./2_regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="4_algo_proximal_lasso.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Sous-diff√©rentiel et le cas du Lasso ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="6_ridge.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Une analyse de la r√©gularisation Ridge ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏è</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Servajean, Leveau & Chailan<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>