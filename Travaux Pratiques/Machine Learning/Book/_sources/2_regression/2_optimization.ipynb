{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# L'optimisation \u2615\ufe0f\u2615\ufe0f\n", "\n", "\n", "**<span style='color:blue'> Objectifs de la s\u00e9quence</span>** ", "\n", "* \u00catre capable de&nbsp;:\n", "    * De r\u00e9soudre des probl\u00e8mes de la forme $x^\\star=\\text{argmin}_{x\\in\\mathbb{R}^d}f(x)$, avec  $f:\\mathbb{R}^d\\mapsto\\mathbb{R}$\n", "    * Comprendre et d'impl\u00e9menter certains des algorithmes d'optimisation les plus connus,\n", "* D'\u00eatre sensibilis\u00e9s&nbsp;:\n", "    * Aux propri\u00e9t\u00e9s importantes (e.g. convexit\u00e9, Lipschitz),\n", "    * Aux limites des algorithmes,\n", "    * \u00c0 l'optimisation sous contraintes.\n", "    \n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La plupart des algorithmes d'optimisation s'appuient sur des informations du premier ordre (i.e. d\u00e9riv\u00e9es, gradient).\n", "\n", "**<span style='color:blue'> Gradient orthogonal aux lignes de niveau</span>** ", "\n", "Soit $c:\\mathbb{R}^+\\mapsto\\mathbb{R}^d$ un arc param\u00e9tr\u00e9 qui suit une ligne de niveau de $f$ (un arc param\u00e9tr\u00e9 prend en argument le \"temps\" et retourne une coordonn\u00e9e dans l'espace). Si $c$ suit une ligne de niveau, nous avons donc&nbsp;:\n", "\n", "$$f(c(t))=f(c(0))=\\text{const}.$$\n", "\n", "Cela implique que nous ayons aussi&nbsp;:\n", "\n", "$$(f(c(t)))^\\prime=\\langle \\nabla f(c(t)), c^\\prime(t)\\rangle=0,$$\n", "\n", "o\u00f9 $\\nabla f(c(t))$ est le gradient en $c(t)$ et $c^\\prime(t)$ donne la direction de l'arc param\u00e9tr\u00e9 (i.e. de la ligne de niveau) en $c(t)$. Les deux sont bien ainsi orthogonaux.\n", "\n\n ----", "\n", "**<span style='color:blue'> Le gradient est la plus forte pente</span>** ", "\n", "Soit $c:\\mathbb{R}^+\\mapsto\\mathbb{R}^d$ un arc param\u00e9tr\u00e9 et soit $f:\\mathbb{R}^d\\mapsto\\mathbb{R}$. Nous \u00e9tudions l'\u00e9volution de $f$ le long de $c$&nbsp;:\n", "\n", "$$f(c(t)).$$\n", "\n", "L'accroissement de $f$ le long de $c(t)$ est donn\u00e9 par la d\u00e9riv\u00e9e&nbsp;:\n", "\n", "$$(f(c(t))^\\prime=\\langle \\nabla f(c(t)), c^\\prime(t)\\rangle.$$\n", "\n", "Nous avons par Cauchy-Schwartz&nbsp;:\n", "\n", "$$\\lVert\\langle \\nabla f(c), c^\\prime\\rangle\\rVert \\leq \\lVert\\nabla f(c)\\rVert\\lVert c^\\prime\\rVert,$$\n", "\n", "o\u00f9 le gradient et l'arc sont \u00e9valu\u00e9s en $t$. L'\u00e9galit\u00e9 est atteinte lorsque les vecteurs sont colin\u00e9aires. La plus forte pente est donc la direction du gradient.\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Imports et fonction de plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["hide-cell"]}, "outputs": [], "source": ["import matplotlib\n", "import matplotlib.pyplot as plt\n", "from matplotlib import cm\n", "from mpl_toolkits.mplot3d import axes3d, Axes3D\n", "import numpy as np\n", "\n", "# Le code ci-dessous permettra d'afficher notre fonction \u00e0 optimiser\n", "\n", "%matplotlib inline\n", "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n", "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n", "plt.style.use('ggplot')\n", "\n", "def plot_loss_contour(obj_func, param_trace=None, figsize=None, three_dim=False, rotate=12, \n", "                      starting=None, ending=None, constraint=None, title=None):\n", "    \n", "    x, y = np.mgrid[slice(-5, 5 + 0.1, 0.1),\n", "                    slice(-5, 5 + 0.1, 0.1)]\n", "    z = np.zeros(x.shape)\n", "    for i in range(x.shape[0]):\n", "        for j in range(x.shape[1]):\n", "            z[i, j] = obj_func([x[i, j], y[i, j]])\n", "    if figsize is not None:\n", "        f = plt.figure(figsize=figsize)\n", "    else:\n", "        f = plt.figure(figsize=(12.0, 8.0))\n", "    if three_dim:\n", "        ax = Axes3D(f, auto_add_to_figure=False)\n", "        f.add_axes(ax)\n", "    else:\n", "        ax = f.gca()\n", "    \n", "    if three_dim:\n", "        m = ax.plot_surface(x, y, z, cmap=cm.viridis)\n", "    else:\n", "        m = ax.contourf(x, y, z, levels = 15)\n", "    #\n", "    if param_trace is not None:\n", "        if three_dim:\n", "            eps = 0.5\n", "            ax.plot(param_trace[:, 0], param_trace[:, 1], param_trace[:, 2] + eps, \n", "                    color='red')\n", "            ax.view_init(65, rotate)\n", "                \n", "        else:\n", "            if type(param_trace) is not tuple:\n", "                param_trace = [param_trace]\n", "            for p in param_trace:\n", "                p = np.array(p) if type(p) is list else p\n", "                plt.plot(p[:, 0], p[:, 1])\n", "                plt.scatter(p[:, 0], p[:, 1])\n", "            f.colorbar(m)\n", "    if starting is not None:\n", "        if three_dim:\n", "            z = obj_func(starting)\n", "            plt.plot([starting[0], starting[0]], [starting[1], starting[1]], [z, z+0.1], lw=4, \n", "                     color='red', label='Initialisation de l\\'optimisation')\n", "            plt.legend()\n", "        else:\n", "            plt.scatter(starting[0], starting[1], color='red', \n", "                        label='Initialisation de l\\'optimisation')\n", "            plt.legend()\n", "            \n", "    if constraint is not None:\n", "        if not three_dim:\n", "            plt.plot(constraint[:, 0], constraint[:, 1], color='red', label='Contrainte')\n", "            plt.legend()\n", "                \n", "    if ending is not None:\n", "        if three_dim:\n", "            z = obj_func(ending)\n", "            plt.plot([ending[0], ending[0]], [ending[1], ending[1]], [z, z+0.1], lw=4, \n", "                     color='green', label='Solution de l\\'optimisation')\n", "            plt.legend()\n", "        else:\n", "            plt.scatter(ending[0], ending[1], color='green', \n", "                        label='Solution de l\\'optimisation')\n", "            plt.legend()\n", "    plt.xlim(-5, 5)\n", "    plt.ylim(-5, 5)\n", "    if title is not None:\n", "        plt.title(title)\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## I. La descente de gradient (\u00e0 pas constant)\n", "### A. L'algorithme"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consid\u00e9rons la fonction suivante qui admet plusieurs minimums locaux."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def f(x):\n", "    x, y = x\n", "    return np.sqrt((x**2 + y - 2)**2 + (x + y**2 - 7)**2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_loss_contour(f, three_dim=False, starting=[0, 2], \n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il est \u00e9galement possible de la repr\u00e9senter en 3 dimensions."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_loss_contour(f, three_dim=True, starting=[0, 2],\n", "                  title='Carte de chaleur 3D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Dit autrement, nous consid\u00e9rons $f:\\mathbb{R}^2\\mapsto\\mathbb{R}$ d\u00e9finie par $f(x, y)=\\sqrt{(x^2+y-2)^2+(x+y^2-7)^2}$. $f$ est continue et infiniment d\u00e9rivable.\n", "\n", "Nous avons en particulier les d\u00e9riv\u00e9es partielles suivantes&nbsp;: \n", "\n", "\n", "$$\\frac{\\partial f}{\\partial x}(x, y)=\\frac{2x^3+x(2y-3)+y^2-7}{\\sqrt{(x^2+y-2)^2+(x+y^2-7)^2}}$$\n", "\n", "et\n", "\n", "\n", "$$\\frac{\\partial f}{\\partial y}(x, y)=\\frac{x^2+2xy+2y^3-13y-2}{\\sqrt{(x^2+y-2)^2+(x+y^2-7)^2}}.$$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sans hypoth\u00e8se sur la fonction $f$, celle-ci peut \u00eatre tr\u00e8s difficile \u00e0 minimiser. Soit $x^{(0)}\\in\\mathbb{R}^2$, un algorithme permettant de chercher un minimum local en partant de $x^{(0)}$ est la descente de gradient. Ce dernier suppose que nous avons acc\u00e8s aux informations du premier ordre&nbsp;: le gradient $\\nabla f(x, y)$. Rappelons que le gradient est le vecteur construit \u00e0 partir des d\u00e9riv\u00e9es partielles $\\nabla f (x, y) = [\\partial f(x,y)/\\partial x, \\partial f(x, y)/\\partial y]^T$. Ce dernier donne le sens de la plus forte croissance de la fonction $f$. Son oppos\u00e9 donne la plus forte pente. L'id\u00e9e de l'algorithme de descente de gradient est de suivre la direction donn\u00e9e par ce dernier par petits pas. On note $\\boldsymbol{x}=(x,y)$. Nous avons ainsi&nbsp;:\n", "\n", "$$\\boldsymbol{x}^{(t+1)}=\\boldsymbol{x}^{(t)}-\\eta\\nabla f(\\boldsymbol{x}^{(t)})$$\n", "\n", "o\u00f9 $\\eta>0$ est justement un param\u00e8tre permettant de contr\u00f4ler la taille du pas."]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "**<span style='color:blue'> Exercice</span>** ", "**Donnez le code permettant de calculer le gradient de la fonction pr\u00e9c\u00e9dente (en format vecteur ligne).**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def grad(x):\n", "    ####### Complete this part ######## or die ####################\n", "    ...\n", "    ...\n", "    return ...\n", "    ###############################################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "**<span style='color:blue'> Exercice</span>** ", "\n", "**Donnez le code permettant de calculer une it\u00e9ration de l'algorithme de descente de gradient. Attention, on appelle le pas d'optimisation $\\eta$ le *learning rate*.**\n", "\n", "\n\n ----", "\n"]}, {"cell_type": "code", "metadata": {}, "source": ["class GradientDescent(object):\n", "    def optimize(self, learning_rate = 0.1, nb_iterations=15, beta=None):\n", "        # beta est notre variable ! \n", "        # si elle n'est pas fix\u00e9e on la tire au hasard\n", "        if beta is None:\n", "            beta = np.random.uniform(-2, 2, size=2)\n", "\n", "        param_trace = [beta]\n", "        loss_trace = [f(beta)]\n", "        \n", "        for i in range(nb_iterations):\n", "            ####### Complete this part ######## or die ####################\n", "            beta = ...\n", "            ###############################################################\n", "            param_trace.append(beta)\n", "            loss_trace.append(f(beta))\n", "            \n", "        return np.array(param_trace), np.array(loss_trace)\n", "        \n", "gd = GradientDescent()\n", "\n", "p, l = gd.optimize()\n", "\n", "plot_loss_contour(f, param_trace=p, three_dim=False, \n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')\n", "\n", "plot_loss_contour(f, param_trace=np.concatenate([p, l.reshape((l.shape[0], 1))], axis=1), \n", "                  three_dim=True,  title='Carte de chaleur 3D de la fonction \u00e0 optimiser')\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"tags": ["remove-cell"]}, "source": ["# L'affichage suivant interactif va nous permettre de tester les diff\u00e9rents param\u00e8tres de notre optimiseur.\n", "\n", "import ipywidgets as widgets\n", "from IPython.display import display\n", "from IPython.display import clear_output\n", "%matplotlib inline\n", "\n", "output = widgets.Output()\n", "\n", "@output.capture()\n", "def interactive_gradient_descent(x, y, learning_rate, iterations):\n", "    clear_output()\n", "    param_trace , loss_trace = gd.optimize(nb_iterations=iterations,\n", "                                           learning_rate=learning_rate, \n", "                                           beta=np.array([x, y]))\n", "    plot_loss_contour(f, param_trace, figsize=(14.0, 6.0))\n", "    \n", "widgets.interact(interactive_gradient_descent,\n", "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=0.05, step=0.0001, \n", "                                                   continuous_update=False, readout_format='.5f'),\n", "                 x=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 y=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 iterations=widgets.IntSlider(value=10, min=10, max=500, step=1, continuous_update=False)\n", ")\n", "display(output)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### B. Convergence de la descente de gradient\n", "\n", "(ici $\\lVert\\cdot\\rVert=\\lVert\\cdot\\rVert_2$)\n", "\n", "Soit $x^\\star$ la solution de notre probl\u00e8me d'optimisation&nbsp;:\n", "\n", "$$x^\\star=\\text{argmin}_{x\\in\\mathbb{R}^d}f(x),$$\n", "\n", "alors, $\\forall x\\in\\mathbb{R}^d$, nous avons $f(x)-f(x^\\star)\\geq 0$. Notons $x^{(k)}$ notre s\u00e9quence d'it\u00e9r\u00e9s (les pas de notre algorithme de descente de gradient). On dira que notre algorithme converge si nous avons :\n", "\n", "$$f(x^{(k)})-f(x^\\star)\\leq g(t),\\ \\lim_{t\\rightarrow \\infty}g(t)=0.$$\n", "\n", "\n", "\n", "Dit autrement, si l'\u00e9cart entre la valeur de notre fonction atteinte par notre algorithme et la solution optimale tend vers $0$, alors on converge. Notez que nous ne mesurons pas $\\lVert x^{(k)}-x^\\star\\rVert$. En effet, s'il existait une infinit\u00e9 de solutions, alors rien ne nous garantit que nous convergerions vers le $x^\\star$ choisi.\n", "\n", "La convergence de l'algorithme de descente de gradient s'appuie sur une propri\u00e9t\u00e9 appell\u00e9e \"continuit\u00e9 Lipschitz\".\n", "\n", "**<span style='color:blue'> D\u00e9finition (continuit\u00e9 Lipschitz)</span>** ", "\n", "On dit qu'une fonction $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}^p$ est Lipschitz si et seulement si&nbsp;:\n", "\n", "\n", "$$\\lVert f(x_1)-f(x_2)\\rVert\\leq K\\lVert x_1-x_2\\rVert,$$\n", "\n", "et on appelle $K$ constante Lipchitz.\n", "\n", "\n\n ----", "\n", "**<span style='color:blue'> Fonction Lipschitz et d\u00e9riv\u00e9e</span>** ", "Soit $f:\\mathbb{R}\\mapsto\\mathbb{R}$ une fonction K-Lipschitz. On a donc pour $h\\in\\mathbb{R}$&nbsp;:\n", "\n", "$$| f(x+h)-f(x)|\\leq K| h|,$$\n", "\n", "ce qui est \u00e9quivalent \u00e0\n", "\n", "$$\\Big|\\frac{f(x+h)-f(x)}{h}\\Big|\\leq K.$$\n", "\n", "\n", "Si on prend la limite de $h$ en $0$, alors c'est la d\u00e9finition de la d\u00e9riv\u00e9e qui est donc major\u00e9e par $K$. Cette id\u00e9e se g\u00e9n\u00e9ralise avec le gradient.\n", "\n\n ----", "\n", "---\n", "\n", "**<span style='color:blue'> Exercice </span>** ", "\n", "**Soit la fonction $f(x)=x^2$ sur $\\mathbb{R}$. Montrer que $f$ n'est pas Lipschitz mais que $f^\\prime$ l'est.**\n", "\n", "\n\n ----", "\n", "\n", "\n", "\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notre algorithme d'optimisation suit le gradient afin de minimiser une fonction de co\u00fbt. Cependant, notre fonction pourrait tr\u00e8s bien avoir une multitudes de minimum locaux voire pas de minimum du tout. La d\u00e9finition suivante nous permet de d\u00e9finir une propri\u00e9t\u00e9 suffisante pour qu'atteindre un minimum local soit acceptable.\n", "\n", "\n", "**<span style='color:blue'> D\u00e9finition (fonction convexe)</span>** ", "Soit $f:\\mathcal{X}\\mapsto\\mathbb{R}$, $x, y\\in\\mathcal{X}$ et $\\lambda\\in[0, 1]$. On dira que $f$ est convexe si&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "f(\\lambda x+ (1-\\lambda)y)&\\leq \\lambda f(x)+(1-\\lambda) f(y)\n", "\\end{aligned}$$\n", "\n", "La convexit\u00e9 ne garantit pas l'existence d'un minimum ni son unicit\u00e9 mais l'\u00e9quivalence entre minimum local et minimum global.\n", "\n", "La convexit\u00e9 stricte est donn\u00e9e par&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "f(\\lambda x+ (1-\\lambda)y)&< \\lambda f(x)+(1-\\lambda) f(y)\n", "\\end{aligned}$$\n", "\n", "qui elle implique l'unicit\u00e9 du minimum s'il existe.\n", "\n\n ----", "\n", "Ainsi, si notre algorihtme trouve un minimum local, alors ce dernier est soit unique - convexit\u00e9 stricte - ou \u00e0 minima, minimise notre fonction objectif. Attention, la convexit\u00e9 ne garantit jamais l'existence de ce minium. Pour cela, il faut une autre propri\u00e9t\u00e9.\n", "\n", "**<span style='color:blue'> D\u00e9finition (fonction coercive)</span>** ", "Une fonction $f$ est coercive si&nbsp;:\n", "\n", "$$\\lim_{\\lVert x\\rVert\\rightarrow\\infty}f(x)=\\infty.$$\n", "\n", "Si notre fonction est propre (ne vaut pas partout $+\\infty$ et n'atteint pas $-\\infty$) et convexe, alors la coercivit\u00e9 implique l'existence d'un minimum. Une fonction propre strictement convexe poss\u00e8de donc un unique minimum.\n", "\n\n ----", "\n", "La convexit\u00e9 est une propri\u00e9t\u00e9 suffisante pour garantir la \"qualit\u00e9\" d'un minimum. Dans la cadre des fonctions strictement convexes, la coercivit\u00e9 est une propri\u00e9t\u00e9 n\u00e9cessaire et suffisante pour garantir l'existence d'un minimum.\n", "\n", "Cela nous am\u00e8ne ainsi au th\u00e9or\u00e8me suivant illustrant la convergence d'un tel algorithme d'optimisation.\n", "\n", "**<span style='color:blue'> Th\u00e9or\u00e8me (convergence de la descente de gradient)</span>** ", "\n", "Soit $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ notre fonction \u00e0 optimiser, convexe et diff\u00e9rentiable, $x^\\star$ une solution du probl\u00e8me et supposant $\\nabla f$ Lipchitz de constante $L$ ($\\lVert\\nabla f(x_1)-\\nabla f(x_2)\\rVert\\leq L\\lVert x_1-x_2\\rVert$). Fixons le pas d'optimisation $\\eta \\leq 1/L$. Alors, nous avons :\n", "\n", "\n", "\n", "\n", "$$f(x^{(k)})-f(x^\\star)\\leq \\frac{\\lVert x^{(0)}-x^\\star\\rVert^2}{2 k\\eta},$$\n", "\n", "o\u00f9, le num\u00e9rateur \u00e9tant constant, la partie \u00e0 droite converge vers $0$ \u00e0 une vitesse proportionnelle \u00e0 $1/k$.\n", "\n", "\n", "\n", "\n", "\n\n ----", "\n", "\n", "**<span style='color:orange'> Preuve</span>** ", "\n", "Soit $x_1, x_2\\in\\mathbb{R}^d$ et notons $h=x_1-x_2$. Nous avons :\n", "\n", "$$\\begin{aligned}\n", "f(x_2+h)&=f(x_2)+\\int_0^1\\langle \\nabla f(x_2+th), h\\rangle dt\\\\\n", "\\Leftrightarrow f(x_2+h)-f(x_2)&=\\int_0^1\\langle \\nabla f(x_2+th), h\\rangle dt\\\\\n", "\\Leftrightarrow f(x_2+h)-f(x_2)-\\int_0^1\\langle \\nabla f(x_2), h\\rangle dt&=\\int_0^1\\langle \\nabla f(x_2+th), h\\rangle dt-\\int_0^1\\langle \\nabla f(x_2), h\\rangle dt\\\\\n", "\\Leftrightarrow f(x_2+h)-f(x_2)-\\langle \\nabla f(x_2), h\\rangle&=\\int_0^1\\langle \\nabla f(x_2+th)-\\nabla f(x_2), h\\rangle dt.\n", "\\end{aligned}$$\n", "\n", "Consid\u00e9rons la partie dans l'int\u00e9grale et appliquons [Cauchy-Schwartz](https://fr.wikipedia.org/wiki/In\u00e9galit\u00e9_de_Cauchy-Schwarz) et utilisons la continuit\u00e9 Lipschitz \n", "\n", "$$\\begin{aligned}\n", "\\langle f(x_2+th)-\\nabla f(x_2), h\\rangle\\leq \\lVert f(x_2+th)-\\nabla f(x_2)\\rVert\\lVert h\\rVert \\leq Lt\\lVert h\\rVert^2.\n", "\\end{aligned}$$\n", "\n", "Nous avons ainsi:\n", "\n", "$$\\begin{aligned}\n", "\\int_0^1\\langle f(x_2+th)-\\nabla f(x_2), h\\rangle dt&\\leq \\int_0^1 Lt\\lVert h\\rVert^2dt = \\frac{L}{2}\\lVert h\\rVert^2.\n", "\\end{aligned}$$\n", "\n", "En combinant le tout, nous avons (1) :\n", "\n", "$$\\begin{align}\n", "f(x_2+h)-f(x_2)-\\langle \\nabla f(x_2), h\\rangle\\leq \\frac{L}{2}\\lVert h\\rVert^2\\\\\n", "\\Leftrightarrow f(x_1)\\leq f(x_2)+\\langle \\nabla f(x_2), x_1-x_2\\rangle+\\frac{L}{2}\\lVert x_1-x_2\\rVert^2\n", "\\end{align}$$\n", "\n", "Reprenons notre formule et rempla\u00e7ons $x^{(k+1)}=x_1$ et $x^{(k)}=x_2$. Nous avons bien s\u00fbr $x^{(k+1)}=x^{(k)}-\\eta\\nabla f(x^{(k)})$. Nous avons&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "f(x^{(k+1)})&\\leq f(x^{(k)})+\\langle \\nabla f(x^{(k)}), x^{(k+1)}-x^{(k)}\\rangle+\\frac{L}{2}\\lVert x^{(k+1)}-x^{(k)}\\rVert^2\\\\\n", "&=f(x^{(k)})+\\langle \\nabla f(x^{(k)}), x^{(k)}-\\eta\\nabla f(x^{(k)})-x^{(k)}\\rangle+\\frac{L}{2}\\lVert x^{(k)}-\\eta\\nabla f(x^{(k)})-x^{(k)}\\rVert^2\\\\\n", "&=f(x^{(k)})-\\eta\\langle \\nabla f(x^{(k)}), \\nabla f(x^{(k)})\\rangle+\\frac{L\\eta^2}{2}\\lVert\\nabla f(x^{(k)})\\rVert^2\\\\\n", "&=f(x^{(k)})-\\eta\\lVert \\nabla f(x^{(k)})\\rVert^2+\\frac{L\\eta^2}{2}\\lVert\\nabla f(x^{(k)})\\rVert^2\\\\\n", "&=f(x^{(k)})-\\eta(1-\\frac{L\\eta}{2})\\lVert\\nabla f(x^{(k)})\\rVert^2\n", "\\end{aligned}$$\n", "\n", "Rappelons que par hypoth\u00e8se, nous avons $\\eta\\leq 1/L$. Cela implique que&nbsp;:\n", "\n", "$$-(1-\\frac{L\\eta}{2})=\\frac{1}{2}L\\eta-1\\leq \\frac{1}{2}-1=-\\frac{1}{2}.$$ \n", "\n", "Ainsi, nous avons (2)&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "f(x^{(k+1)})&\\leq f(x^{(k)})-\\frac{\\eta}{2}\\lVert\\nabla f(x^{(k)})\\rVert^2.\n", "\\end{aligned}$$\n", "\n", "On remarque ainsi que le pas de descente de gradient ne peut QUE d\u00e9cro\u00eetre la fonction objectif \u00e0 moins que le gradient soit nul et l'algorithme reste constant. Cela est d\u00fb \u00e0 la continuit\u00e9 Lipschitz et au choix appropri\u00e9 du pas $\\eta$.\n", "\n", "Rappelons que $f$ est convexe impliquant les deux in\u00e9galit\u00e9s suivantes&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "f(x^\\star)&\\geq f(x)+\\langle \\nabla f(x), x^\\star-x\\rangle\\\\\n", "f(x)&\\leq f(x^\\star)+\\langle \\nabla f(x), x-x^\\star\\rangle\\text{ (en multipliant par -1).}\n", "\\end{aligned}$$\n", "\n", "En r\u00e9cup\u00e9rant l'in\u00e9galit\u00e9 (2), nous avons&nbsp;:\n", "\n", "\n", "$$\\begin{aligned}\n", "f(x^{(k+1)})&\\leq f(x^{(k)})-\\frac{\\eta}{2}\\lVert\\nabla f(x^{(k)})\\rVert^2\\\\\n", "&\\leq f(x^\\star)+\\langle \\nabla f(x^{(k)}), x^{(k)}-x^\\star\\rangle-\\frac{\\eta}{2}\\lVert\\nabla f(x^{(k)})\\rVert^2\\\\\n", "\\Leftrightarrow f(x^{(k+1)}) - f(x^\\star) &\\leq \\frac{1}{2\\eta}\\big(2\\eta\\langle \\nabla f(x^{(k)}), x^{(k)}-x^\\star\\rangle-\\eta^2\\lVert\\nabla f(x^{(k)})\\rVert^2\\big)\\\\\n", "\\Leftrightarrow f(x^{(k+1)}) - f(x^\\star) &\\leq \\frac{1}{2\\eta}\\big(2\\eta\\langle \\nabla f(x^{(k)}), x^{(k)}-x^\\star\\rangle-\\eta^2\\lVert\\nabla f(x^{(k)})\\rVert^2\\\\\n", "&\\ \\ - \\lVert x^{(k)}-x^\\star\\rVert^2+\\lVert x^{(k)}-x^\\star\\rVert^2\\big)\\\\\n", "&=\\frac{1}{2\\eta}\\big(\\lVert x^{(k)}-x^\\star\\rVert^2-\\lVert x^{(k)}-\\eta\\nabla f(x^{(k)})-x^\\star\\rVert^2\\big)\\\\\n", "&=\\frac{1}{2\\eta}\\big(\\lVert x^{(k)}-x^\\star\\rVert^2-\\lVert x^{(k+1)}-x^\\star\\rVert^2\\big)\n", "\\end{aligned}$$\n", "\n", "L'in\u00e9galit\u00e9 pr\u00e9c\u00e9dente est vraie pour tout $k\\in\\mathbb{N}$. Nous avons donc aussi l'in\u00e9galit\u00e9 suivante&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "\\sum_{t=0}^k f(x^{(t+1)}) - f(x^\\star) &\\leq \\sum_{t=0}^k\\frac{1}{2\\eta}\\big(\\lVert x^{(t)}-x^\\star\\rVert^2-\\lVert x^{(t+1)}-x^\\star\\rVert^2\\big)\\\\\n", "&=\\frac{1}{2\\eta}\\big(\\lVert x^{(0)}-x^\\star\\rVert^2\\\\&\\ \\ -\\lVert x^{(k+1)}-x^\\star\\rVert^2\\big)\\text{ (les termes de la somme se t\u00e9l\u00e9scopent)}\\\\\n", "&\\leq \\frac{1}{2\\eta}\\lVert x^{(0)}-x^\\star\\rVert^2\n", "\\end{aligned}$$\n", "\n", "Nous avons ainsi&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "\\sum_t f(x^{(k+1)})-f(x^\\star)&\\leq \\sum_t f(x^{(t+1)}) - f(x^\\star)\\text{ (GD ne peut que am\u00e9liorer la fonction objectif)}\\\\\n", "\\Leftrightarrow f(x^{(k+1)})-f(x^\\star)&\\leq \\frac{1}{k+1}\\sum_t  f(x^{(t+1)}) - f(x^\\star)\\leq \\frac{\\lVert x^{(0)}-x^\\star\\rVert^2}{2\\eta(k+1)},\n", "\\end{aligned}$$\n", "\n", "ce qui conclut la preuve.\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## II. La descente de gradient \u00e0 pas optimal"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dans le sc\u00e9nario pr\u00e9c\u00e9dent, nous avons du fixer un pas d'optimisation $\\eta$ arbitraire. Ce dernier doit \u00eatre suffisament petit pour garantir que l'algorithme converge et suffisamment grand pour que l'optimisation se fasse. Il est possible de d\u00e9finir une notion de pas d'optimisation optimal. Cependant, celle-ci est souvent intractable en pratique (trouver le pas est plus couteux que l'optimisation initiale). Dans certains cas, nous pouvons n\u00e9anmoins le d\u00e9terminer. C'est ce que nous allons faire ici. Consid\u00e9rons maintenant la fonction suivante&nbsp;:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["A = np.array([[1, 0], [0, 2]])\n", "b = np.array([[2], [1]])\n", "\n", "def f(x):\n", "    if type(x) is np.ndarray:\n", "        x = x.tolist()\n", "    return (np.dot(np.dot(A, x).T, x)*0.5+np.dot(b.T, x))[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_loss_contour(f, three_dim=False, starting=[0, 2], \n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')\n", "plot_loss_contour(f, three_dim=True, starting=[4, 4], \n", "                  title='Carte de chaleur 3D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["L'algorithme de descente de gradient nous permet d'avancer dans la bonne direction. Cependant, le choix du pas $\\eta$ peut nous sembler insuffisant. \n", "\n", "Soit $\\boldsymbol{\\nu}=[x, y]^T$, la direction d'optimisation $\\boldsymbol{d}^{(k)}=-\\nabla f(\\boldsymbol{\\nu}^{(k)})$ et la fonction $\\gamma:t\\mapsto f(\\boldsymbol{\\nu}^{(k)}+t\\boldsymbol{d}^{(k)})$. La valeur de $t$ qui minimise la fonction $\\gamma$ est un pas optimal pour une minimisation dans la direction du gradient. Sans contrainte particuli\u00e8re sur la fonction $f$, $\\gamma$ pourrait admettre un certain nombre de points critiques de natures et de valeurs diff\u00e9rentes.\n", "\n", "Les points critiques sont les points d'annulation de la d\u00e9riv\u00e9e : $\\{t\\in\\mathbb{R}:\\ \\gamma^\\prime(t)=0\\}$. On obtient assez facilement la d\u00e9riv\u00e9e de la mani\u00e8re suivante&nbsp;:\n", "\n", "$$\\gamma^\\prime(t)=\\frac{\\partial f}{\\partial x}\\left(\\boldsymbol{\\nu}^{(k)}+t\\boldsymbol{d}^{(k)}\\right)\\frac{\\partial f}{\\partial x}\\left(\\boldsymbol{\\nu}^{(k)}\\right)+\\frac{\\partial f}{\\partial y}\\left(\\boldsymbol{\\nu}^{(k)}+t\\boldsymbol{d}^{(k)}\\right)\\frac{\\partial f}{\\partial y}\\left(\\boldsymbol{\\nu}^{(k)}\\right)$$\n", "\n", "On remarque que r\u00e9soudre cette \u00e9quation est rapidement probl\u00e9matique et n\u00e9cessite l'utilisation d'un autre algorithme de descente de gradient. En r\u00e9alit\u00e9, il y a grossi\u00e8rement deux possibilit\u00e9s :\n", "1. On peut trouver une valeur $t$ analytiquement et c'est le choix qu'on doit faire,\n", "2. Il n'est pas possible de calculer $t$ et on doit le calculer num\u00e9riquement. Cependant, si on doit le calculer num\u00e9riquement, alors, il devient n\u00e9cessaire de calculer le gradient \u00e0 chaque \u00e9tape, et dans ce cas, pourquoi ne pas juste se d\u00e9placer dans l'espace des param\u00e8tres avec notre vecteur $\\boldsymbol{[x, y]}$ ce qui nous donnerait une meilleure direction dans l'espace des param\u00e8tres...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il se trouve que la fonction d\u00e9finie ci-dessus est : $f(\\boldsymbol{x})=\\frac{1}{2}\\langle Ax, x\\rangle+\\langle b, x\\rangle$ o\u00f9&nbsp;:\n", "\n", "\n", "$$A=\\begin{bmatrix} 1& 0\\\\ 0& 2\\end{bmatrix}$$\n", "\n", "est sym\u00e9trique d\u00e9finie positive et \n", "\n", "\n", "$$b=\\begin{bmatrix}2\\\\1\\end{bmatrix}$$\n", "\n", "Notons \n", "\n", "$$\\begin{aligned}\n", "f(\\boldsymbol{x}+t\\boldsymbol{d})&=\\frac{1}{2}\\langle A(x+t\\boldsymbol{d}), x+t\\boldsymbol{d}\\rangle+\\langle b, x+t\\boldsymbol{d}\\rangle\\\\\n", "&=\\frac{1}{2}(\\langle A\\boldsymbol{x},\\boldsymbol{x}\\rangle+t\\langle A\\boldsymbol{d},\\boldsymbol{x}\\rangle+t\\langle A\\boldsymbol{x},\\boldsymbol{d}\\rangle+t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle)+\\langle \\boldsymbol{b},\\boldsymbol{x}\\rangle+t\\langle \\boldsymbol{b},\\boldsymbol{d}\\rangle\\\\\n", "&=f(\\boldsymbol{x})+\\frac{1}{2} t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle+t\\langle A\\boldsymbol{x}+\\boldsymbol{b},\\boldsymbol{d}\\rangle\n", "\\end{aligned}$$\n", "\n", "Notons de plus que $\\partial f(\\boldsymbol{x})/\\partial \\boldsymbol{x}=A\\boldsymbol{x}+\\boldsymbol{b}=-\\boldsymbol{d}$. Nous avons donc&nbsp;:\n", "\n", "\n", "$$f(\\boldsymbol{x}+t\\boldsymbol{d})=f(\\boldsymbol{x})+\\frac{1}{2} t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle-t\\langle \\boldsymbol{d},\\boldsymbol{d}\\rangle=f(\\boldsymbol{x})+\\frac{1}{2} t^2\\langle A\\boldsymbol{d},\\boldsymbol{d}\\rangle-\\left\\lVert\\boldsymbol{d}\\right\\lVert^2 t$$\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La direction $\\boldsymbol{d}=-\\nabla f(\\boldsymbol{x})$ est celle qui indique la plus forte pente. La variable $t$ recherch\u00e9e indique la taille du pas que l'on souhaite faire. Pour cela, nous devons chercher les points critiques de la fonction $\\gamma(t)=f(\\boldsymbol{x}+t\\boldsymbol{d})$ qui sont donn\u00e9s en recherchant les points d'annulation de la d\u00e9riv\u00e9e. De plus, $A$ (la Hessienne) \u00e9tant d\u00e9finie positive, nous savons que ces points critiques seront des minimums. Nous avons donc&nbsp;:\n", "\n", "$$\\frac{\\partial \\gamma}{\\partial t}(t)=t\\langle A\\boldsymbol{d}, \\boldsymbol{d}\\rangle - \\left\\lVert\\boldsymbol{d}\\right\\lVert^2=0$$\n", "\n", "Et le point critique est donn\u00e9 par&nbsp;:\n", "\n", "$$t=\\frac{\\left\\lVert\\boldsymbol{d}\\right\\lVert^2}{\\langle A\\boldsymbol{d}, \\boldsymbol{d}\\rangle}$$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Donnez le code permettant de calculer le gradient (i.e. la direction d'optimisation).**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def grad(x):\n", "    ####### Complete this part ######## or die ####################\n", "    return ...\n", "    ###############################################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Donnez le code permettant de calculer une it\u00e9ration de l'algorithme de descente de gradient avec un pas optimal.**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["class OptimalStepGradientDescent(object):\n", "    def optimize(self, learning_rate=0.1, nb_iterations=15, beta=None):\n", "        if beta is None:\n", "            beta = np.random.uniform(-2, 2, size=(2, 1))\n", "        else:\n", "            beta = beta.reshape((2, 1))\n", "            \n", "        beta2 = beta.copy()\n", "\n", "        param_trace = [beta]\n", "        param_trace2 = [beta2]\n", "        loss_trace = [f(beta)]\n", "        loss_trace2 = [f(beta2)]\n", "        it = 0\n", "        stop = False\n", "        \n", "        for i in range(nb_iterations):\n", "            d = -grad(beta)\n", "            if d[0, 0] == d[1, 0] == 0.:\n", "                stop = True\n", "            else:\n", "                ####### Complete this part ######## or die ####################\n", "                t = ...\n", "                beta = ...\n", "                ###############################################################\n", "                \n", "                param_trace.append(beta)\n", "                loss_trace.append(f(beta))\n", "            \n", "            # cette partie du code permet de calculer le gradient classique\n", "            # afin que nous puissions le comparer avec la descente de gradient\n", "            # \u00e0 pas optimal.\n", "            beta2 = beta2 - learning_rate * grad(beta2)\n", "            param_trace2.append(beta2)\n", "            loss_trace2.append(f(beta2))\n", "            it += 1\n", "        return (np.array(param_trace), np.array(loss_trace), \n", "                np.array(param_trace2), np.array(loss_trace2))\n", "        \n", "gd = OptimalStepGradientDescent()\n", "\n", "p1, _, p2, _ = gd.optimize(learning_rate=0.1, nb_iterations=50, beta=np.array([2, 2]))\n", "\n", "plot_loss_contour(f, (p1, p2), figsize=(14.0, 6.0))\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"tags": ["remove-cell"]}, "source": ["# L'affichage suivant interactif va nous permettre de tester les diff\u00e9rents param\u00e8tres de notre optimiseur.\n", "\n", "import ipywidgets as widgets\n", "from IPython.display import display\n", "from IPython.display import clear_output\n", "%matplotlib inline\n", "\n", "output = widgets.Output()\n", "\n", "@output.capture()\n", "def interactive_gradient_descent(learning_rate, x, y, iterations):\n", "    clear_output()\n", "    p1, l1, p2, l2 = gd.optimize(learning_rate=learning_rate, nb_iterations=iterations,\n", "                                           beta=np.array([x, y]))\n", "    plot_loss_contour(f, (p1, p2), figsize=(14.0, 6.0))\n", "    \n", "widgets.interact(interactive_gradient_descent,\n", "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=1., step=0.0001, \n", "                                                   continuous_update=False, readout_format='.5f'),\n", "                 x=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 y=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 iterations=widgets.IntSlider(value=1, min=1, max=20, step=1, continuous_update=False)\n", ")\n", "display(output)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["--- \n", "\n", "**<span style='color:blue'> Exercice (dur)</span>** ", "\n", "**Soit $A\\in\\mathcal{S}_n(\\mathbb{R})$, $b\\in\\mathbb{R}^n$. Montrer que notre fonction&nbsp;:**\n", "\n", "$$\\begin{aligned}f:\\mathbb{R}^n&\\rightarrow \\mathbb{R}\\\\\n", "x&\\mapsto \\frac{1}{2}x^TAx-b^Tx\\end{aligned}$$\n", "\n", "**admet un *unique minimum* si, et seulement si $\\text{Sp}(A)\\subset\\mathbb{R}^+$ et $b\\in\\text{Im}(A)$.**\n", "\n", "\n\n ----", "\n", "**<span style='color:green'> Indices</span>** ", "Rappelons que $\\mathcal{S}_n(\\mathbb{R})$ repr\u00e9sente les matrices r\u00e9elles sym\u00e9triques de taille $n\\times n$, $\\text{Sp}(A)$ est le spectre de $A$ (i.e. ses valeurs propres) et $\\text{Im}(A)$, l'image de $A$.\n", "\n\n ----", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## III. La descente de gradient stochastique (SGD)\n", "\n", "En *machine learning*, la fonction que nous souhaitons optimiser a la forme suivante&nbsp;:\n", "\n", "$$J(\\theta)=\\frac{1}{n}\\sum_{i=1}^n \\ell(h_\\theta(x_i), y_i),$$\n", "\n", "o\u00f9 $h_\\theta$ est une fonction param\u00e9tris\u00e9e par $\\theta$ et $\\ell$ une fonction qui quantifie l'erreur \u00e9l\u00e9mentaire de notre mod\u00e8le pour un point donn\u00e9. La descente de gradient n\u00e9cessite l'\u00e9valuation du gradient de cette derni\u00e8re&nbsp;:\n", "\n", "$$\\nabla J(\\theta)=\\frac{1}{n}\\sum_{i=1}^n \\nabla \\ell(h_\\theta(x_i), y_i).$$\n", "\n", "Si $n$ est grand, alors l'\u00e9valuation du gradient est couteuse. On pourrait m\u00eame imaginer un sc\u00e9nario o\u00f9 la collecte des donn\u00e9es s'effectue en continue et o\u00f9 $n\\rightarrow\\infty$. Le calcul du gradient serait alors tout simplement impossible. La solution consiste \u00e0 ne calculer \u00e0 chaque it\u00e9ration le gradient que sur un unique point de notre jeu de donn\u00e9es&nbsp;:\n", "\n", "$$\\hat{\\nabla}J(\\theta)=\\nabla \\ell(h_\\theta(x_i), y_i),\\ i\\in\\{1, \\ldots, n\\}.$$\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "**Montrer que l'esp\u00e9rance du gradient sur un point ou sur tout le jeu de donn\u00e9es est la m\u00eame.**\n", "\n", "\n\n ----", "\n", "\n", "\n", "Ainsi, l'estimation du gradient est $n$ fois plus rapide que sur le jeu de donn\u00e9es complet.\n", "\n", "\n", "Une situation interm\u00e9diaire consiste \u00e0 calculer le gradient sur un batch de donn\u00e9es de taille $b$ (i.e. *batch size*)&nbsp;:\n", "\n", "$$\\hat{\\nabla}J(\\theta)=\\frac{1}{b}\\sum_{i\\in I_b}\\nabla \\ell(h_\\theta(x_i), y_i),\\ I_b\\subseteq\\{1, \\ldots, n\\},\\ |I_b|=b.$$\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "**Montrer que l'esp\u00e9rance du gradient calcul\u00e9 sur un *batch* ou sur tout le jeu de donn\u00e9es est la m\u00eame.**\n", "\n\n ----", "\n", "\n", "\n", "Quelque soit la strat\u00e9gie, la strat\u00e9gie peut \u00eatre avec ou sans remise. Les approches de type *deep learning* pr\u00e9f\u00e8rent souvent celle sans remise. Lorsque tout le jeu de donn\u00e9e a \u00e9t\u00e9 vu, on dit qu'il s'est pass\u00e9 une *epoch*. Et lorsqu'une *epoch* se termine, le jeu de donn\u00e9es peut \u00eatre re-parcouru tel quel ou m\u00e9lang\u00e9 avant d'\u00eatre re-parcouru. La seconde strat\u00e9gie est souvent pr\u00e9f\u00e9r\u00e9e.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "n = 100\n", "\n", "X = np.random.randn(n, 2)\n", "y = np.random.randn(n)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Compl\u00e9tez le code suivant afin de pouvoir jouer sur la taille des batchs dans le calcul du gradient.**\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["####### Complete this part ######## or die ####################\n", "class LeastSquare(object):\n", "    def __init__(self, X, y):\n", "        self.X=X\n", "        self.y = LeastSquare._format_ndarray(y)\n", "        \n", "    def _format_ndarray(arr):\n", "        arr = np.array(arr) if type(arr) is not np.ndarray else arr\n", "        return arr.reshape((arr.shape[0], 1)) if len(arr.shape) == 1 else arr\n", "    \n", "    def __call__(self, beta):\n", "        # Cette m\u00e9thode calcule la valeur de la fonction\n", "        beta = LeastSquare._format_ndarray(beta)\n", "        prediction = np.dot(beta.T, self.X.T)\n", "        errors = np.power(prediction - self.y.T, 2)\n", "        val = errors.sum()/(2*self.X.shape[0])\n", "        \n", "        return val\n", "    \n", "    def grad(self, beta):\n", "            \n", "        X, y = self.X, self.y\n", "\n", "        beta = LeastSquare._format_ndarray(beta)\n", "        \n", "        grad = (np.dot(np.dot(X.T, X), beta)-np.dot(X.T, y))/X.shape[0]\n", "        return grad\n", "    \n", "    def optimize(self, lr=0.1, nb_iterations=10, beta=None):\n", "        # beta est notre variable ! \n", "        # si elle n'est pas fix\u00e9e on la tire au hasard\n", "        if beta is None:\n", "            beta = np.random.uniform(-2, 2, size=2)\n", "\n", "        param_trace = [beta]\n", "        loss_trace = [self(beta)]\n", "        \n", "        for i in range(nb_iterations):\n", "            beta = beta - lr * self.grad(beta).ravel()\n", "\n", "            param_trace.append(beta)\n", "            loss_trace.append(self(beta))\n", "        return np.array(param_trace), np.array(loss_trace)\n", "    \n", "###############################################################\n", "l = LeastSquare(X, y)\n", "plot_loss_contour(l, three_dim=True)\n", "plot_loss_contour(l, three_dim=False)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["gd = LeastSquare(X, y)\n", "sgd = LeastSquare(X, y)\n", "\n", "p1, l1 = gd.optimize(\n", "    lr=0.1, nb_iterations=50, beta=np.array([4, 4])\n", ")\n", "p2, l2 = sgd.optimize(\n", "    lr=0.1, nb_iterations=50, \n", "    beta=np.array([4, 4]), batch_size=1\n", ")\n", "plot_loss_contour(gd, (p1, p2), figsize=(14.0, 6.0))\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"tags": ["remove-cell"]}, "source": ["# L'affichage suivant interactif va nous permettre de tester les diff\u00e9rents param\u00e8tres de notre optimiseur.\n", "\n", "import ipywidgets as widgets\n", "from IPython.display import display\n", "from IPython.display import clear_output\n", "%matplotlib inline\n", "\n", "output = widgets.Output()\n", "\n", "\n", "\n", "@output.capture()\n", "def interactive_gradient_descent(learning_rate, x, y, iterations, batch_size):\n", "    clear_output()\n", "    p1, l1 = gd.optimize(lr=learning_rate, nb_iterations=iterations, beta=np.array([x, y]))\n", "    p2, l2 = sgd.optimize(\n", "        lr=learning_rate, nb_iterations=iterations, \n", "        beta=np.array([x, y]), batch_size=batch_size)\n", "    plot_loss_contour(gd, (p1, p2), figsize=(14.0, 6.0))\n", "    \n", "widgets.interact(interactive_gradient_descent,\n", "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=1., step=0.0001, \n", "                                                   continuous_update=False, readout_format='.5f'),\n", "                 x=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 y=widgets.FloatSlider(value=0, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 iterations=widgets.IntSlider(value=1, min=1, max=20, step=1, continuous_update=False),\n", "                 batch_size=widgets.IntSlider(value=1, min=1, max=n, step=1, continuous_update=False)\n", ")\n", "display(output)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## IV. La m\u00e9thode de Newton"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Introduction\n", "L'\u00e9l\u00e9ment de base de la m\u00e9thode de Newton est le d\u00e9veloppement limit\u00e9 d'une fonction $f$ en $x_0$. Soit $f\\in C^n(\\mathbb{R})$ une fonction $n$ fois d\u00e9rivable de d\u00e9riv\u00e9e $n^{eme}$ continue de $\\mathbb{R}$ dans $\\mathbb{R}$, son d\u00e9veloppement limit\u00e9 \u00e0 l'ordre $n$ est donn\u00e9 par la formule suivante&nbsp; :\n", "\n", "$$f(x)=\\sum_{i=1}^n \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n+o\\big((x-x_0)^n\\big)$$\n", "\n", "Ainsi, la tangente \u00e0 notre fonction au point $x_0$, ou approximation lin\u00e9aire de notre fonction en $x_0$, est donn\u00e9e par&nbsp;:\n", "\n", "\n\n ----", "\n", "La m\u00e9thode de Newton vient bien d'Isaac Newton ainsi que de Joseph Raphson.\n", "\n", "\n\n ----", "\n", "\n", "$$f(x)\\approx f(x_0)+f^\\prime(x_0)(x-x_0)$$\n", "\n", "et l'approximation \u00e0 l'ordre $2$ par&nbsp;:\n", "\n", "$$f(x)\\approx f(x_0)+f^\\prime(x_0)(x-x_0)+\\frac{f^{\\prime\\prime}(x_0)}{2}(x-x_0)^2$$\n", "\n", "\n", "Ces id\u00e9es se g\u00e9n\u00e9ralisent \u00e0 des fonctions $f:\\mathbb{R}^n\\mapsto\\mathbb{R}$&nbsp;:\n", "\n", "$$f(x)\\approx f(x_0)+\\langle \\nabla f(x_0), x-x_0\\rangle + \\frac{1}{2} (x-x_0)^TH_f(x-x_0)$$\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### La m\u00e9thode\n", "Soit $f:\\mathbb{R}\\mapsto\\mathbb{R}$ une fonction deux fois d\u00e9rivables de d\u00e9riv\u00e9e seconde continue, l'objectif de la m\u00e9thode de Newton est de minimiser $f$&nbsp;:\n", "\n", "$$\\min_{x\\in\\mathbb{R}}f(x)$$\n", "\n", "Supposons de plus $f$ strictement convexe. Cette minimisation est s\u00e9quentielle est produit une suite d'it\u00e9r\u00e9s $\\{x_0, x_1, ..., x_k\\}$ o\u00f9 $x_0$ est notre point de d\u00e9part. chaque it\u00e9r\u00e9 se rapproche un peu plus du minimiseur recherche $x^\\star$.\n", "\n", "\u00c0 chaque it\u00e9r\u00e9e, l'approximation \u00e0 l'ordre $2$ de $f$ est elle-m\u00eame une fonction (strictement) convexe et coercive. Elle admet donc un minimum que l'on peut trouver en annulant la d\u00e9riv\u00e9e&nbsp;:\n", "\n", "$$f(x_k+t)\\approx f(x_k)+f^\\prime(x_k)t+\\frac{f^{\\prime\\prime}(x_k)}{2}t^2$$\n", "\n", "On a donc&nbsp;:\n", "\n", "$$\\frac{d}{dt}(f(x_k)+f^\\prime(x_k)t+\\frac{f^{\\prime\\prime}(x_k)}{2}t^2)=f^\\prime(x_k)+f^{\\prime\\prime}(x_k)t=0\\Leftrightarrow t=-\\frac{f^\\prime(x_k)}{f^{\\prime\\prime}(x_k)}$$\n", "\n", "Ce qui nous permet de fixer l'it\u00e9r\u00e9 suivant&nbsp;: $x_{k+1}=x_k-f^\\prime(x_k)/f^{\\prime\\prime}(x_k)$.\n", "\n", "Cette m\u00e9thode se g\u00e9n\u00e9ralise bien s\u00fbr \u00e0 des fonctions \u00e0 plusieurs variables comme nous allons le voir lors d'une autre section."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consid\u00e9rons la fonction suivante&nbsp;:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def f(x):\n", "    return np.power(x-0.85, 2) + 12+np.power(x, 4)+np.exp(x)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_start = -2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_curve(x_start, optimization_steps=None):\n", "    x = np.linspace(-3, 3, 301)\n", "    plt.figure(figsize=(12.0, 8.0))\n", "    plt.plot(x, f(x), label='Function $f$')\n", "    plt.scatter([x_start], f(x_start), label='Optimization starting point')\n", "    if optimization_steps is not None:\n", "        plt.scatter(optimization_steps[:, 0], optimization_steps[:, 1], \n", "                    color='blue', label='Optimization steps')\n", "    plt.title('Notre fonction $f$')\n", "    plt.legend()\n", "    plt.show()\n", "plot_curve(x_start)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Donnez le code permettant de calculer une it\u00e9ration de la m\u00e9thode d'optimisation de Newton. Jouez ensuite avec l'affichage interactif.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["def f_prime(x):\n", "    return 2*x-1.7+4*x**3+np.exp(x)\n", "\n", "def f_prime_prime(x):\n", "    return 2+12*x**2+np.exp(x)\n", "\n", "class NewtonMethod(object):\n", "    def optimize(self, x_start, nb_iterations=15):\n", "        \n", "        \n", "\n", "        optimization_steps = []\n", "        x_t = x_start\n", "        \n", "        for i in range(nb_iterations):\n", "            ####### Complete this part ######## or die ####################\n", "            x_t = ...\n", "            ###############################################################\n", "            \n", "            optimization_steps.append([x_t, f(x_t)])\n", "            \n", "        return np.array(optimization_steps)\n", "        \n", "newton = NewtonMethod()\n", "\n", "optimization_steps = newton.optimize(-2, nb_iterations=5)\n", "plot_curve(-2, optimization_steps)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"tags": ["remove-cell"]}, "source": ["# L'affichage suivant interactif va nous permettre de tester les diff\u00e9rents param\u00e8tres de notre optimiseur.\n", "\n", "import ipywidgets as widgets\n", "from IPython.display import display\n", "from IPython.display import clear_output\n", "%matplotlib inline\n", "\n", "output = widgets.Output()\n", "\n", "@output.capture()\n", "def interactive_gradient_descent(x, iterations):\n", "    clear_output()\n", "    optimization_steps = newton.optimize(x, nb_iterations=iterations)\n", "    plot_curve(x, optimization_steps)\n", "    \n", "widgets.interact(interactive_gradient_descent,\n", "                 x=widgets.FloatSlider(value=-3, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 iterations=widgets.IntSlider(value=1, min=1, max=10, step=1, continuous_update=False)\n", ")\n", "display(output)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## V. La descente de coordonn\u00e9es"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La descente de coordonn\u00e9es ou *coordinate descent* consiste \u00e0 optimiser une fonction multivari\u00e9e variable par variable. Soit $f:\\mathbb{R}^d\\mapsto\\mathbb{R}$ et le probl\u00e8me d'optimisation suivant&nbsp;:\n", "\n", "$$x^\\star=\\text{argmin}_{x\\in\\mathbb{R}^d}f(x).$$\n", "\n", "Contrairement \u00e0 la descente de gradient classique, ici, lors d'une \u00e9tape d'optimisation, une unique variable est mise \u00e0 jour \u00e0 la fois : \n", "\n", "$$x^{(t)}_i=\\text{argmin}_{x\\in\\mathbb{R}}f(x^{(t)}_1,\\ldots, x_{i-1}^{(t)}, x, x_{i+1}^{(t-1)}, \\ldots, x_d^{(t-1)}).$$\n", "\n", "Consid\u00e9rons la fonction \u00e0 deux variables suivantes&nbsp;: $f(x, y)=5x^2-6xy+5y^2$."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def f(x):\n", "    return 5*np.power(x[0], 2)-6*x[0]*x[1]+5*np.power(x[1], 2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_loss_contour(f, three_dim=False, starting=[0, 2], \n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consid\u00e9rons $g_y(x)=f(x, y)$ comme une fonction de $x$ uniquement (i.e. $y$ est fix\u00e9) et d\u00e9rivons&nbsp;:\n", "\n", "$$g_y^\\prime(x)=10x-6y.$$\n", "\n", "Ainsi, l'it\u00e9r\u00e9 suivant pour la variable $x$ s'obtient de la mani\u00e8re suivante&nbsp;: $x^{(t)}=x^{(t-1)}-\\eta g_y^\\prime(x^{(t-1)})$. Le m\u00eame raisonement s'\u00e9tend de mani\u00e8re totalement sym\u00e9trique pour obtenir l'it\u00e9r\u00e9 de la variable $y$ (remarquez que $f(x, y)= f(y, x)$)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "**Donnez le code permettant de calculer une it\u00e9ration de la m\u00e9thode *coordinate descent*.**\n", "\n", "\n\n ----"]}, {"cell_type": "code", "metadata": {}, "source": ["class CoordinateDescent(object):\n", "    def optimize(self, x_start, nb_iterations=15, learning_rate=0.01):\n", "        optimization_steps = [np.copy(x_start)]\n", "        x_t = x_start\n", "        \n", "        for i in range(nb_iterations):\n", "            ####### Complete this part ######## or die ####################\n", "            x_t[0]=...\n", "            ###############################################################\n", "\n", "            optimization_steps.append(np.copy(x_t))\n", "            \n", "            ####### Complete this part ######## or die ####################\n", "            x_t[1]=...\n", "            ###############################################################\n", "            \n", "            optimization_steps.append(np.copy(x_t))\n", "\n", "            \n", "        return np.array(optimization_steps)\n", "        \n", "coordinate = CoordinateDescent()\n", "\n", "param_trace = coordinate.optimize(\n", "    x_start=np.array([2., 2.]), \n", "    nb_iterations=20, \n", "    learning_rate=0.1\n", ")\n", "plot_loss_contour(f, param_trace, figsize=(14.0, 6.0))\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"tags": ["remove-cell"]}, "source": ["\n", "# L'affichage suivant interactif va nous permettre de tester les diff\u00e9rents param\u00e8tres de notre optimiseur.\n", "\n", "import ipywidgets as widgets\n", "from IPython.display import display\n", "from IPython.display import clear_output\n", "%matplotlib inline\n", "\n", "output = widgets.Output()\n", "\n", "@output.capture()\n", "def interactive_gradient_descent(learning_rate, x, y, iterations):\n", "    clear_output()\n", "    param_trace = coordinate.optimize(x_start=np.array([x, y]),\n", "                                      nb_iterations=iterations,\n", "                                      learning_rate=learning_rate)\n", "    plot_loss_contour(f, param_trace, figsize=(14.0, 6.0))\n", "    \n", "widgets.interact(interactive_gradient_descent,\n", "                 learning_rate=widgets.FloatSlider(value=1e-5, min=1e-5, max=0.1, step=0.0001, \n", "                                                   continuous_update=False, readout_format='.5f'),\n", "                 x=widgets.FloatSlider(value=-2, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 y=widgets.FloatSlider(value=-2, min=-4, max=4, step=0.1, continuous_update=False),\n", "                 iterations=widgets.IntSlider(value=1, min=1, max=20, step=1, continuous_update=False)\n", ")\n", "display(output)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## VI. Optimisation sous contrainte (en plus ?)\n", "\n", "### A. Introduction aux multiplicateurs de Lagrange\n", "Il est parfois n\u00e9cessaire d'introduire certaines contraintes que notre solution doit satisfaire. Par exemple, on peut vouloir minimiser une fonction de co\u00fbt $\\mathcal{L}$ et en m\u00eame temps vouloir contraindre la solution $\\hat{\\beta}$ \u00e0 avoir une norme de taille fixe.\n", "\n", "Consid\u00e9rons le probl\u00e8me d'optimisation suivant&nbsp;:\n", "\n", "$$x^\\star=\\text{argmin}_{x\\in\\mathbb{R}^d}f(x)\\text{ s.t. }g(x)=0,$$\n", "\n", "o\u00f9 $f$ est la fonction objectif \u00e0 respecter et $g$ notre ensemble de contraintes. Supposons $g, f\\in\\mathcal{C}^1$. Afin de rendre plus explicite les \u00e9tapes de notre raisonnement, illustrons cela au travers d'un exemple avec la fonction suivante&nbsp;:\n", "\n", "$$f(x)=\\frac{1}{2}x^TAx+b^Tx,$$\n", "\n", "o\u00f9\n", "\n", "$$A=\\begin{bmatrix} 1& 0\\\\ 0& 2\\end{bmatrix}$$\n", "\n", "et\n", "\n", "\n", "$$b=\\begin{bmatrix}2\\\\1\\end{bmatrix}.$$\n", "\n", "C'est la m\u00eame fonction que nous avons optimis\u00e9 tout \u00e0 l'heure. Dans le cas sans contrainte, il nous suffit de d\u00e9river&nbsp;:\n", "\n", "$$f^\\prime(x)=Ax+b$$\n", "\n", "puis d'annuler cette derni\u00e8re&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "f^\\prime(x)&=0\\\\\n", "\\Leftrightarrow Ax+b&=0\\\\\n", "\\Leftrightarrow x &= -A^{-1}b.\n", "\\end{aligned}$$\n", "\n", "Le probl\u00e8me initial \u00e9tait convexe la solution pr\u00e9c\u00e9dente est un minimum global."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["A = np.array([[1, 0], [0, 2]])\n", "b = np.array([[2], [1]])\n", "\n", "def f(x):\n", "    if type(x) is np.ndarray:\n", "        x = x.tolist()\n", "    return (np.dot(np.dot(A, x).T, x)*0.5+np.dot(b.T, x))[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = -np.dot(np.linalg.inv(A), b)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_loss_contour(f, three_dim=False, ending=np.ravel(x), \n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consid\u00e9rons maintenant la contrainte $x_1=x_2$ qu'on peut formuler au travers de la fonction&nbsp;:\n", "\n", "$$g(x)=c^Tx,$$\n", "\n", "o\u00f9 $c=[1, -1]^T$. On veut trouver le minimiseur de notre fonction sous la constrainte que les deux oordonn\u00e9es de notre vecteur de solution soient identiques ! Observons tout d'abord la forme de cette contrainte."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["c_x = np.linspace(-5, 5, 100)\n", "c_y = c_x\n", "constraint = np.stack([c_x, c_y], axis=1)\n", "\n", "plot_loss_contour(f, three_dim=False, ending=np.ravel(x), constraint=constraint,\n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Le *Lagrangien* du probl\u00e8me sous contrainte pr\u00e9c\u00e9dent est&nbsp;:\n", "\n", "$$\\mathcal{L}(x, \\lambda)=f(x)+\\lambda g(x)$$\n", "\n", "Le coefficient $\\lambda$ s'appelle multiplicateur de Lagrange. On cherche \u00e0 trouver $x^\\star$ et $\\lambda^\\star$ tel que $g(x^\\star)=0$ et $\\mathcal{L}(x^\\star,\\lambda^\\star)$ est minimis\u00e9 (i.e. on minise notre fonction $f$ en conservant les contraintes satisfaites.)L'approche classique consiste \u00e0 v\u00e9rifier les conditions que devraient satistifaire une solution $(x^\\star, \\lambda^\\star)$ au travers du Lagrangien. On parle de condition d'optimalit\u00e9. Si notre contrainte est satisfaite, alors $g(x)=0$ et&nbsp;:\n", "\n", "$$\\frac{\\partial\\mathcal{L}(x^\\star, \\lambda^\\star)}{\\partial \\lambda}=0.$$\n", "\n", "\n", "On remarque que c'est une condition n\u00e9cessaire et suffisante garantissant que nos contraintes sont statisfaites. Cela donne dans notre exemple&nbsp;:\n", "\n", "$$\\frac{\\partial\\mathcal{L}(x, \\lambda)}{\\partial \\lambda}=c^Tx^=0\\Leftrightarrow x_1=x_2.$$\n", "\n", "Consid\u00e9rons maintenant $\\lambda^\\star$ fixe, la condition que doit satisfaire $x^\\star$ s'il est un minimum est&nbsp;:\n", "\n", "$$\\frac{\\partial \\mathcal{L}(x^\\star,\\lambda^\\star)}{\\partial x}=0,$$\n", "\n", "Cela donne dans notre cas&nbsp;:\n", "\n", "$$\\frac{\\partial\\mathcal{L}(x,\\lambda)}{\\partial x}=Ax+b+\\lambda c=\\boldsymbol{0}.$$\n", "\n", "Nous avons ainsi un syst\u00e8me de deux \u00e9quations&nbsp;:\n", "\n", "$$\\begin{cases}x_1+2+\\lambda&=0\\\\\n", "2x_2+1-\\lambda&=0.\\end{cases}$$\n", "\n", "En nous appuyans sur la condition $x_1=x_2$, cela nous donne&nbsp;:\n", "\n", "$$\\begin{cases}x+2+\\lambda&=0\\\\\n", "2x+1-\\lambda&=0,\\end{cases}$$\n", "\n", "que nous pouvons r\u00e9soudre et qui nous donne $\\lambda=-1$ et $x_1=x_2=-1$.\n", "\n", "Nous aurions bien s\u00fbr pu \u00e9viter de passer par le Lagrandien sur ce probl\u00e8me simple mais cela \u00e9tait l'occasion d'un exemple. De plus, remarquons que $(x^\\star, \\lambda^\\star)$ est un point selle de notre probl\u00e8me."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["c_x = np.linspace(-5, 5, 100)\n", "c_y = c_x\n", "constraint = np.stack([c_x, c_y], axis=1)\n", "\n", "plot_loss_contour(f, three_dim=False, ending=[-1, -1], constraint=constraint,\n", "                  title='Carte de chaleur 2D de la fonction \u00e0 optimiser')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### B. Les conditions de Karush-Kuhn-Tucker\n", "\n", "Consid\u00e9rons le probl\u00e8me d'optimisation sous contraintes suivant&nbsp;:\n", "\n", "$$\\begin{aligned}\n", "&\\text{argmin}\\hspace{0.5cm}f(x)\\\\\n", "&\\text{subject to:}\\\\\n", "&\\hspace{1cm}h_i(x)=0,\\ i\\in\\{1, \\ldots, m\\}\\\\\n", "&\\hspace{1cm}g_j(x)\\leq 0,\\ j\\in\\{1, \\ldots, n\\}\\\\\n", "\\end{aligned},$$\n", "\n", "o\u00f9 $h_i$ est une contrainte d'\u00e9galit\u00e9 et $g_j$ une contrainte d'in\u00e9galit\u00e9. Il s'agit du probl\u00e8me qu'on appellera *primal* et on notera $p^\\star=f(x^\\star)$ o\u00f9 $x^\\star$ minimise $f$ et satisfait les contraintes. \n", "\n", "Le Lagrangien associ\u00e9 \u00e0 ce probl\u00e8me est donn\u00e9 par&nbsp;:\n", "\n", "$$\\mathcal{L}(x, \\lambda,\\mu)=f(x)+\\lambda^T h(x)+\\mu^T g(x),$$\n", "\n", "o\u00f9 nous avons vectoris\u00e9 les notations des contraintes et o\u00f9 $\\mu\\geq 0$. Ainsi $\\lambda\\in\\mathbb{R}^m$ et $\\mu\\in\\mathbb{R}^n$.\n", "\n", "Il est possible de construire un probl\u00e8me qu'on appelle *dual* de Lagrange \u00e0 partir du Lagrangien et qu'on note&nbsp;:\n", "\n", "$$l(\\lambda, \\mu)=\\text{inf}_x\\ \\mathcal{L}(x, \\lambda, \\mu).$$\n", "\n", "---\n", "\n", "**<span style='color:blue'> Proposition</span>** ", "\n", "La fonction $l$ est concave en $\\lambda$ et $\\mu$.\n", "\n", "\n\n ----", "\n", "**<span style='color:orange'> Preuve</span>** ", "\n", "Soient $\\lambda_1, \\lambda_2$ et $\\mu_1, \\mu_2$. Notons&nbsp;:\n", "\n", "$$\\lambda=\\alpha\\lambda_1+(1-\\alpha)\\lambda_2\\text{ et }\\mu=\\alpha\\mu_1+(1-\\alpha)\\mu_2,\\ \\alpha\\in[0, 1].$$\n", "\n", "Nous avons alors&nbsp;:\n", "\n", "$$\\begin{aligned}l(\\lambda, \\mu)&=\\text{inf}_x\\ f(x)+\\lambda^T h(x)+\\mu^T g(x)\\\\\n", "&=\\text{inf}_x\\ f(x)+(\\alpha\\lambda_1+(1-\\alpha)\\lambda_2)^T h(x)+(\\alpha\\mu_1+(1-\\alpha)\\mu_2)^T g(x)\\\\\n", "&=\\text{inf}_x\\ \\alpha(f(x)+\\lambda_1^T h(x)+\\mu_1^T g(x))+(1-\\alpha)(f(x)+\\lambda_2^T h(x)+\\mu_2^T g(x))\n", "\\end{aligned}$$\n", "\n", "Enfin, nous avons&nbsp;:\n", "\n", "$$\\begin{aligned}\\text{inf}_x&\\ \\alpha(f(x)+\\lambda_1^T h(x)+\\mu_1^T g(x))+(1-\\alpha)(f(x)+\\lambda_2^T h(x)+\\mu_2^T g(x))\\\\&\\geq \\text{inf}_x\\ \\alpha(f(x)+\\lambda_1^T h(x)+\\mu_1^T g(x))+\\text{inf}_x\\ (1-\\alpha)(f(x)+\\lambda_2^T h(x)+\\mu_2^T g(x)),\\end{aligned}$$\n", "\n", "ce qui nous donne&nbsp;\n", "\n", "$$l(\\lambda, \\mu)\\geq \\alpha l(\\lambda_1,\\mu_1)+(1-\\alpha)l(\\lambda_2,\\mu_2)$$\n", "\n\n ----", "\n", "\n", "On observe assez rapidement que si $x$ respecte ses contraintes, alors $h_i(x)=0$ et $g_j(x)\\leq 0$ et&nbsp;:\n", "\n", "$$\\mathcal{L}(x, \\lambda, \\mu)\\leq f(x),$$\n", "\n", "ce qui implique ce qu'on appelle la dualit\u00e9 faible&nbsp;:\n", "\n", "$$d^\\star\\leq p^\\star.$$\n", "\n", "o\u00f9&nbsp;:\n", "\n", "$$d^\\star=\\text{max}_{\\lambda,\\mu}l(\\lambda, \\mu).$$\n", "\n", "Le point \u00e0 noter est que le dual, en \u00e9tant un probl\u00e8me de maximisation d'une fonction concave devient un probl\u00e8me de minimisation convexe.\n", "\n", "**<span style='color:blue'> Th\u00e9or\u00e8me (condition de Slater)</span>** ", "\n", "Si $f$ et $g_j \\forall j$ sont convexes et $h_i\\forall i$  sont affines et qu'il existe un point admissible (i.e. qui satisfait les contraintes) pour lequel une des contraintes d'in\u00e9galit\u00e9 n'est pas satur\u00e9e (i.e. $g_j(x)<0$), alors la dualit\u00e9 forte est garantie&nbsp;:\n", "\n", "$$d^\\star=p^\\star.$$\n", "\n", "\n\n ----"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lorsque nous travaillons avec une fonction $f$, nous sommes souvent int\u00e9ress\u00e9s par une r\u00e8gle qui nous permettrait de d\u00e9terminer une \u00e9quivalence entre certaines propri\u00e9t\u00e9s et le fait d'\u00eatre un minimum. Si $f$ est diff\u00e9rentiable et convexe, alors $x^\\star$ est minimum de $f$ si et seulement si $\\nabla f(x^\\star)=0. Les conditions de Karush-Kuhn-Tucker g\u00e9n\u00e9ralise cette id\u00e9e au cas d'un probl\u00e8me d'optimisation sous contrainte.\n", "\n", "Supposons maintenant $f, g_1,\\ldots, g_m, h_1,\\ldots, h_n$ diff\u00e9rentiables et supposons que la dualit\u00e9 forte tienne.\n", "\n", "---\n", "\n", "**<span style='color:blue'> Th\u00e9or\u00e8me (conditions de Karush\u2013Kuhn\u2013Tucker)</span>** ", "\n", "Soit $(x^\\star, \\lambda^\\star, \\mu^\\star)$ tels que les conditions suivantes sont satisfaites&nbsp;:\n", "\n", "**Stationarit\u00e9&nbsp;:**\n", "\n", "$$\\nabla f(x^\\star)+{\\lambda^\\star}^T D h(x^\\star)+{\\mu^\\star}^T D g(x^\\star)=0,$$\n", "\n", "o\u00f9 $Dg$ et $Dh$ sont les jacobiennes.\n", "\n", "**faisabilit\u00e9 du primal&nbsp;:**\n", "\n", "$$g_j(x^\\star)\\leq 0\\ \\forall j\\text{ et }h_i(x^\\star)=0\\ \\forall i.$$\n", "\n", "**faisabilit\u00e9 du dual&nbsp;:**\n", "\n", "$$\\mu^\\star\\geq \\boldsymbol{0},$$\n", "\n", "**compl\u00e9mentarit\u00e9&nbsp;:**\n", "\n", "$$\\sum_j {\\mu_j}^\\star g_i(x^\\star)=0$$\n", "\n", "alors, $(\\lambda^\\star, \\mu^\\star)$ est une solution du dual de Lagrange et $x^\\star$ est une solution du primal.\n", "\n", "\n\n ----", "\n", "\n", "**<span style='color:orange'> Preuve</span>** ", "\n", "Soit $(x^\\star, \\lambda^\\star, \\mu^\\star)$ tels que les conditions de KKT soient satisfaites. La condition de *faisabilit\u00e9 du primal* nous indique que $x^\\star$ satisfait nos contraintes et appartient donc \u00e0 l'ensemble de faisabilit\u00e9.\n", "\n", "En tant que combinaison lin\u00e9aire de fonctions convexes, le Lagrangien est convexe et la condition de *stationarit\u00e9* implique que $x^\\star$ minimise le lagrangien pour $\\mu^\\star$ et $\\lambda^\\star$ fix\u00e9s.\n", "\n", "Observons que $l(\\lambda^\\star, \\mu^\\star)=f(x^\\star)$ gr\u00e2ce \u00e0 la condition de *compl\u00e9mentarit\u00e9* et \u00e0 la *faisabilit\u00e9 du primal*.\n", "\n", "Par *dualit\u00e9 faible* nous avons $f(x^\\star) = d^\\star\\leq p^\\star \\leq f(x^\\star)$ et on a donc&nbsp;:\n", "\n", "$$l(\\lambda^\\star, \\mu^\\star)=d^\\star=p^\\star,$$\n", "\n", "et $x^\\star$ est solution du primal et $(\\lambda^\\star, \\mu^\\star)$ est solution du dual.\n", "\n\n ----"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 4}