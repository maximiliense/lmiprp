{"cells": [{"cell_type": "markdown", "id": "5d729a22", "metadata": {}, "source": ["# Jeu d'apprentissage *set-valued*"]}, {"cell_type": "markdown", "id": "463a8a0a", "metadata": {}, "source": ["**<span style='color:blue'> Objectifs de la s\u00e9quence</span>** ", "\n", "* \u00catre sensibilis\u00e9&nbsp;:\n", "    * \u00e0 l'id\u00e9e de pr\u00e9diction d'ensembles.\n", "* \u00catre capable&nbsp;:\n", "    * d'impl\u00e9menter un \\textit{top-K} avec $\\texttt{pytorch}$.\n", "\n", "\n\n ----", "\n", "Soit $\\mathcal{X}$ notre espace des donn\u00e9es d'entr\u00e9e et $\\mathcal{Y}=\\{1, \\ldots, C\\}$ notre espace des labels pour un probl\u00e8me de classification \u00e0 $C$ classes. Le probl\u00e8me de classification multi-classes dans son *framework* traditionnel revient \u00e0 chercher une application de $\\mathcal{X}$ dans $\\mathcal{Y}$.\n", "\n", "Cependant, comme nous allons le voir, il est parfois souhaitable de pr\u00e9dire une liste de classes (un ensemble), plut\u00f4t qu'une classe indivuduelle. Dans cette premi\u00e8re s\u00e9quence, nous partons du principe qu'il existe un jeu de donn\u00e9es d'apprentissage d\u00e9crivant de tels ensembles."]}, {"cell_type": "markdown", "id": "e8f4c796", "metadata": {}, "source": ["## I. Pr\u00e9sentation d'un jeu de donn\u00e9es avec ambiguit\u00e9\n", "\n", "Le jeu de donn\u00e9es d'annotation est t\u00e9l\u00e9chargeable \u00e0 l'adresse suivante [CIFAR-10H](https://github.com/jcpeterson/cifar-10h/blob/master/data/cifar10h-counts.npy). Ce dossier a \u00e9t\u00e9 construit en demandant \u00e0 des gens d'annoter un jeu de donn\u00e9es connu : \"CIFAR-10\". On s'est rendu compte suite \u00e0 l'annotation que le jeu de donn\u00e9es \u00e9tait ent\u00e2ch\u00e9 d'incertitude : chaque image peut correspondre \u00e0 plusieurs labels. Observons cela."]}, {"cell_type": "code", "execution_count": null, "id": "4ad47e91", "metadata": {"tags": ["remove-cell"]}, "outputs": [], "source": ["import numpy as np\n", "\n", "A = np.load('cifar10h-counts.npy')\n", "\n", "# construct proba\n", "A = A/A.sum(axis=1)[:, None]\n", "\n", "max_proba = A.max(axis=1)"]}, {"cell_type": "code", "execution_count": null, "id": "2c8e6930", "metadata": {"tags": ["remove-cell"]}, "outputs": [], "source": ["from torchvision import datasets\n", "\n", "cifar_train = datasets.CIFAR10(root='./data', train=True, download=True)\n", "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True)\n", "\n", "classes = cifar_test.classes\n", "class_to_idx = cifar_test.class_to_idx\n", "\n", "X, y = cifar_test.data, cifar_test.targets"]}, {"cell_type": "code", "execution_count": null, "id": "6f542339", "metadata": {"tags": ["remove-input"]}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "plt.figure(figsize=(14, 8))\n", "plt.suptitle('CIFAR-10 is ambiguous!')\n", "for i, idx in enumerate(np.argsort(max_proba)[:4]):\n", "    plt.subplot(2, 4, i+1)\n", "    plt.imshow(X[idx])\n", "    plt.axis('off')\n", "    \n", "for i, idx in enumerate(np.argsort(max_proba)[:4]):\n", "    ax = plt.subplot(2, 4, i+5)\n", "    labels_sorted = (-A[idx]).argsort()\n", "    labels = [classes[j] for j in labels_sorted[:4]]\n", "    probas = [A[idx][j] for j in labels_sorted[:4]]\n", "    color = ['lightcoral' if j == y[idx] else 'lightblue' for j in labels_sorted[:4]]\n", "    ax.bar(labels, probas, color=color)\n", "\n", "plt.show()"]}, {"cell_type": "markdown", "id": "f796d828", "metadata": {}, "source": ["La bonne classe (celle du jeu de donn\u00e9es officiel) est mise en avant.\n", "\n", "Un mod\u00e8le qui retournerait dans ces cas de figure l'ensemble des classes serait-il un mauvais mod\u00e8le ? *A priori* on voudrait dire que non."]}, {"cell_type": "markdown", "id": "14711455", "metadata": {}, "source": ["## II. Un probl\u00e8me toujours multi-classes ?\n", "\n", "Nous disposons donc d'un probl\u00e8me de classification multi-classe tel que $\\mathcal{X}$ est l'espace de nos donn\u00e9es et $\\mathcal{Y}$ celui de nos labels. Cependant, notre objectif est de construire un mod\u00e8le dont la pr\u00e9diction se fait sur $\\mathcal{P}(\\mathcal{Y})$, soit l'ensemble des parties de $\\mathcal{Y}$. Illustrons cela par un exemple. Si $\\mathcal{Y}=\\{0, 1\\}$, alors $\\mathcal{P}(\\mathcal{Y})=\\{\\emptyset, \\{0\\}, \\{1\\}, \\{0, 1\\}\\}$. C'est exactement ce qu'on veut. Finalement, on se rend compte que cela revient \u00e0 consid\u00e9rer un nouveau probl\u00e8me de classification o\u00f9 les classes sont les \u00e9l\u00e9ments de $\\mathcal{P}$. Ainsi, au lieu d'avoir un probl\u00e8me de classification binaire, nous aurions ici $4$ classes. Et si le mod\u00e8le pr\u00e9dit la troisi\u00e8me classe, alors on retournerait $\\{0, 1\\}$.\n", "\n", "Cette strat\u00e9gie est malheureusement vou\u00e9e \u00e0 l'\u00e9chec \u00e0 moins que nous sachions \u00e0 l'avant qu'une quantit\u00e9 limit\u00e9 d'ambigu\u00eft\u00e9 est possible. En effet, si on note $|\\mathcal{Y}|$ le cardinal de $\\mathcal{Y}$, alors $|\\mathcal{P}(\\mathcal{Y})|=2^{|\\mathcal{Y}|}$. Sur $\\texttt{CIFAR-10}$, notre probl\u00e8me \u00e0 10 classes en poss\u00e8de maintenant $1024$. Il devient m\u00eame tr\u00e8s probable que certaines configurations n'aient jamais \u00e9t\u00e9 vues (et ne poss\u00e8dent donc aucun exemple d'apprentissage).\n", "\n", "L'astuce consiste \u00e0 consid\u00e9rer les classes comme des entit\u00e9s s\u00e9par\u00e9es et ind\u00e9pendantes. Une classe est possible ind\u00e9pendamment de son voisinage."]}, {"cell_type": "markdown", "id": "495b3719", "metadata": {}, "source": ["## III. Un probl\u00e8me multi-labels"]}, {"cell_type": "markdown", "id": "e6a090e3", "metadata": {}, "source": ["Si l'information est disponible, alors il est possible de reformuler notre probl\u00e8me d'apprentissage multi-classes en un probl\u00e8me d'apprentissage multi-labels. Ici, l'espace de nos labels devient $\\mathcal{Y}=\\{0, 1\\}^C$. Dit autrement chaque classe possible est, ou n'est pas accept\u00e9e. Notons que pour r\u00e9fl\u00e9chir de cette mani\u00e8re, il est absolument n\u00e9cessaire que les donn\u00e9es contiennent l'information d'ensemble (i.e. nous devons avoir un jeu de donn\u00e9es d'apprentissage multi-labels). Nous devons pouvoir p\u00e9naliser notre mod\u00e8le s'il retourne une classe dans notre ensemble alors qu'elle n'aurait pas du y \u00eatre. Dans le cas contraire, il suffirait de retourner tout le temps toutes les classes pour \u00eatre s\u00fbrs de retourner la bonne classe.\n", "\n", "### A. Le classifieur de Bayes\n", "\n", "**<span style='color:blue'> Question </span>** ", "**Imaginons que nous disposions de la loi $\\eta_k(x)=\\mathbb{P}(Y_k=1|X=x)$ indiquant la probabilit\u00e9 que la classe $k$ soit pr\u00e9sente pour notre image $x$. Quelle est la meilleure pr\u00e9diction \u00e0 faire. C'est le classifieur de Bayes.**\n", "\n\n ----", "\n", "\n", "### B. Des estimateurs de la probabilit\u00e9 conditionnelle\n", "\n", "Il suffit ainsi de consid\u00e9rer un mod\u00e8le de classification binaire par classe. Nous allons ici d\u00e9velopper des mod\u00e8les de r\u00e9seaux de neurones cherchant \u00e0 estimer la probabilit\u00e9 conditionnelle $\\hat{\\eta}_k$. Comme nous l'avons vu lors de la s\u00e9quence multi-t\u00e2ches, partager l'apprentissage de notre mod\u00e8le de r\u00e9seaux de neurones entre plusieurs t\u00e2ches permet d'am\u00e9liorer l'apprentissage de repr\u00e9sentation."]}, {"cell_type": "markdown", "id": "da92837b", "metadata": {}, "source": ["Tout d'abord construisons notre jeu de donn\u00e9es multi-labels en consid\u00e9rant qu'un label est pr\u00e9sent \u00e0 partir du moment o\u00f9 sa probabilit\u00e9 suite \u00e0 l'annotation humaine est sup\u00e9rieure \u00e0 $5\\%$."]}, {"cell_type": "code", "execution_count": null, "id": "f9d774d2", "metadata": {}, "outputs": [], "source": ["labels_test = (A > 0.05).astype(float)"]}, {"cell_type": "code", "execution_count": null, "id": "a456e888", "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch.utils.data import DataLoader\n", "import torchvision.transforms as transforms"]}, {"cell_type": "code", "execution_count": null, "id": "adc063da", "metadata": {}, "outputs": [], "source": ["transform = transforms.Compose(\n", "  [\n", "      transforms.ToTensor(),\n", "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n", "  ]\n", ")\n", "\n", "cifar_train = datasets.CIFAR10(root='./data', train=True, transform=transform)\n", "cifar_test = datasets.CIFAR10(root='./data', train=False, transform=transform)\n", "\n", "# on indique les nouveaux labels\n", "cifar_test.targets = labels_test\n", "\n", "batch_size = 128\n", "\n", "trainloader = DataLoader(\n", "  cifar_train, batch_size=batch_size\n", ")\n", "\n", "testloader = DataLoader(\n", "  cifar_test, batch_size=batch_size, shuffle=True\n", ")\n", "\n", "print('Nb test batchs:', len(testloader))"]}, {"cell_type": "markdown", "id": "c1c30561", "metadata": {}, "source": ["**<span style='color:blue'> Question</span>** ", "**Devons-nous adapter le code du mod\u00e8le suivant de mani\u00e8re \u00e0 lui permettre de g\u00e9rer un apprentissage multi-labels ? Si oui, adaptez-le.**\n", "\n\n ----"]}, {"cell_type": "code", "execution_count": null, "id": "fe76b898", "metadata": {}, "outputs": [], "source": ["####### Complete this part ######## or die ####################\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "from torchvision import models, transforms\n", "\n", "class Net(nn.Module):\n", "    def __init__(self):\n", "        super(Net, self).__init__()\n", "        self.conv1 = nn.Conv2d(3, 16, 5)\n", "        self.pool = nn.MaxPool2d(2, 2)\n", "        self.conv2 = nn.Conv2d(16, 32, 5)\n", "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n", "        self.fc2 = nn.Linear(120, 84)\n", "        self.fc = nn.Linear(84, 10)\n", "\n", "    def forward(self, x):\n", "        x = self.pool(F.relu(self.conv1(x)))\n", "        x = self.pool(F.relu(self.conv2(x)))\n", "        x = x.view(-1, 32 * 5 * 5)\n", "        x = F.relu(self.fc1(x))\n", "        x = F.relu(self.fc2(x))\n", "        x = self.fc(x)\n", "        return x\n", "###############################################################"]}, {"cell_type": "code", "execution_count": null, "id": "fa776924", "metadata": {}, "outputs": [], "source": ["model = Net()"]}, {"cell_type": "code", "execution_count": null, "id": "063dd1a5", "metadata": {}, "outputs": [], "source": ["import torch.optim as optim\n", "from torch.optim.lr_scheduler import MultiStepLR"]}, {"cell_type": "markdown", "id": "e4af100b", "metadata": {}, "source": ["**<span style='color:blue'> Question</span>** ", "**Devons-nous adapter le code de la *loss* de mani\u00e8re \u00e0 lui permettre de g\u00e9rer un apprentissage multi-labels ? Si oui, adaptez-le.**\n", "\n\n ----"]}, {"cell_type": "code", "id": "0c9718e5", "metadata": {}, "source": ["####### Complete this part ######## or die ####################\n", "#Choose the loss function\n", "criterion = nn.CrossEntropyLoss()\n", "\n", "#Optimizer\n", "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=0.)\n", "###############################################################\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "b80cb77d", "metadata": {}, "source": ["Notez que seul le test a \u00e9t\u00e9 annot\u00e9 par des \u00eatres humains. Nous devons donc malheureusement inverser le jeu d'apprentissage et le jeu de test."]}, {"cell_type": "code", "id": "fac05c01", "metadata": {}, "source": ["loss_history = []\n", "for epoch in range(4):  # loop over the dataset multiple times\n", "\n", "    running_loss = 0.0\n", "    for i, data in enumerate(testloader, 0):\n", "        # get the inputs; data is a list of [inputs, labels]\n", "        inputs, labels = data\n", "\n", "        # zero the parameter gradients\n", "        optimizer.zero_grad()\n", "\n", "        # forward + backward + optimize\n", "        outputs = model(inputs)\n", "        loss = criterion(outputs, labels)\n", "        loss.backward()\n", "        optimizer.step()\n", "\n", "        # print statistics\n", "        running_loss += loss.item()\n", "        if i % 10 == 9:  # print every 2000 mini-batches\n", "            # TODO uncomment print('\\r[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000), end='')\n", "            loss_history.append(running_loss / 2000)\n", "            running_loss = 0.0\n", "print('\\r**** Finished Training ****')\n", "plt.figure(figsize=(12, 8))\n", "plt.plot([i for i in range(1, len(loss_history)+1)], loss_history, \n", "         label='My set-valued model')\n", "plt.legend()\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "aa92c89a", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "**Proposez une \u00e9valuation *set-valued* en utilisant l'attribut $\\texttt{threshold}$. La m\u00e9thode doit retourner le score moyen ainsi que la taille moyenne des ensembles.**\n", "\n\n ----"]}, {"cell_type": "code", "id": "67863532", "metadata": {}, "source": ["def test(model, loader, threshold, timeout=5):\n", "    model.eval()  # on passe le modele en mode evaluation\n", "    correct = 0\n", "    total = 0\n", "    set_size = 0\n", "    with torch.no_grad():\n", "        for i, data in enumerate(loader):\n", "            images, labels = data\n", "            outputs = model(images)\n", "            # TODO Correction a supprimer\n", "            ####### Complete this part ######## or die ####################\n", "            correct += ...\n", "            set_size += ...\n", "            ###############################################################\n", "            total += labels.size(0)\n", "            if i >= timeout:\n", "                break\n", "\n", "    model.train()  # on remet le modele en mode apprentissage\n", "    return correct / total, set_size / total\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "47163eca", "metadata": {}, "source": ["set_size = []\n", "accuracy = []\n", "for threshold in [-i for i in range(10)]:\n", "    accu, size = test(model, trainloader, threshold)\n", "    set_size.append(size)\n", "    accuracy.append(accu)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "aac13020", "metadata": {}, "source": ["plt.figure(figsize=(12, 8))\n", "plt.plot(set_size, accuracy)\n", "plt.xlabel('Set size')\n", "plt.ylabel('Accuracy')\n", "plt.show()\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "2a83a41d", "metadata": {}, "source": ["Certes notre mod\u00e8le n'est pas tr\u00e8s bon, mais il est important de noter que l'apprentissage a eu lieu sur le jeu de test qui est beaucoup plus petit que le jeu d'apprentissage. Cela est du au fait que labeliser un jeu d'apprentissage complet en multi-labels est tr\u00e8s dur. Ce genre d'information n'est g\u00e9n\u00e9ralement pas disponible et nous devons agir autrement comme nous le verrons dans la s\u00e9quence suivante.\n", "\n", "Cependant, notons que d\u00e8s qu'on accepte de retourner $2$ labels en moyenne, notre mod\u00e8le atteint presque $70\\%$ d'accuracy."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 5}