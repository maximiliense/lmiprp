{"cells": [{"cell_type": "markdown", "id": "described-brave", "metadata": {}, "source": ["# Calibration des probabilit\u00e9s et quelques notions \u2615\ufe0f\n", "\n", "**<span style='color:blue'> Objectifs de la s\u00e9quence</span>** ", "\n", "* \u00catre sensibilis\u00e9&nbsp;:\n", "    * aux difficult\u00e9s \u00e0 estimer la loi conditionnelle $\\eta_k(x)=\\mathbb{P}(Y=k|X=x)$.\n", "* \u00catre capable de&nbsp;:\n", "    * de calibrer les probabilit\u00e9s d'un r\u00e9seau de neurones pour am\u00e9liorer le fit de $\\eta$.\n", "\n", "\n\n ----", "\n", "## I. Introduction\n", "\n", "Notez que par soucis de simplicit\u00e9, nous consid\u00e9rons dans nos formules le cas de la classification binaire. Le propos se g\u00e9n\u00e9ralise bien s\u00fbr !\n", "\n", "Consid\u00e9rons un probl\u00e8me de classification o\u00f9 $\\mathcal{X}$ repr\u00e9sente notre espace d'entr\u00e9e et $\\mathcal{Y}=\\{0, 1\\}$ l'ensemble de nos classes (ici deux classes). Notons $X,Y$ deux variables al\u00e9atoires sur $\\mathcal{X}\\times\\mathcal{Y}$ et notons $\\mu$ la mesure de $X$ et $\\eta(x)=\\mathbb{P}(Y=1|X=x)$ la \"probabilit\u00e9 *a posteriori*\". Notre objectif est assez traditionnellement de trouver une application $h:\\mathcal{X}\\rightarrow\\mathcal{Y}$ telle que le risque suivant est minimis\u00e9&nbsp;:\n", "\n", "$$R(h)=\\mathbb{E}\\big[\\textbf{1}\\{h(X)\\neq Y\\}\\big].$$\n", "\n", "Ne connaissant ni $\\mu$ ni $\\eta$, nous ne pouvons estimer ce risque et devons l'estimer empiriquement en collectant un jeu de donn\u00e9es $S_n=\\{(X_i, Y_i)\\}_{i\\leq n}$. Utilisant ce jeu de donn\u00e9es, nous pouvons construire la notion de risque empirique&nbsp;:\n", "\n", "$$R_n(h)=\\frac{1}{n}\\sum_{i=1}^n \\textbf{1}\\{h(X_i)\\neq Y_i\\}.$$\n", "\n", "La s\u00e9quence sur les fonctions proxy nous a montr\u00e9 que minimiser ce risque est g\u00e9n\u00e9ralement difficile. Nous ne pouvons en particulier pas utiliser la descente de gradient puisque ce dernier est presque partout nul. Nous avons vu que nous pouvions cependant construire une strat\u00e9gie o\u00f9 notre application ne retourne pas un label mais un score sur $\\mathbb{R}$ (qu'on appelle logit en *deep learning* ou en r\u00e9gression logistique), score dont le signe nous permet de d\u00e9terminer la classe. Une *loss* poss\u00e9dant un certain nombre de propri\u00e9t\u00e9s (e.g. convexe) \u00e9tait ensuite optimis\u00e9e. Les propri\u00e9t\u00e9s de cette derni\u00e8re nous permettait de conclure que le r\u00e9sultat ne sera pas trop mauvais. Un exemple de loss est la *logistic loss* d\u00e9finie comme&nbsp;:\n", "\n", "$$\\text{log}\\big(1+e^{-z}\\big),$$\n", "\n", "o\u00f9 $z$ est justement le score retourn\u00e9 par notre mod\u00e8le. Nous allons dans cette s\u00e9quence une approche parall\u00e8le. Cette fois-ci, notre mod\u00e8le ne donnera pas un score sur $\\mathbb{R}$ mais sur $[0, 1]$ (la probabilit\u00e9 de la classe $1$ dans le cas \u00e0 deux classes). Nous avons vu dans la s\u00e9quence sur les fonctions proxy que consid\u00e9rer un mod\u00e8le qui retourne un score sur $\\mathbb{R}$ suivi de la *logistic loss* \u00e9tait \u00e9quivalent au m\u00eame mod\u00e8le dont on donne le score \u00e0 une fonction de lien sigmoid (qui retourne une probabilit\u00e9) et qu'on optimise avec l'inverse de la log-vraisemblance&nbsp;: la vision statistique ou *machine learning* sont en r\u00e9alit\u00e9 les deux faces d'une m\u00eame pi\u00e8ce.\n", "\n", "L'approche *machine learning* nous permet de r\u00e9fl\u00e9chir avec une vision purement pr\u00e9dictive et performances de pr\u00e9diction alors que l'approche statistiques nous donne cette information sur les probabilit\u00e9s. Cette derni\u00e8re peut \u00eatre importante par exemple si on veut seuiller, e.g. je ne retourne la classe $1$ que si sa probabilit\u00e9 est sup\u00e9rieure \u00e0 $99\\%$. On verra que cette id\u00e9e est cl\u00e9 lorsqu'on cherche \u00e0 pr\u00e9dire des ensembles (cf. la s\u00e9quence d\u00e9di\u00e9e). \n", "\n", "Nous allons ici voir comment estimer ses probabilit\u00e9s sur un jeu d'apprentissage puis comment corriger/calibrer ces derni\u00e8res pour qu'elles soient le plus r\u00e9alistes possibles."]}, {"cell_type": "markdown", "id": "extra-montreal", "metadata": {}, "source": ["## II. Estimation de la probabilit\u00e9 conditionnelle\n", "\n", "### A. *Proper loss* et *cross-entropy*\n", "\n", "Nous allons ici prendre la perspective statistique, c'est-\u00e0-dire celle o\u00f9 on cherche \u00e0 estimer la probabilit\u00e9 conditionnelle. Nous voulons construire un estimateur&nbsp;:\n", "\n", "$$\\hat{\\eta}(x)=\\hat{\\mathbb{P}}\\big(Y=1|X=x\\big),$$\n", "\n", "o\u00f9 $\\hat{\\eta}\\in\\mathcal{F}$ et $\\mathcal{F}$ est notre ensemble de \"probabilit\u00e9s conditionnelles\" (e.g. les param\u00e9trisations d'une r\u00e9gression logistique ou d'un r\u00e9seau de neurones). Il existe de nombreuses strat\u00e9gies afin d'atteindre cet objectif. L'une consiste \u00e0 trouver une loss qui nous permettra de faire le meilleur choix de probabilit\u00e9 conditionnelle. La strat\u00e9gie est souvent de maximiser la vraisemblance, ou, de mani\u00e8re totalement \u00e9quivalente, de minimiser l'oppos\u00e9 de la log-vraisemblance&nbsp;:\n", "\n", "$$\\mathcal{L}(\\hat{\\eta})=-\\sum_{i=1}^n Y_i\\text{log}(\\hat{\\eta}(X_i))+(1-Y_i)\\text{log}(1-\\hat{\\eta}(X_i)).$$\n", "\n", "En esp\u00e9rance, nous notons&nbsp;:\n", "\n", "$$\\mathcal{L}_\\eta(\\hat{\\eta})=-\\mathbb{E}_X\\big[\\eta(X)\\text{log}(\\hat{\\eta}(X))+(1-\\eta(X))\\text{log}(1-\\hat{\\eta}(X))\\big].$$\n", "\n", "Est-ce une bonne strat\u00e9gie. Finalement la premi\u00e8re chose que notre *loss* doit satisfaire est la suivante. Si on lui donnait la vraie probabilit\u00e9 conditionnelle $\\eta$, serait-elle minimis\u00e9e ? Serait-ce l'unique minimiseur ? Les d\u00e9finitions suivantes formalisent ces id\u00e9es.\n", "\n", "---\n", "\n", "**D\u00e9finition 1 (*Proper loss*)**\n", "\n", "Une loss $\\mathcal{L}_\\eta$ est dite *proper* si $\\eta$ est un minimiseur de cette derni\u00e8re&nbsp;\n", "\n", "$$\\forall \\hat{\\eta},\\ \\mathcal{L}_\\eta(\\hat{\\eta})\\geq \\mathcal{L}_\\eta(\\eta).$$\n", "\n", "---\n", "\n", "**D\u00e9finition 2 (*Strictly proper loss*)**\n", "Une loss $\\mathcal{L}_\\eta$ est dite *strictly proper* si $\\eta$ est l'unique minimiseur de cette derni\u00e8re&nbsp;\n", "\n", "$$\\forall \\hat{\\eta},\\ \\hat{\\eta}\\neq \\eta,\\ \\mathcal{L}_\\eta(\\hat{\\eta})> \\mathcal{L}_\\eta(\\eta).$$\n", "\n", "---\n", "\n", "Il se trouve que la *cross-entropy* ou log-vraisemblance n\u00e9gative est *strictly proper*.\n", "\n", "### B. Consistence de la *cross-entropy*\n", "\n", "\n", "**D\u00e9finition 3 (Plugin rule)**\n", "\u00c9tant donn\u00e9e un estimateur des probabilit\u00e9s conditionnelles $\\hat{\\eta}$, la plugin rule est celle qui retourne la classe associ\u00e9e \u00e0 la plus forte probabilit\u00e9&nbsp;:\n", "\n", "$$g_{\\hat{\\eta}}(x)=\\begin{cases}1\\text{ si }\\hat{\\eta}(x)\\geq 0.5\\\\ 0\\text{ sinon.}\\end{cases}$$\n", "\n", "**<span style='color:blue'> Exercice</span>** ", "\n", "Soit $\\mathcal{F}$ un ensemble d'estimateurs du vrai $\\eta$ (e.g. r\u00e9gression logistique) et $\\mathcal{H}_{\\mathcal{F}}$ les classifieurs (i.e. plugin rule) associ\u00e9s. Le choix du bon estimateur $\\hat{\\eta}\\in\\mathcal{F}$ se fait via la *cross entropy* qui est, rappelons le, *strictly proper*. Le classifieur associ\u00e9 est not\u00e9 $g_{\\hat{\\eta}}\\in\\mathcal{H}_{\\mathcal{F}}$. Notons $g^\\star\\in\\mathcal{H}_{\\mathcal{F}}$ le minimiseur du risque (ou le minimiseur du risque empirique apr\u00e8s avoir vu une infinit\u00e9 de donn\u00e9es). Le choix de $\\hat{\\eta}$ en minimisant la *cross entropy* sur une infinit\u00e9 de donn\u00e9es garantit-il que le classifieur associ\u00e9 converge vers $g^\\star\\in\\mathcal{H}_{\\mathcal{F}}$ ?\n", "\n", "\n\n ----", "\n", "**<span style='color:green'> Indices</span>** ", "\n", "Consid\u00e9rer le sc\u00e9nario suivant. $\\mathcal{X}=\\{0, 1\\}$, $\\mu(0)=0.5$, $\\mu(1)=0.5$, $\\eta(0)=0.55$ et $\\eta(1)=0.45$. Consid\u00e9rez maintenant la classe d'estimateurs suivante $\\mathcal{F}=\\{\\eta_1,\\eta_2\\}$ o\u00f9 $\\eta_1(0)=0.99$ et $\\eta_1(1)=0.01$ ainsi que $\\eta_2(0)=0.49$ et $\\eta_1(1)=0.51$. Calculez la *cross-entropy* et d\u00e9duisez-en le meilleur estimateur de la probabilit\u00e9 conditionnelle. Ensuite calculez le minimiseur du risque (l'estimateur dont la plugin rule fera le moins d'erreurs).\n", "\n", "\n\n ----", "\n", "\n", "---\n", "\n", "En r\u00e9alit\u00e9, la cross-entropy garantit que l'on obtienne la meilleure plugin-rule \u00e0 partir du moment o\u00f9 on accepte certaines hypoth\u00e8ses. Ainsi, si le vrai $\\eta$ fait partie des param\u00e9trisations possibles alors, \u00e7a sera le cas."]}, {"cell_type": "markdown", "id": "governmental-milwaukee", "metadata": {}, "source": ["## III. Calibration de la probabilit\u00e9\n", "\n", "Dans de nombreuses applications, il est n\u00e9cessaire d'avoir une estimation \"relativement correcte\" de la probabilit\u00e9 conditionnelle $\\eta$. Consid\u00e9rons le jeu de donn\u00e9es synth\u00e9tique suivant. Nous allons d\u00e9lib\u00e9r\u00e9ment consid\u00e9rer un mod\u00e8le avec une forte capacit\u00e9 de sur-apprentissage afin de mettre ces effets en avant dans des temps d'apprentissage raisonables."]}, {"cell_type": "code", "execution_count": null, "id": "classical-colorado", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from scipy.special import expit as sigmoid\n", "\n", "np.random.seed(15)\n", "\n", "def sample(n=100, d=10):\n", "    beta = np.array([3. for _ in range(d)])\n", "    X = np.random.uniform(-4, 4, size=(n, d))\n", "    logits = np.dot(X, beta)\n", "    y = np.random.binomial(1, p=sigmoid(logits))\n", "    return X, y"]}, {"cell_type": "code", "execution_count": null, "id": "bc7d8ccb", "metadata": {}, "outputs": [], "source": ["X, y = sample()"]}, {"cell_type": "markdown", "id": "e0b1bab8", "metadata": {}, "source": ["Entra\u00eenons notre premier mod\u00e8le sur ces donn\u00e9es via un r\u00e9seau de neurones sur $\\texttt{pytorch}$."]}, {"cell_type": "code", "execution_count": null, "id": "756da24d", "metadata": {}, "outputs": [], "source": ["from torch.utils.data import DataLoader, Dataset\n", "import torch.optim as optim\n", "import torch.nn as nn\n", "import torch\n", "torch.manual_seed(42)"]}, {"cell_type": "code", "execution_count": null, "id": "pleased-officer", "metadata": {}, "outputs": [], "source": ["def fullyconnected_layer(in_f, out_f):\n", "    \"\"\"\n", "    \" this function returns a fully connected layer with batchnorm\n", "    \"\"\"\n", "    return nn.Sequential(\n", "        nn.Linear(in_f, out_f),\n", "        nn.BatchNorm1d(out_f),\n", "        nn.ReLU()\n", "    )\n", "\n", "class Net(nn.Module):\n", "    def __init__(self, n_labels=2, n_input=10, architecture=(2,)):\n", "        \"\"\"\n", "        \" n_labels is the dimension of the output\n", "        \" n_input is the dimension of the input\n", "        \" architecture describes the series of hidden layers\n", "        \"\"\"\n", "        super(Net, self).__init__()\n", "\n", "        layer_size = [n_input] + [i for i in architecture]\n", "\n", "        layers = [\n", "            fullyconnected_layer(in_f, out_f) for in_f, out_f in zip(layer_size, layer_size[1:])\n", "        ]\n", "        self.layers = nn.Sequential(*layers)\n", "        self.fc = nn.Linear(architecture[-1], n_labels)\n", "\n", "    def forward(self, x):\n", "        x = self.layers(x)\n", "        x = self.fc(x)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "id": "7c731003", "metadata": {}, "outputs": [], "source": ["class SyntheticDataset(Dataset):\n", "    def __init__(self, X, y):\n", "        self.dataset, self.label = X, y\n", "\n", "    def __len__(self):\n", "        return len(self.label)\n", "\n", "    def __getitem__(self, idx):\n", "        return torch.from_numpy(self.dataset[idx]).float(), int(self.label[idx])\n", "    \n", "dataset = SyntheticDataset(X, y)"]}, {"cell_type": "code", "execution_count": null, "id": "34065bfc", "metadata": {}, "outputs": [], "source": ["# TODO D\u00e9commenter les prints de loss, etc.\n", "import matplotlib.pyplot as plt\n", "\n", "def train_and_plot(lr=0.005, batch_size=50, epochs=5000, logs=10):\n", "    model = Net(architecture=tuple(10 for _ in range(10)))\n", "    # model.cuda()\n", "    model.train()\n", "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n", "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1000)\n", "    criterion = nn.CrossEntropyLoss()\n", "    \n", "    train_loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=0)\n", "    \n", "    loss_history = []\n", "    running_loss = 0.0\n", "    for e in range(epochs):\n", "        for idx, data in enumerate(train_loader):\n", "            inputs, labels = data\n", "            # labels = labels.cuda()\n", "            optimizer.zero_grad()\n", "            outputs = model(inputs)\n", "\n", "            loss = criterion(outputs, labels)\n", "            running_loss += loss.item()\n", "            if idx % logs == logs - 1:  # print every 2000 mini-batches\n", "                print('\\r[%d, %5d] loss: %.3f' % (e + 1, idx + 1, running_loss / logs), end=\"\")\n", "                loss_history.append(running_loss / logs)\n", "                running_loss = 0.0\n", "\n", "            loss.backward() # on calcule le gradient\n", "            optimizer.step() # on fait un pas d'optimisation\n", "        scheduler.step()\n", "    print('\\r************* Training done! *************')\n", "    plt.figure(figsize=(12, 8))\n", "    plt.plot(loss_history)\n", "    plt.title('Loss')\n", "    plt.show()\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "id": "4994f1be", "metadata": {}, "outputs": [], "source": ["model = train_and_plot(lr=0.005, batch_size=50, epochs=5000, logs=1)"]}, {"cell_type": "markdown", "id": "da7766e0", "metadata": {}, "source": ["L'optimisation se passe bien. Notre *loss* d\u00e9cro\u00eet et se rapproche asymptotiquement de $0$. On observe \u00e9galement quelques fluctuations li\u00e9es au fait qu'on optimise notre r\u00e9seau par *batch* (i.e. SGD). Consid\u00e9rons les notations suivantes. Soit $h:\\mathcal{X}\\rightarrow\\mathbb{R}$ notre r\u00e9seau de neurones dont la sortie sont appel\u00e9s *logit*. Notons $\\sigma(z)=(1+e^{-z})^{-1}$ la fonction sigmoid. C'est la fonction de lien qui permet de transformer nos *logits* en probabilit\u00e9. Nous avons donc un estimateur de la vraie probabilit\u00e9 conditionnelle&nbsp;:\n", "\n", "$$\\hat{\\eta}(x)=\\sigma(h(x)).$$\n", "\n", "Notre r\u00e9seau est optimis\u00e9 via la *cross-entropy* d\u00e9crite plus haut&nbsp;:\n", "\n", "$$\\mathcal{L}(h)=-\\frac{1}{n}\\sum_{i=1}^n y_i\\log\\big(\\sigma(h(x_i))\\big)+(1-y_i)\\log\\big(1-\\sigma(h(x_i))\\big).$$\n", "\n", "**<span style='color:blue'> Question</span>** ", "\n", "Notre *loss* atteint quasiment $0$. Supposons qu'elle soit aussi proche de $0$ que l'on veut. Que pouvons-nous dire sur l'erreur de classification $0/1$&nbsp;:\n", "\n", "$$Re(h)=\\frac{1}{n}\\sum_{i=1}^n\\textbf{1}\\{h(x_i)\\neq y_i\\},$$\n", "\n", "relativement \u00e0 la *plugin-rule* associ\u00e9e \u00e0 $\\sigma(h(x))$&nbsp;?\n", "\n", "\n\n ----", "\n", "\n", "Si notre *loss* est proche de $0$, alors les probabilit\u00e9s retourn\u00e9es par notre mod\u00e8le sont soit tr\u00e8s proches de $0$ pour les points de notre jeu de donn\u00e9es de la classe $0$, soit tr\u00e8s proches de $1$ pour les points associ\u00e9s \u00e0 la classe $1$. Notre mod\u00e8le indique donc une \"forte confiance\" dans ses pr\u00e9dictions tout en ne faisant que peu d'erreurs sur notre jeu d'apprentissage. Il existe une strat\u00e9gie permettant de quantifier la qualit\u00e9 de la \"confiance\" d'un mod\u00e8le&nbsp;: la courbe de calibration. Cette derni\u00e8re va confronter les scores de pr\u00e9diction de notre mod\u00e8le \u00e0 leur valeur empirique sur nos donn\u00e9es (i.e. si notre mod\u00e8le pr\u00e9dit $70\\%$, on s'attend que $70\\%$ des points associ\u00e9s \u00e0 ce score soient de la classe $1$)."]}, {"cell_type": "code", "execution_count": null, "id": "3a48bb31", "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(dataset, shuffle=True, batch_size=100, num_workers=0)"]}, {"cell_type": "code", "execution_count": null, "id": "fd88f13d", "metadata": {}, "outputs": [], "source": ["def loss_value(loader, temperature=None):\n", "    criterion = nn.CrossEntropyLoss()\n", "\n", "    with torch.no_grad():\n", "        model.eval()\n", "        running_loss = 0\n", "        true_labels = []\n", "        pred = []\n", "        for idx, data in enumerate(loader):\n", "            inputs, labels = data\n", "            true_labels.append(labels.cpu().detach().numpy())\n", "            outputs = model(inputs)\n", "            if temperature is not None:\n", "                outputs = outputs * temperature\n", "            pred.append(torch.softmax(outputs, axis=1)[:, 1].cpu().detach().numpy())\n", "            loss = criterion(outputs, labels)\n", "            running_loss += loss.item()\n", "    true_labels = np.concatenate(true_labels, axis=0)\n", "    pred = np.concatenate(pred, axis=0)\n", "    return true_labels, pred, running_loss\n", "\n", "true_train, pred_train, loss_train = loss_value(trainloader)\n", "print('Cross-entropy sur le train: %.3f' % loss_train)"]}, {"cell_type": "code", "execution_count": null, "id": "e55350b9", "metadata": {}, "outputs": [], "source": ["from sklearn.calibration import calibration_curve\n", "def calibration(true_value, pred_value):\n", "    fig = plt.figure(figsize=(12, 8))\n", "    ax1 = fig.gca()\n", "    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n", "\n", "    fraction_of_positives, mean_predicted_value = \\\n", "        calibration_curve(true_value, pred_value, n_bins=10)\n", "\n", "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n", "             label=\"%s\" % ('Deep net', ))\n", "\n", "    ax1.set_ylabel(\"Fraction of positives\")\n", "    ax1.set_xlabel(\"Mean predicted value\")\n", "    ax1.set_ylim([-0.05, 1.05])\n", "    ax1.legend(loc=\"lower right\")\n", "    ax1.set_title('Calibration plots')\n", "    plt.show()\n", "    \n", "calibration(true_train, pred_train)"]}, {"cell_type": "markdown", "id": "674c3a39", "metadata": {}, "source": ["Ce r\u00e9sultat \u00e9tait attendu. Notre mod\u00e8le est en surapprentissage : il ne se trompe pas sur le jeu d'apprentissage et pr\u00e9dit des scores indiquant une forte confiance. Nous devons \u00e9valuer la calibration **et** la *cross-entropy* sur un jeu de test afin d'avoir une id\u00e9e de la qualit\u00e9 des pr\u00e9dictions de notre mod\u00e8le."]}, {"cell_type": "code", "execution_count": null, "id": "38c126c1", "metadata": {}, "outputs": [], "source": ["X_test, y_test = sample(n=500)\n", "testset = SyntheticDataset(X_test, y_test)\n", "testloader = DataLoader(testset, shuffle=True, batch_size=500, num_workers=0)"]}, {"cell_type": "code", "execution_count": null, "id": "c601dd76", "metadata": {}, "outputs": [], "source": ["true_test, pred_test, loss_test = loss_value(testloader)\n", "print('Cross-entropy sur le train: %.3f' % loss_test)\n", "calibration(true_test, pred_test)"]}, {"cell_type": "markdown", "id": "d25dceae", "metadata": {}, "source": ["Notons tout d'abord qu'un mod\u00e8le qui pr\u00e9dirait $50\\%$ (une sorte de mod\u00e8le al\u00e9atoire) pour chacun des points de notre jeu d'apprentissage aurait une *cross-entropy* de $0.7$. Notre mod\u00e8le est donc pire, d'un point de vue des probabilit\u00e9s, qu'un mod\u00e8le al\u00e9atoire.\n", "\n", "**<span style='color:blue'> Question</span>** ", "\n", "Une forte *cross-entropy* en validation indique-t-elle un mauvais classifieur du point de vue de l'erreur $0/1$&nbsp;?\n", "\n", "\n\n ----", "\n", "\n", "Concernant notre courbe de calibration, le meilleur mod\u00e8le (du point de vue de la calibration) est celui qui serait situ\u00e9 totalement sur la diagonal. C'est le mod\u00e8le dont les probabilit\u00e9s estim\u00e9es correspond aux erreurs de pr\u00e9dictions constat\u00e9s empiriquement. On observe que les probabilit\u00e9s estim\u00e9es ne correspondent pas du tout \u00e0 ce qui est observ\u00e9 en pratique. Ainsi, lorsqu'on regarde les points pr\u00e9dit \u00e0 $45\\%$ comme appartenant \u00e0 la classe $1$, ils sont en r\u00e9alit\u00e9 \u00e0 $0\\%$ du c\u00f4t\u00e9 de la classe $1$. \u00c0 l'inverse, si je prends ceux qui sont \u00e0 $20\\%$ associ\u00e9s \u00e0 la classe $1$, ils le sont r\u00e9ellement $65\\%$ du temps. Nos probabilit\u00e9s sont absolument impossibles \u00e0 interpr\u00e9ter.\n", "\n", "\n", "**<span style='color:blue'> Question</span>** ", "\n", "Un mod\u00e8le situ\u00e9 parfaitement sur la diagonale de calibration est-il n\u00e9cessairement un bon mod\u00e8le pr\u00e9dictif de classification&nbsp;?\n", "\n", "\n\n ----", "\n", "\n", "Notre strat\u00e9gie va \u00eatre de trouver une \"adaptation\" de notre mod\u00e8le qui ne change en rien son pouvoir pr\u00e9dictif mais qui calibre mieux les probabilit\u00e9s. Observons tout d'abord notre fonction de lien."]}, {"cell_type": "code", "execution_count": null, "id": "8e97e40a", "metadata": {"tags": ["remove-input"]}, "outputs": [], "source": ["x = np.linspace(-5, 5, 100)\n", "y = sigmoid(x)\n", "plt.figure(figsize=(12, 8))\n", "plt.plot(x, y)\n", "plt.show()"]}, {"cell_type": "markdown", "id": "c527c595", "metadata": {}, "source": ["Lorsque les valeurs des *logits* (i.e. $h(x)$) s'\u00e9cartent de $0$, la probabilit\u00e9 estim\u00e9e se rapproche des fortement de $0$ ou de $1$. Ainsi, en r\u00e9duisant l'amplitude des *logits*, nous rapprochons nos probabilit\u00e9s estim\u00e9es de $50\\%$. Cela nous permet de r\u00e9duire l'exc\u00e8s de confiance de notre mod\u00e8le. On constate de plus que cela ne change en rien le pouvoir pr\u00e9dictif de notre mod\u00e8le. Illustrons ce dernier point par un exemple."]}, {"cell_type": "code", "execution_count": null, "id": "5b62b623", "metadata": {}, "outputs": [], "source": ["x = np.random.uniform(-50, 50, (10, 1))\n", "\n", "y = np.concatenate([\n", "    sigmoid(x),\n", "    sigmoid(x/50) # on divise nos logits par 50\n", "], axis=1)\n", "print(y)\n", "print(y>0.5) # on a la valeur True lorque c'est la classe $1$ qui est pr\u00e9dite"]}, {"cell_type": "markdown", "id": "cbb6900a", "metadata": {}, "source": ["On remarque qu'ind\u00e9pendamment de l'amplitude de nos logits, les pr\u00e9dictions restent les m\u00eames. Cela se g\u00e9n\u00e9ralise bien s\u00fbr au cas multiclasse.\n", "\n", "Nous devons donc estimer un facteur multiplicatif permettant d'obtenir une meilleure calibration (i.e. on veut \u00eatre sur la diagonale de calibration). Ce n'est en r\u00e9alit\u00e9 pas suffisant car il suffit que le facteur multiplicatif soit aussi proche de $0$ qu'on le souhtaite afin d'\u00eatre aussi proche de la diagonale que possible. La strat\u00e9gie va \u00eatre d'optimiser ce score multiplicatif afin que notre mod\u00e8le soit bon sur un ensemble de validation. Ainsi, on ne change pas la forme de notre mod\u00e8le pr\u00e9dictif (la fronti\u00e8re de d\u00e9cision reste fixe), mais on alt\u00e8re l'estimation des probabilit\u00e9s afin d'obtenir un bon score sur un jeu de validation. Notre mod\u00e8le devient donc&nbsp;:\n", "\n", "$$\\sigma(t h(x)),$$\n", "o\u00f9 $t\\in\\mathbb{R}^+$ est notre scalaire qu'on appelle \"temp\u00e9rature\". L'id\u00e9e va ensuite d'optimiser notre mod\u00e8le dont l'unique param\u00e8tre est $t$ pour $h$ fix\u00e9 sur un jeu d'apprentissage avec la *cross-entropy*."]}, {"cell_type": "code", "execution_count": null, "id": "807cf486", "metadata": {}, "outputs": [], "source": ["X_val, y_val = sample(n=500)\n", "valset = SyntheticDataset(X_val, y_val)\n", "valloader = DataLoader(valset, shuffle=True, batch_size=500, num_workers=0)"]}, {"cell_type": "markdown", "id": "0f1e90ee", "metadata": {}, "source": ["**<span style='color:blue'> Exercice</span>** ", "\n", "Compl\u00e9tez le code ci-dessous afin d'estimer le scalaire de temp\u00e9rature.\n", "\n", "\n\n ----"]}, {"cell_type": "code", "id": "0be450ac", "metadata": {}, "source": ["temperature = nn.Parameter(torch.ones(1))\n", "####### Complete this part ######## or die ####################\n", "...\n", "...\n", "...\n", "###############################################################\n", "print('\\nTemperature:', temperature.detach())\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "id": "d99e8cdb", "metadata": {}, "source": ["true_test, pred_test, loss_test = loss_value(testloader, temperature)\n", "print('Cross-entropy sur le test: %.3f' % loss_test)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "e6d47556", "metadata": {}, "source": ["Notre mod\u00e8le est donc meilleur qu'un mod\u00e8le al\u00e9atoire en terme d'estimation des probabilit\u00e9s sur un jeu de test."]}, {"cell_type": "code", "id": "cccc1e90", "metadata": {}, "source": ["calibration(true_test, pred_test)\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "id": "bad4d6e1", "metadata": {}, "source": ["On observe \u00e9galement que la calibration est bien meilleure !"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.2"}}, "nbformat": 4, "nbformat_minor": 5}