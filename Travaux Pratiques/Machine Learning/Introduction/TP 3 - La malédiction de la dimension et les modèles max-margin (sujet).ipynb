{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  La malédiction de la dimension et les modèles max-margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques liens pour plus de détails :\n",
    "* [Overfitting](https://github.com/maximiliense/lmpirp/blob/main/Notes/Overfitting.pdf)\n",
    "* [KNN](https://github.com/maximiliense/lmpirp/blob/main/Notes/KNN.pdf)\n",
    "* [SVM](https://github.com/maximiliense/lmpirp/blob/main/Notes/SVM.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous avons pu le voir lors des TPs précedents, l'objectif de l'apprentissage est de trouver une fonction $f\\in\\mathcal{H}$ de $\\mathcal{X}\\mapsto\\mathcal{Y}$ telle que le risque de généralisation $R:\\mathcal{H}\\mapsto\\mathbb{R}^+$ est minimisé :\n",
    "\\begin{equation}\n",
    "f=\\text{argmin}_{h\\in\\mathcal{H}}R(h)\n",
    "\\end{equation}\n",
    "\n",
    "Le risque de généralisation est défini comme l'espérance d'un risque élémentaire $r$ (qui dépend de la tâche que l'on souhaite résoudre) :\n",
    "\\begin{equation}\n",
    "R(h)=\\mathbb{E}_{X\\times Y}\\Big[r(h(X), Y)\\Big]\n",
    "\\end{equation}\n",
    "\n",
    "Ce calcul d'espérance est bien entendu impossible, ne serait-ce que par ce que nous ne connaissons pas la loi de $X\\times Y$... La stratégie de l'apprentissage statistique consiste à s'appuyer sur un risque dit empirique ; un risque calculé à partir d'un certain nombre d'exemples d'apprentissages que l'on notera $\\mathcal{S}=\\{(\\boldsymbol{x_i}, y_i)\\}_{i\\leq n}$ :\n",
    "\\begin{equation}\n",
    "Re(h)=\\frac{1}{n}\\sum_{i=1}^n r\\big(h(\\boldsymbol{x_i}), y_i\\big)\n",
    "\\end{equation}\n",
    "\n",
    "Le risque empirique, est un estimateur sans biais du risque de généralisation pour un $h$ quelconque. Cependant, nous sommes intéressé par un $\\hat{h}\\in\\mathcal{H}$ particulier : celui qui minimise le risque empirique :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{h}=\\text{argmin}_{h\\in\\mathcal{H}}Re(h).\n",
    "\\end{equation}\n",
    "\n",
    "Dans le cadre de la régression linéaire, logistique, etc. nous avons pu voir que $\\mathcal{H}$ était construit de manière paramétrique et que l'optimisation se faisait soit analytiquement, soit au travers de de l'algorithme de descente de gradient.\n",
    "\n",
    "**Il convient de faire attention**. Comme nous avons pu le constater dans les TPs précedents, le risque empirique **n'est pas** un estimateur sans biais du risque de généralisation pour $\\hat{h}$. Nous avons pu observer des scénarios où $Re(h)=0$ alors que le risque de généralisation atteignait des valeurs catastrophiques. De manière plus rigoureuse, le gap de généralisation est l'écart entre notre risque empirique de notre estimateur $\\hat{h}$ et son risque de généralisation :\n",
    "\\begin{equation}\n",
    "\\text{gap}(\\hat{h})=|Re(\\hat{h})-R(\\hat{h})|.\n",
    "\\end{equation}\n",
    "\n",
    "Il est possible d'avoir une idée de $R(\\hat{h})$ en passant par un jeu de test ou autre stratégies d'évaluation.\n",
    "\n",
    "\n",
    "Deux facteurs principaux sont admis comme entrant en jeu : \n",
    "* la taille de l'ensemble $\\mathcal{H}$ qui est généralement liée au nombre de paramètres de notre modèle,\n",
    "* la taille du jeu de données $\\mathcal{S}$.\n",
    "\n",
    "Plus $\\mathcal{H}$ est grand, plus on s'attend à voir l'erreur augmenter. L'effet de double descente montre qu'avec un choix réfléchi de paramétrisation, cette tendance n'est pas nécessairement monotone. De la même manière, augmenter la taille du jeu de données $\\mathcal{S}$ permet de réduire l'erreur de généralisation.\n",
    "\n",
    "La taille de $\\mathcal{H}$ est intrinsèquement liée au nombre de paramètres qui lui-même dépend très souvent de la dimension $d$ de nos données. La première partie de ce TP se concentrera sur ce qu'on appelle la *malédiction de la dimension* et la seconde partie sur la notion de *max-margin*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La malédiction de la dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La malédiction de la dimension fait référence aux résultats contre-intuitifs qui apparaissent lorsque la dimension augmente. Une première manière de l'observer est possible grâce au KNN. Ce dernier classe un nouvel élément en fonction de ses voisins dans le jeu d'apprentissage. Nous allons en particulier étudier l'évolution du risque de généralisation en fonction de la dimension. Plus précisément, les données sont construites de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample_data(n, k=3, d=3, mu=1):\n",
    "    y = np.random.randint(0, 2, size=(n, 1))\n",
    "    \n",
    "    X = np.random.normal(mu, 1, size=(n, k))\n",
    "    X = y*X-(1-y)*X # positive have mean mu and negative, -mu\n",
    "    noise = np.random.normal(0, 1, size=(n, d-k))\n",
    "    X = np.concatenate([X, noise], axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit autrement, $k$ dimensions contiennent le signal intéressant pour notre tâche et $d$ dimensions ne servent à rien. Nous observons ci-dessous ce qui se passe lorsqu'on rajouter des dimensions de bruits (i.e. qui ne servent à rien)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scores = []\n",
    "redo = 5\n",
    "max_dim = 5000\n",
    "first_dim = 10\n",
    "steps = 100\n",
    "\n",
    "for d in range(first_dim, max_dim, steps):\n",
    "    s = 0\n",
    "    for _ in range(redo):\n",
    "        X, y = sample_data(100, d=d)\n",
    "        X_test, y_test = sample_data(200, d=d)\n",
    "        c = KNeighborsClassifier()\n",
    "        c.fit(X, y.reshape((y.shape[0],)))\n",
    "        s += c.score(X_test, y_test.reshape((y_test.shape[0],)))/redo\n",
    "    scores.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configuration generale de matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.plot(list(range(first_dim, max_dim, steps)), scores)\n",
    "plt.title('Evolution de l\\'erreur en fonction de la dimension du probleme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:blue\">**Exercice 1 :**</span> **Quelle est le risque de généralisation pour l'erreur 0/1 (1 si la classe est mal prédite, 0 sinon) d'un classifieur aléatoire ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "<span style=\"color:blue\">**Exercice 2 :**</span> **Expliquez pourquoi l'erreur de généralisation déminimue lorsqu'on rajoute des dimensions sans signal.**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manière similaire, affichons ci-dessous l'évolution des distances entre nos points en fonction de la dimension du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_data(n, d):\n",
    "    return np.random.uniform(-1, 1, size=(n, d))/np.sqrt(d)\n",
    "X = sample_data(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = 50\n",
    "def experiment_(d):\n",
    "    min_ = 0\n",
    "    max_ = 0\n",
    "    mean_ = 0\n",
    "    for _ in range(redo):\n",
    "        X = sample_data(100, d)\n",
    "        vec = np.sqrt((X**2).sum(axis=1))\n",
    "        min_ += vec.min()/redo\n",
    "        max_ += vec.max()/redo\n",
    "        mean_ += vec.mean()/redo\n",
    "    return min_, max_, mean_\n",
    "idx = []\n",
    "val = []\n",
    "for d in range(10, 1000, 100):\n",
    "    idx.append([d])\n",
    "    val.append(experiment_(d))\n",
    "for d in range(2000, 10000, 1000):\n",
    "    idx.append([d])\n",
    "    val.append(experiment_(d))\n",
    "arr = np.concatenate([np.array(idx), np.array(val)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(arr[:, 0], arr[:, 1], label='Min')\n",
    "plt.plot(arr[:, 0], arr[:, 2], label='Max')\n",
    "plt.plot(arr[:, 0], arr[:, 3], label='Moy')\n",
    "plt.legend()\n",
    "plt.title('Evolution des distances en fonction de la dimension du probleme')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice 3 :**</span> **Quelle phénomène mathématique pouvons nous invoquer afin d'expliquer ce phénomène ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine à vecteurs de support ou l'hypothèse du *max-margin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'hypothèse implicite derrière le *max-margin* est qu'entre deux frontières de même complexité, la plus robuste aux perturbations (dans le sens où si on perturbe un élément du train la probabilité qu'il change de classe est la plus faible) est la meilleure. L'idée fait sens car on peut supposer que les échantillons nouveaux peuvent être vus comme des perturbations des échantillons du jeu d'apprentissage. \n",
    "\n",
    "La frontière la plus robuste aux perturbations est celle qui maximise la distance entre le point le plus proche et elle-même. C'est l'hypothèse du *max-margin*.\n",
    "\n",
    "Le SVM, ou machine à vecteurs de support adopte cette stratégie. Une présentation plus détaillée du SVM est disponible à l'adresse suivante : [SVM](https://github.com/maximiliense/lmpirp/blob/main/Notes/SVM.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un problème de classification linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le SVM est un classifieur linéaire. Soit $\\mathcal{X}\\subset\\mathbb{R}^d$ nos variables d'entrées et $\\mathcal{Y}=\\{-1,+1\\}$ nos variable à prédire. Un classifieur linéaire sépare les éléments de notre jeu de données par un hyperplan. Comme vous avez pu le voir dans le TP précédent, un hyperplan décrit par le vecteur normal $w$ est défini par les solutions de l'équations suivantes :\n",
    "\\begin{equation}\n",
    "\\langle w, x\\rangle = 0\n",
    "\\end{equation}\n",
    "\n",
    "Si le produit scalaire est positif, on dira que notre échantillon $x$ appartient à la classe positive et inversement.\n",
    "\n",
    "Un classifieur linéaire peut donc être décrit de la manière suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "h_w:\\mathcal{X}&\\mapsto\\mathcal{Y}=\\{-1,+1\\}\\\\\n",
    "x&\\rightarrow \\text{sign}(\\langle w, x\\rangle)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "De la même manière que pour les TPs précédents, on peut introduire la notion de biais en rajoutant une dimension de $1$ aux vecteurs $x$.\n",
    "\n",
    "---\n",
    "<span style=\"color:blue\">**Petite question d'algèbre :**</span> **Trouvez le projecteur orthogonal de $\\mathcal{X}$ sur l'hyperplan décrit par le vecteur $w$, noté $\\text{proj}_w(x)$. Démontrez que $\\forall x\\in\\mathcal{X},\\ \\text{proj}_w(x)\\in\\{z:\\langle w, z\\rangle=0\\}$ (autrement dit, démontrez que la projection de $x$ sur la frontière est bien sur la frontière).**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span> \n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Petite question d'algèbre 2 :**</span> **Montrer que $\\text{proj}_w^2=\\text{proj}_w$ (le carré est pris dans le sens de la composition). Cela vous semble-t-il logique ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span> \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le primal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dit plus haut, on ne cherche pas n'importe quel hyperplan, mais bien celui qui rang la marge maximale. La marge est définie par la plus patite distance entre un point du jeu de données et la frontière de décision.\n",
    "\n",
    "La distance d'un point à la frontière est donnée par $|\\langle x_i, w\\rangle|$ ($w$ unitaire). La quantité $y_i\\langle x_i, w\\rangle$ est positive et indique la distance à la frontière si le point est bien classé et donne la distance négative si le point est mal classé. Ainsi $\\min_{i\\leq m} y_i\\langle x_i, w\\rangle$ nous donne le point la plus petite distance (négative si mal classé).\n",
    "\n",
    "On souhaite donc trouver $w$ tel que cette distance soit maximale (i.e. le point le plus proche est le plus loin possible de la frontière) :\n",
    "\\begin{equation}\n",
    "\\hat{w}=\\text{argmax}_{w, ||w||=1}\\min_{i\\leq m}y_i\\langle x_i, w\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "Il est possible de montrer que le vecteur $w=w_0/||w_0||$ tel que :\n",
    "$$w_0=\\text{argmin}_{w}||w||^2_2,\\ s.t. \\forall i\\leq m,\\ y_i\\langle x_i, w\\rangle \\geq 1$$\n",
    "est solution de ce problème de minimisation.\n",
    "\n",
    "Remarquez que cela fait penser à la régularisation : parmi toutes les solutions possibles, on cherche celle de norme minimale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le dual (optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème d'optimisation si dessus est ce qu'on appelle un problème d'optimisation sous contrainte. Un tel problème est associé à ce qu'on appelle un Lagrangien :\n",
    "$$\\mathcal{L}(w, \\alpha)=||w||_2^2+\\sum_{i=1}^m\\alpha_i(1-y_i\\langle x_i, w\\rangle),\\ \\alpha_j\\geq 0, j\\leq m$$\n",
    "\n",
    "Notons $g(w)=\\max_{\\alpha,\\alpha\\geq 0}\\mathcal{L}(w,\\alpha)$. On observe assez rapidement que $g(w)=\\infty$ si une des contraintes n'est pas satisfaite et vaut $||w||^2_2$ sinon.\n",
    "\n",
    "Ainsi, minimiser $g(w)$ revient à minimiser la norme du vecteur $w$ en respectant les contraintes. C'est ce qu'on appelle le *primal* qu'on note $p^\\star$ :\n",
    "$$p^\\star=\\min_w\\max_{\\alpha,\\alpha\\geq 0}\\mathcal{L}(w,\\alpha)$$\n",
    "\n",
    "Le passage au dual permet d'inverser la minimisation et la maximisation. Il n'est pas évident de montrer que les deux problèmes sont équivalents. C'est ici le cas et on note $d^\\star$ le dual (on parle donc de dualité forte) :\n",
    "$$d^\\star=\\max_{\\alpha,\\alpha\\geq 0}\\min_w\\mathcal{L}(w,\\alpha).$$\n",
    "\n",
    "Quelques éléments de calculs plus loin (le minimum est un point critique, on annule les dérivées partielles, etc.), on reformule le dual de la manière suivante :\n",
    "$$\\max_{\\alpha,\\alpha\\geq 0}\\sum_i\\alpha_i-\\frac{1}{2}\\sum_i\\sum_j\\alpha_i\\alpha_jy_iy_j\\langle x_i, x_j\\rangle$$\n",
    "\n",
    "et\n",
    "\n",
    "$$w=\\frac{1}{2}\\sum_i \\alpha_iy_ix_i$$\n",
    "\n",
    "Ainsi, notre modèle prédictif prend la forme suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "h:\\mathcal{X}&\\mapsto\\mathcal{Y}\\\\\n",
    "x&\\rightarrow\\text{sign}(\\sum_i\\alpha_iy_i\\langle x_i, x\\rangle)\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'astuce du noyau (optionnel, suite du dual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'astuce du noyau découle de la formation duale et notamment du fait que celle-ci n'est liée aux données qu'au travers du produit $y_iy_i$ et du produit scalaire $\\langle x_i, x_j\\rangle$. Si le problème de classification est non linéaire, il est possible de passer par une transformation non linéaire $\\phi:\\mathcal{X}\\mapsto\\mathcal{F}$ de nos données d'entrées. Le problème devient donc :\n",
    "$$\\max_{\\alpha,\\alpha\\geq 0}\\sum_i\\alpha_i-\\frac{1}{2}\\sum_i\\sum_j\\alpha_i\\alpha_jy_iy_j\\langle \\phi(x_i), \\phi(x_j)\\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans rentrer dans les détails, l'astuce du noyau vient de l'existence de fonctions :\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "k:\\mathcal{X}\\times\\mathcal{X}&\\mapsto\\mathbb{R}\\\\\n",
    "x_i,x_j&\\rightarrow k(x_i,x_j)=\\langle\\phi(x_i),\\phi(x_j).\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Ces fonctions $k$ ne nécessitent pas de projeter les $x$ dans un espace de plus grande dimension et permettent d'obtenir le résultat du produit scalaire directement dans l'espace d'origine. Ainsi, on peut même calculer le produit scalaire dans des espaces de dimensions infinies.\n",
    "\n",
    "Par exemple le noyau :\n",
    "$$k(x_i, x_j)=(\\langle x_i, x_j\\rangle+c)^n,$$\n",
    "nous permet de faire une transformations polynomiales de degré $n$ directement dans l'espace d'origine ; on remarque que la puissance $n$ est calculée sur le résultat du produit scalaire ($+c$) qui est donc un sclaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de la frontière de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce premier exercice est de visualiser la frontière de décision d'un SVM en jouant sur un exemple simple avec les noyaux offerts par la librairie $\\texttt{scikit-learn}$.\n",
    "\n",
    "La visualisation suivante permet d'observer la marge et notamment les vecteurs de supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "np.random.seed(0)\n",
    "\n",
    "dataset_size = 20\n",
    "\n",
    "X = np.r_[np.random.randn(dataset_size, 2) - [2, 2], np.random.randn(dataset_size, 2) + [2, 2]]\n",
    "Y = [0] * dataset_size + [1] * dataset_size\n",
    "\n",
    "# figure number\n",
    "fignum = 1\n",
    "\n",
    "kernel = 'linear'\n",
    "clf = svm.SVC(kernel=kernel)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# get the separating hyperplane\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-5, 5)\n",
    "yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "# plot the parallels to the separating hyperplane that pass through the\n",
    "# support vectors (margin away from hyperplane in direction\n",
    "# perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in\n",
    "# 2-d.\n",
    "margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))\n",
    "yy_down = yy - np.sqrt(1 + a ** 2) * margin\n",
    "yy_up = yy + np.sqrt(1 + a ** 2) * margin\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.clf()\n",
    "plt.plot(xx, yy, 'k-')\n",
    "plt.plot(xx, yy_down, 'k--')\n",
    "plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,\n",
    "            facecolors='none', zorder=10, edgecolors='k')\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired,\n",
    "            edgecolors='k')\n",
    "\n",
    "plt.axis('tight')\n",
    "x_min = -4.8\n",
    "x_max = 4.2\n",
    "y_min = -6\n",
    "y_max = 6\n",
    "\n",
    "XX, YY = np.mgrid[x_min:x_max:500j, y_min:y_max:500j]\n",
    "Z = clf.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(XX.shape)\n",
    "plt.pcolormesh(XX, YY, Z, cmap=plt.cm.Paired, shading='auto')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(size=80):\n",
    "    X = np.random.uniform(-1, 1, size=(200, 2))\n",
    "    y = X[:, 0]**3 < X[:, 1]\n",
    "    return X, y\n",
    "X, y = sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X, y, clf=None):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    if clf is not None:\n",
    "\n",
    "        XX, YY = np.mgrid[-1:1:500j, -1:1:500j]\n",
    "        Z = clf.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.pcolormesh(XX, YY, Z, cmap=plt.cm.Paired, shading='auto')\n",
    "\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici la visualisation d'un SVM avec un noyau linéaire (un produit scalaire $\\langle\\cdot,\\cdot\\rangle$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'linear'\n",
    "clf = svm.SVC(kernel=kernel)\n",
    "clf.fit(X, y)\n",
    "\n",
    "plot(X, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous avez pu le voir, si vous avez lu la section concernant le dual, le SVM permet de remplacer les comparaisons linéaires (i.e. le produit scalaire), par des comparaisons non-linéaires (i.e. produit scalaire dans un espace où les données sont projetées non linéairement). La librairie $\\texttt{scikir-learn}$ permet de jouer avec ce paramètre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice 4 :**</span> **Jouez avec plusieurs noyaux et observez la forme de la frontière de décision.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Question :**</span> **Comparez la robustesse d'un SVM par rapport à un 1NN relativement à la dimension du problème. Le SVM est-il plus ou moins robuste que le 1NN ?**\n",
    "\n",
    "<span style=\"color:green\">**Réponse :**</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sur de vrais données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice 5 :**</span> **Utilisez le SVM, la régression logistique ou encore le KNN pour résoudre les problèmes ci-dessous.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digit = datasets.load_digits()\n",
    "\n",
    "X = digit['data']\n",
    "Y = digit['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(14, 8))\n",
    "fig.tight_layout()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img = X[i].reshape((8, 8))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.imshow(img, cmap='gray_r', vmin=0, vmax=1)\n",
    "    plt.title('Label: '+str(Y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "X = wine['data']\n",
    "Y = wine['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
